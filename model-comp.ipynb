{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Model Comparison Jupyter notebook\r\n",
    "\r\n",
    "This notebook will load nets as defined int the imported python modules with certain preformance characteristics for comparison.\r\n",
    "This file will also contain the tensorboard that helps visualize the models accuracy over time and the training process.\r\n",
    "\r\n",
    "Components:\r\n",
    "- initialize training parameters and fetch dataset (including RotMNIST dataset)\r\n",
    "- compare model attributes (such as total parameters and structure)\r\n",
    "- define hyperparameters\r\n",
    "- create tensorboard and set up preformance graphs\r\n",
    "- compare model training and preformance under different conditions\r\n",
    "- save models to files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "### Imports for pytorch and dataset\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "from RotMNIST import RotMNIST"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "### Define dataloaders\r\n",
    "### Instatiate RotMNIST and verify behaviour below with the dataloaders\r\n",
    "dataset_rot = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=True\r\n",
    ")\r\n",
    "\r\n",
    "test_dataset_rot = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=False,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=True\r\n",
    ")\r\n",
    "\r\n",
    "dataset_upright = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=False,\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "### Import different networks from python files\r\n",
    "# TODO: Uncomment other networks and import\r\n",
    "from p4m_conv import P4MNet\r\n",
    "from p4_conv import P4Net\r\n",
    "from z2_conv import ConvNet\r\n",
    "\r\n",
    "p4m_net = P4MNet()\r\n",
    "p4_net = P4Net()\r\n",
    "conv_net = ConvNet()\r\n",
    "\r\n",
    "p4m_total_params = sum(p.numel() for p in p4m_net.parameters() if p.requires_grad)\r\n",
    "p4_total_params = sum(p.numel() for p in p4_net.parameters() if p.requires_grad)\r\n",
    "z2_total_params = sum(p.numel() for p in conv_net.parameters() if p.requires_grad)\r\n",
    "\r\n",
    "print(p4m_net)\r\n",
    "print(p4_net)\r\n",
    "print(conv_net)\r\n",
    "\r\n",
    "print(\"P4M  --\\tTrainable Params: \" + str(p4m_total_params))\r\n",
    "print(\"P4   --\\tTrainable Params: \" + str(p4_total_params))\r\n",
    "print(\"Conv --\\tTrainable Params: \" + str(z2_total_params))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "P4MNet(\n",
      "  (conv1): P4MConvZ2()\n",
      "  (conv2): P4MConvP4M()\n",
      "  (conv3): P4MConvP4M()\n",
      "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "P4Net(\n",
      "  (conv1): P4ConvZ2()\n",
      "  (conv2): P4ConvP4()\n",
      "  (conv3): P4ConvP4()\n",
      "  (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "ConvNet(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=184, bias=True)\n",
      "  (fc2): Linear(in_features=184, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "P4M  --\tTrainable Params: 128954\n",
      "P4   --\tTrainable Params: 65466\n",
      "Conv --\tTrainable Params: 119598\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "### Hyperparameters\r\n",
    "learning_rate = 0.001\r\n",
    "batch_size = 64\r\n",
    "epochs = 25\r\n",
    "\r\n",
    "### Objectives/Loss fn\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "### Dataloaders\r\n",
    "train_dataloader_rot = DataLoader(dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "test_dataloader_rot = DataLoader(test_dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "train_dataloader_upright = DataLoader(dataset_upright, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Tensorboard helpers\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# helper function to show an image (copied from https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\r\n",
    "# (used in the `plot_classes_preds` function below)\r\n",
    "def imshow(img):\r\n",
    "    img = img.mean(dim=0)\r\n",
    "    img = img / 2 + 0.5     # unnormalize\r\n",
    "    npimg = img.numpy()\r\n",
    "    plt.imshow(npimg, cmap=\"Greys\")\r\n",
    "\r\n",
    "### Tensorboard\r\n",
    "import torch.utils.tensorboard\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "writer = SummaryWriter('runs/p4m_MNIST_1')\r\n",
    "\r\n",
    "# Get grid of training images\r\n",
    "dataiter = iter(train_dataloader_upright)\r\n",
    "images, labels = dataiter.next()\r\n",
    "img_grid = torchvision.utils.make_grid(images)\r\n",
    "imshow(img_grid)\r\n",
    "\r\n",
    "# To tensorboard\r\n",
    "writer.add_image('Training Batch', img_grid)\r\n",
    "\r\n",
    "writer.add_graph(p4m_net, images)\r\n",
    "writer.close()\r\n",
    "\r\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\r\n",
    "# helper function\r\n",
    "def select_n_random(data, labels, n=100):\r\n",
    "    '''\r\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\r\n",
    "    '''\r\n",
    "    assert len(data) == len(labels)\r\n",
    "\r\n",
    "    perm = torch.randperm(len(data))\r\n",
    "    return data[perm][:n], labels[perm][:n]\r\n",
    "\r\n",
    "# select random images and their target indices\r\n",
    "images, labels = select_n_random(dataset_upright.data, dataset_upright.targets)\r\n",
    "\r\n",
    "# get the class labels for each image\r\n",
    "class_labels = [classes[lab] for lab in labels]\r\n",
    "\r\n",
    "# log embeddings\r\n",
    "features = images.view(-1, 28 * 28)\r\n",
    "writer.add_embedding(features,\r\n",
    "                    metadata=class_labels,\r\n",
    "                    label_img=images.unsqueeze(1))\r\n",
    "writer.close()\r\n",
    "\r\n",
    "# helper functions\r\n",
    "\r\n",
    "def images_to_probs(net, images):\r\n",
    "    '''\r\n",
    "    Generates predictions and corresponding probabilities from a trained\r\n",
    "    network and a list of images\r\n",
    "    '''\r\n",
    "    output = net(images)\r\n",
    "    # convert output probabilities to predicted class\r\n",
    "    _, preds_tensor = torch.max(output, 1)\r\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\r\n",
    "    return preds, [torch.nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\r\n",
    "\r\n",
    "\r\n",
    "def plot_classes_preds(net, images, labels):\r\n",
    "    '''\r\n",
    "    Generates matplotlib Figure using a trained network, along with images\r\n",
    "    and labels from a batch, that shows the network's top prediction along\r\n",
    "    with its probability, alongside the actual label, coloring this\r\n",
    "    information based on whether the prediction was correct or not.\r\n",
    "    Uses the \"images_to_probs\" function.\r\n",
    "    '''\r\n",
    "    preds, probs = images_to_probs(net, images)\r\n",
    "    # plot the images in the batch, along with predicted and true labels\r\n",
    "    fig = plt.figure(figsize=(32, 32))\r\n",
    "    for idx in np.arange(64):\r\n",
    "        ax = fig.add_subplot(8, 8, idx+1, xticks=[], yticks=[])\r\n",
    "        imshow(images[idx].cpu())\r\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\r\n",
    "            preds[idx],\r\n",
    "            probs[idx] * 100.0,\r\n",
    "            labels[idx]),\r\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\r\n",
    "            \r\n",
    "    return fig\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, cur_epoch):\r\n",
    "    running_loss = 0.0\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        model.to(device)\r\n",
    "        # Compute prediction and loss for backprop\r\n",
    "        pred = model(X.to(device))\r\n",
    "        loss = loss_fn(pred, y.to(device))\r\n",
    "\r\n",
    "        # Backpropagation by setting grad to zero, calculating using backprop engine and stepping (using learning rate)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        running_loss += loss.item()\r\n",
    "\r\n",
    "        if batch % 100 == 99:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\r\n",
    "\r\n",
    "            writer.add_scalar('training loss', running_loss / 100, cur_epoch * len(dataloader) + batch)\r\n",
    "            running_loss = 0.0\r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    model.to(device)\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "    \r\n",
    "    # No gradient on training data (faster computation and no optimization happening here anyway)\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, y in dataloader:\r\n",
    "            pred = model(X.to(device))\r\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\r\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\r\n",
    "\r\n",
    "    test_loss /= size\r\n",
    "    correct /= size\r\n",
    "    \r\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\r\n",
    "    return correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Train all networks\r\n",
    "def train_test_net(net, train_upright):\r\n",
    "    # Add option to train networks with RotMNIST\r\n",
    "    test_dataloader = train_dataloader_rot\r\n",
    "    if (train_upright):\r\n",
    "        test_dataloader = train_dataloader_upright\r\n",
    "\r\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\r\n",
    "    for t in range(epochs):\r\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "        train_loop(test_dataloader, net, loss_fn, optimizer, t)\r\n",
    "        correct = test_loop(test_dataloader_rot, net, loss_fn)\r\n",
    "        writer.add_scalar('Test Performance', correct, t * len(test_dataloader_rot) + batch_size)\r\n",
    "    print('Finished Training Net + ' + str(type(net)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "base_dir = \"trained-models/\"\r\n",
    "\r\n",
    "writer = SummaryWriter('runs/p4m_MNIST_1')\r\n",
    "train_test_net(p4m_net, True)\r\n",
    "torch.load(p4m_net, base_dir + 'upright-trained-p4m-1.pth')\r\n",
    "\r\n",
    "writer = SummaryWriter('runs/p4_MNIST_1')\r\n",
    "train_test_net(p4_net, True)\r\n",
    "torch.save(p4_net, base_dir + 'upright-trained-p4-1.pth')\r\n",
    "\r\n",
    "writer = SummaryWriter('runs/conv_MNIST_1')\r\n",
    "train_test_net(conv_net, False)\r\n",
    "torch.save(conv_net, base_dir + 'rot-trained-conv-1.pth')\r\n",
    "\r\n",
    "convu_net = ConvNet()\r\n",
    "writer = SummaryWriter('runs/convu_MNIST_1')\r\n",
    "train_test_net(convu_net, True)\r\n",
    "torch.save(convu_net, base_dir + 'upright-trained-conv-1.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Comparisons\r\n",
    "\r\n",
    "There are a few comparisons between the models to be made here. Here is a list of the following that I log\r\n",
    "- Model accuracy on 10000 test images\r\n",
    "- Model accuracy per class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import torch\r\n",
    "base_dir = \"trained-models/\"\r\n",
    "\r\n",
    "# p4m_net = torch.load(base_dir + 'upright-trained-p4m.pth')\r\n",
    "p4_net = torch.load(base_dir + 'upright-trained-p4.pth')\r\n",
    "conv_net = torch.load(base_dir + 'rot-trained-conv.pth')\r\n",
    "convu_net = torch.load(base_dir + 'upright-trained-conv.pth')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def test_accuracy(net):\r\n",
    "    correct = 0\r\n",
    "    total = 0\r\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in test_dataloader_rot:\r\n",
    "            images, labels = data[0].to(device), data[1].to(device)\r\n",
    "            # calculate outputs by running images through the network\r\n",
    "            outputs = net(images)\r\n",
    "            # the class with the highest energy is what we choose as prediction\r\n",
    "            _, predicted = torch.max(outputs.data, 1)\r\n",
    "            total += labels.size(0)\r\n",
    "            correct += (predicted == labels.to(device)).sum().item()\r\n",
    "\r\n",
    "    print('Accuracy of the ' + str(type(net)) + ' on the 10000 test images: %f %%' % (\r\n",
    "        100.0 * correct / total))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def class_labels(net):\r\n",
    "    # prepare to count predictions for each class\r\n",
    "    correct_pred = {num : 0 for num in range(0, 10)}\r\n",
    "    total_pred = {num : 0 for num in range(0, 10)}\r\n",
    "\r\n",
    "    # again no gradients needed\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in test_dataloader_rot:\r\n",
    "            images, labels = data[0].to(device), data[1].to(device)\r\n",
    "            outputs = net(images.to(device))\r\n",
    "            _, predictions = torch.max(outputs, 1)\r\n",
    "            # collect the correct predictions for each class\r\n",
    "            for label, prediction in zip(labels, predictions):\r\n",
    "                if label == prediction:\r\n",
    "                    correct_pred[label.item()] += 1\r\n",
    "                total_pred[label.item()] += 1\r\n",
    "\r\n",
    "    print('Classes for ' + str(type(net)))\r\n",
    "\r\n",
    "    # print accuracy for each class\r\n",
    "    for classname, correct_count in correct_pred.items():\r\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\r\n",
    "        print(\"Accuracy for num {} is: {:.1f} %\".format(classname,\r\n",
    "                                                   accuracy))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "test_accuracy(p4m_net)\r\n",
    "class_labels(p4m_net)\r\n",
    "\r\n",
    "test_accuracy(p4_net)\r\n",
    "class_labels(p4_net)\r\n",
    "\r\n",
    "test_accuracy(conv_net)\r\n",
    "class_labels(conv_net)\r\n",
    "\r\n",
    "test_accuracy(convu_net)\r\n",
    "class_labels(convu_net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the <class 'p4m_conv.P4MNet'> on the 10000 test images: 97.240000 %\n",
      "Classes for <class 'p4m_conv.P4MNet'>\n",
      "Accuracy for num 0 is: 97.3 %\n",
      "Accuracy for num 1 is: 98.8 %\n",
      "Accuracy for num 2 is: 96.3 %\n",
      "Accuracy for num 3 is: 98.5 %\n",
      "Accuracy for num 4 is: 96.9 %\n",
      "Accuracy for num 5 is: 94.6 %\n",
      "Accuracy for num 6 is: 96.5 %\n",
      "Accuracy for num 7 is: 98.4 %\n",
      "Accuracy for num 8 is: 96.5 %\n",
      "Accuracy for num 9 is: 97.9 %\n",
      "Accuracy of the <class 'p4_conv.P4Net'> on the 10000 test images: 97.400000 %\n",
      "Classes for <class 'p4_conv.P4Net'>\n",
      "Accuracy for num 0 is: 99.4 %\n",
      "Accuracy for num 1 is: 99.5 %\n",
      "Accuracy for num 2 is: 95.9 %\n",
      "Accuracy for num 3 is: 99.0 %\n",
      "Accuracy for num 4 is: 97.1 %\n",
      "Accuracy for num 5 is: 96.1 %\n",
      "Accuracy for num 6 is: 95.8 %\n",
      "Accuracy for num 7 is: 96.1 %\n",
      "Accuracy for num 8 is: 97.9 %\n",
      "Accuracy for num 9 is: 96.7 %\n",
      "Accuracy of the <class 'z2_conv.ConvNet'> on the 10000 test images: 93.550000 %\n",
      "Classes for <class 'z2_conv.ConvNet'>\n",
      "Accuracy for num 0 is: 98.3 %\n",
      "Accuracy for num 1 is: 98.6 %\n",
      "Accuracy for num 2 is: 88.3 %\n",
      "Accuracy for num 3 is: 96.2 %\n",
      "Accuracy for num 4 is: 94.8 %\n",
      "Accuracy for num 5 is: 84.0 %\n",
      "Accuracy for num 6 is: 91.1 %\n",
      "Accuracy for num 7 is: 93.1 %\n",
      "Accuracy for num 8 is: 94.1 %\n",
      "Accuracy for num 9 is: 95.3 %\n",
      "Accuracy of the <class 'z2_conv.ConvNet'> on the 10000 test images: 32.180000 %\n",
      "Classes for <class 'z2_conv.ConvNet'>\n",
      "Accuracy for num 0 is: 79.3 %\n",
      "Accuracy for num 1 is: 50.3 %\n",
      "Accuracy for num 2 is: 12.9 %\n",
      "Accuracy for num 3 is: 23.2 %\n",
      "Accuracy for num 4 is: 32.3 %\n",
      "Accuracy for num 5 is: 15.9 %\n",
      "Accuracy for num 6 is: 16.1 %\n",
      "Accuracy for num 7 is: 24.9 %\n",
      "Accuracy for num 8 is: 48.6 %\n",
      "Accuracy for num 9 is: 14.5 %\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f665fd8ed1386b9605bd6d1d95408943e5396eca0f77e44c2585e6a9876cbe3c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('reu-code': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}