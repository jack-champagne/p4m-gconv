{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Jupyter notebook\r\n",
    "\r\n",
    "This notebook will load nets as defined int the imported python modules with certain preformance characteristics for comparison.\r\n",
    "This file will also contain the tensorboard that helps visualize the models accuracy over time and the training process.\r\n",
    "\r\n",
    "Components:\r\n",
    "- initialize training parameters and fetch dataset (including RotMNIST dataset)\r\n",
    "- compare model attributes (such as total parameters and structure)\r\n",
    "- define hyperparameters\r\n",
    "- create tensorboard and set up preformance graphs\r\n",
    "- compare model training and preformance under different conditions\r\n",
    "- save models to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports for pytorch and dataset\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "from RotMNIST import RotMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define dataloaders\r\n",
    "### Instatiate RotMNIST and verify behaviour below with the dataloaders\r\n",
    "dataset_rot = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=True\r\n",
    ")\r\n",
    "\r\n",
    "test_dataset_rot = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=False,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=True\r\n",
    ")\r\n",
    "\r\n",
    "dataset_upright = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=False,\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P4MNet(\n",
      "  (conv1): P4MConvZ2()\n",
      "  (conv2): P4MConvP4M()\n",
      "  (conv3): P4MConvP4M()\n",
      "  (fc1): Linear(in_features=32, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n",
      "P4M Trainable Params: 122244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Import different networks from python files\r\n",
    "# TODO: Uncomment other networks and import\r\n",
    "from p4m_conv import P4MNet\r\n",
    "# from p4_conv import P4Net\r\n",
    "# from z2_conv import ConvNet\r\n",
    "\r\n",
    "p4m_net = P4MNet()\r\n",
    "# p4_net = P4Net()\r\n",
    "# conv_net = ConvNet()\r\n",
    "\r\n",
    "p4m_total_params = sum(p.numel() for p in p4m_net.parameters() if p.requires_grad)\r\n",
    "# p4_total_params = sum(p.numel() for p in p4_net.parameters() if p.requires_grad)\r\n",
    "# z2_total_params = sum(p.numel() for p in conv_net.parameters() if p.requires_grad)\r\n",
    "\r\n",
    "print(p4m_net)\r\n",
    "print(\"P4M Trainable Params: \" + str(p4m_total_params) + '\\n')\r\n",
    "\r\n",
    "# print(p4_net)\r\n",
    "# print(\"P4 Trainable Params: \" + str(p4_total_params) + '\\n')\r\n",
    "\r\n",
    "# print(conv_net)\r\n",
    "# print(\"Conv Trainable Params: \" + str(z2_total_params) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\r\n",
    "learning_rate = 0.001\r\n",
    "batch_size = 64\r\n",
    "epochs = 25\r\n",
    "\r\n",
    "### Objectives/Loss fn\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "### Dataloaders\r\n",
    "train_dataloader_rot = DataLoader(dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "test_dataloader_rot = DataLoader(test_dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "train_dataloader_upright = DataLoader(dataset_upright, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tensorboard helpers\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# helper function to show an image (copied from https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\r\n",
    "# (used in the `plot_classes_preds` function below)\r\n",
    "def imshow(img):\r\n",
    "    img = img.mean(dim=0)\r\n",
    "    img = img / 2 + 0.5     # unnormalize\r\n",
    "    npimg = img.numpy()\r\n",
    "    # plt.imshow(npimg, cmap=\"Greys\")\r\n",
    "\r\n",
    "### Tensorboard\r\n",
    "import torch.utils.tensorboard\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "writer = SummaryWriter('runs/p4m_mnist_1')\r\n",
    "\r\n",
    "# Get grid of training images\r\n",
    "dataiter = iter(train_dataloader_upright)\r\n",
    "images, labels = dataiter.next()\r\n",
    "img_grid = torchvision.utils.make_grid(images)\r\n",
    "imshow(img_grid)\r\n",
    "\r\n",
    "# To tensorboard\r\n",
    "writer.add_image('Training Batch', img_grid)\r\n",
    "\r\n",
    "writer.add_graph(p4m_net, images)\r\n",
    "writer.close()\r\n",
    "\r\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\r\n",
    "# helper function\r\n",
    "def select_n_random(data, labels, n=100):\r\n",
    "    '''\r\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\r\n",
    "    '''\r\n",
    "    assert len(data) == len(labels)\r\n",
    "\r\n",
    "    perm = torch.randperm(len(data))\r\n",
    "    return data[perm][:n], labels[perm][:n]\r\n",
    "\r\n",
    "# select random images and their target indices\r\n",
    "images, labels = select_n_random(dataset_upright.data, dataset_upright.targets)\r\n",
    "\r\n",
    "# get the class labels for each image\r\n",
    "class_labels = [classes[lab] for lab in labels]\r\n",
    "\r\n",
    "# log embeddings\r\n",
    "features = images.view(-1, 28 * 28)\r\n",
    "writer.add_embedding(features,\r\n",
    "                    metadata=class_labels,\r\n",
    "                    label_img=images.unsqueeze(1))\r\n",
    "writer.close()\r\n",
    "\r\n",
    "# helper functions\r\n",
    "\r\n",
    "def images_to_probs(net, images):\r\n",
    "    '''\r\n",
    "    Generates predictions and corresponding probabilities from a trained\r\n",
    "    network and a list of images\r\n",
    "    '''\r\n",
    "    output = net(images)\r\n",
    "    # convert output probabilities to predicted class\r\n",
    "    _, preds_tensor = torch.max(output, 1)\r\n",
    "    preds = np.squeeze(preds_tensor.numpy())\r\n",
    "    return preds, [torch.nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\r\n",
    "\r\n",
    "\r\n",
    "def plot_classes_preds(net, images, labels):\r\n",
    "    '''\r\n",
    "    Generates matplotlib Figure using a trained network, along with images\r\n",
    "    and labels from a batch, that shows the network's top prediction along\r\n",
    "    with its probability, alongside the actual label, coloring this\r\n",
    "    information based on whether the prediction was correct or not.\r\n",
    "    Uses the \"images_to_probs\" function.\r\n",
    "    '''\r\n",
    "    preds, probs = images_to_probs(net, images)\r\n",
    "    # plot the images in the batch, along with predicted and true labels\r\n",
    "    fig = plt.figure(figsize=(12, 48))\r\n",
    "    for idx in np.arange(4):\r\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\r\n",
    "        imshow(images[idx])\r\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\r\n",
    "            classes[preds[idx]],\r\n",
    "            probs[idx] * 100.0,\r\n",
    "            classes[labels[idx]]),\r\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\r\n",
    "    return fig\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\r\n",
    "    running_loss = 0.0\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        model.to(device)\r\n",
    "        # Compute prediction and loss for backprop\r\n",
    "        pred = model(X.to(device))\r\n",
    "        loss = loss_fn(pred, y.to(device))\r\n",
    "\r\n",
    "        # Backpropagation by setting grad to zero, calculating using backprop engine and stepping (using learning rate)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        running_loss += loss.item()\r\n",
    "\r\n",
    "        if batch % 100 == 99:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\r\n",
    "\r\n",
    "            writer.add_scalar('training loss', running_loss / 100, cur_epoch * len(dataloader) + batch)\r\n",
    "            writer.add_figure('predictions vs actuals', plot_classes_preds(model.to('cpu'), X, labels), global_step=cur_epoch * len(dataloader) + batch)\r\n",
    "            running_loss = 0.0\r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    model.to(device)\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "    \r\n",
    "    # No gradient on training data (faster computation and no optimization happening here anyway)\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, y in dataloader:\r\n",
    "            pred = model(X.to(device))\r\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\r\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\r\n",
    "\r\n",
    "    test_loss /= size\r\n",
    "    correct /= size\r\n",
    "    \r\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.278352  [ 6336/60000]\n",
      "loss: 1.997343  [12736/60000]\n",
      "loss: 1.132336  [19136/60000]\n",
      "loss: 0.958909  [25536/60000]\n",
      "loss: 0.654748  [31936/60000]\n",
      "loss: 0.648335  [38336/60000]\n",
      "loss: 0.760683  [44736/60000]\n",
      "loss: 0.709569  [51136/60000]\n",
      "loss: 0.501799  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.006629 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.284434  [ 6336/60000]\n",
      "loss: 0.339571  [12736/60000]\n",
      "loss: 0.398244  [19136/60000]\n",
      "loss: 0.274706  [25536/60000]\n",
      "loss: 0.285697  [31936/60000]\n",
      "loss: 0.118139  [38336/60000]\n",
      "loss: 0.202080  [44736/60000]\n",
      "loss: 0.290453  [51136/60000]\n",
      "loss: 0.212414  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.003547 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.363411  [ 6336/60000]\n",
      "loss: 0.226567  [12736/60000]\n",
      "loss: 0.298706  [19136/60000]\n",
      "loss: 0.094547  [25536/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a696afbc5677>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcur_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader_upright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp4m_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader_rot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp4m_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Finished Training P4M Net'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c60d34e80c9b>\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Compute prediction and loss for backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Repos\\jack-champagne\\reu-code\\p4m-gconv\\p4m_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplane_group_spatial_max_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplane_group_spatial_max_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\groupy\\gconv\\pytorch_gconv\\splitgconv2d.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mtw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         tw_shape = (self.out_channels * self.output_stabilizer_size,\n\u001b[0;32m     69\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_channels\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_stabilizer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\groupy\\gconv\\pytorch_gconv\\splitgconv2d.py\u001b[0m in \u001b[0;36mtrans_filter\u001b[1;34m(w, inds)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrans_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0minds_reshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mw_indexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds_reshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds_reshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds_reshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     w_indexed = w_indexed.view(w_indexed.size()[0], w_indexed.size()[1],\n\u001b[0;32m     19\u001b[0m                                     inds.shape[0], inds.shape[1], inds.shape[2], inds.shape[3])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Upright training loop for p4m_net\r\n",
    "optimizer = torch.optim.SGD(p4m_net.parameters(), lr=learning_rate, momentum=0.9)\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "for t in range(epochs):\r\n",
    "    cur_epoch = t\r\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "    train_loop(train_dataloader_upright, p4m_net, loss_fn, optimizer)\r\n",
    "    test_loop(test_dataloader_rot, p4m_net, loss_fn)\r\n",
    "print('Finished Training P4M Net')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparisons\r\n",
    "\r\n",
    "There are a few comparisons between the models to be made here. Here is a list of the following that I log\r\n",
    "- Model accuracy on 10000 test images\r\n",
    "- Model accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Upright training loop for p4_net\r\n",
    "# optimizer = torch.optim.SGD(p4_net.parameters(), lr=learning_rate, momentum=0.9)\r\n",
    "# for t in range(epochs):\r\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "#     train_loop(train_dataloader_upright, p4_net, loss_fn, optimizer)\r\n",
    "#     test_loop(test_dataloader_rot, p4_net, loss_fn)\r\n",
    "# print('Finished Training P4 Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Upright training loop for conv_net\r\n",
    "# optimizer = torch.optim.SGD(conv_net.parameters(), lr=learning_rate, momentum=0.9)\r\n",
    "# for t in range(epochs):\r\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "#     train_loop(train_dataloader_upright, conv_net, loss_fn, optimizer)\r\n",
    "#     test_loop(test_dataloader_rot, conv_net, loss_fn)\r\n",
    "# print('Finished Training Conv Net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.100000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\r\n",
    "total = 0\r\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\r\n",
    "with torch.no_grad():\r\n",
    "    for data in test_dataloader_rot:\r\n",
    "        images, labels = data[0].to(device), data[1].to(device)\r\n",
    "        # calculate outputs by running images through the network\r\n",
    "        outputs = p4m_net(images)\r\n",
    "        # the class with the highest energy is what we choose as prediction\r\n",
    "        _, predicted = torch.max(outputs.data, 1)\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels.to(device)).sum().item()\r\n",
    "\r\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\r\n",
    "    100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for num 0 is: 98.6 %\n",
      "Accuracy for num 1 is: 98.6 %\n",
      "Accuracy for num 2 is: 89.2 %\n",
      "Accuracy for num 3 is: 95.5 %\n",
      "Accuracy for num 4 is: 95.8 %\n",
      "Accuracy for num 5 is: 92.3 %\n",
      "Accuracy for num 6 is: 91.6 %\n",
      "Accuracy for num 7 is: 98.1 %\n",
      "Accuracy for num 8 is: 94.7 %\n",
      "Accuracy for num 9 is: 95.8 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\r\n",
    "correct_pred = {num : 0 for num in range(0, 10)}\r\n",
    "total_pred = {num : 0 for num in range(0, 10)}\r\n",
    "\r\n",
    "# again no gradients needed\r\n",
    "with torch.no_grad():\r\n",
    "    for data in test_dataloader_rot:\r\n",
    "        images, labels = data[0].to(device), data[1].to(device)\r\n",
    "        outputs = p4m_net(images.to(device))\r\n",
    "        _, predictions = torch.max(outputs, 1)\r\n",
    "        # collect the correct predictions for each class\r\n",
    "        for label, prediction in zip(labels, predictions):\r\n",
    "            if label == prediction:\r\n",
    "                correct_pred[label.item()] += 1\r\n",
    "            total_pred[label.item()] += 1\r\n",
    "\r\n",
    "\r\n",
    "# print accuracy for each class\r\n",
    "for classname, correct_count in correct_pred.items():\r\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\r\n",
    "    print(\"Accuracy for num {} is: {:.1f} %\".format(classname,\r\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b78303bc53f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m### New instance of CNN for testing on MNIST and RotMNIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Net' is not defined"
     ]
    }
   ],
   "source": [
    "### Imports\n",
    "from RotMNIST import RotMNIST\n",
    "\n",
    "### New instance of CNN for testing on MNIST and RotMNIST\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "### Hyperparameters\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "# Optimizers and Objectives\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "### Datasets and Dataloaders\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((32,32))]\n",
    "     )\n",
    "dataset_rot = RotMNIST(\n",
    "    root = 'data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    rotation_mirroring=True\n",
    ")\n",
    "\n",
    "test_dataset_rot = RotMNIST(\n",
    "    root = 'data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    rotation_mirroring=True\n",
    ")\n",
    "\n",
    "dataset_upright = RotMNIST(\n",
    "    root = 'data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    rotation_mirroring=False,\n",
    ")\n",
    "\n",
    "### Instantiate dataloader for RotMNIST and get batches\n",
    "train_dataloader_rot = torch.utils.data.DataLoader(dataset_rot, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_rot = torch.utils.data.DataLoader(test_dataset_rot, batch_size=batch_size, shuffle=True)\n",
    "train_dataloader_upright = torch.utils.data.DataLoader(dataset_upright, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305217  [    0/60000]\n",
      "loss: 2.296696  [ 6400/60000]\n",
      "loss: 2.293112  [12800/60000]\n",
      "loss: 2.294113  [19200/60000]\n",
      "loss: 2.295065  [25600/60000]\n",
      "loss: 2.278071  [32000/60000]\n",
      "loss: 2.265457  [38400/60000]\n",
      "loss: 2.223956  [44800/60000]\n",
      "loss: 2.120625  [51200/60000]\n",
      "loss: 1.505598  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 27.4%, Avg loss: 0.036824 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.200164  [    0/60000]\n",
      "loss: 0.745467  [ 6400/60000]\n",
      "loss: 0.519635  [12800/60000]\n",
      "loss: 0.599424  [19200/60000]\n",
      "loss: 0.524786  [25600/60000]\n",
      "loss: 0.370485  [32000/60000]\n",
      "loss: 0.350423  [38400/60000]\n",
      "loss: 0.361508  [44800/60000]\n",
      "loss: 0.539175  [51200/60000]\n",
      "loss: 0.148360  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 29.4%, Avg loss: 0.072286 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.197427  [    0/60000]\n",
      "loss: 0.248409  [ 6400/60000]\n",
      "loss: 0.179247  [12800/60000]\n",
      "loss: 0.343159  [19200/60000]\n",
      "loss: 0.411106  [25600/60000]\n",
      "loss: 0.194376  [32000/60000]\n",
      "loss: 0.148326  [38400/60000]\n",
      "loss: 0.167673  [44800/60000]\n",
      "loss: 0.293181  [51200/60000]\n",
      "loss: 0.363734  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 30.4%, Avg loss: 0.069705 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.089621  [    0/60000]\n",
      "loss: 0.043389  [ 6400/60000]\n",
      "loss: 0.184873  [12800/60000]\n",
      "loss: 0.201435  [19200/60000]\n",
      "loss: 0.183594  [25600/60000]\n",
      "loss: 0.148242  [32000/60000]\n",
      "loss: 0.233676  [38400/60000]\n",
      "loss: 0.123976  [44800/60000]\n",
      "loss: 0.065899  [51200/60000]\n",
      "loss: 0.219382  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.8%, Avg loss: 0.070319 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.322948  [    0/60000]\n",
      "loss: 0.080944  [ 6400/60000]\n",
      "loss: 0.181632  [12800/60000]\n",
      "loss: 0.103492  [19200/60000]\n",
      "loss: 0.089976  [25600/60000]\n",
      "loss: 0.032953  [32000/60000]\n",
      "loss: 0.117819  [38400/60000]\n",
      "loss: 0.196212  [44800/60000]\n",
      "loss: 0.050344  [51200/60000]\n",
      "loss: 0.181368  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 0.074017 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.172528  [    0/60000]\n",
      "loss: 0.190052  [ 6400/60000]\n",
      "loss: 0.097227  [12800/60000]\n",
      "loss: 0.067256  [19200/60000]\n",
      "loss: 0.141679  [25600/60000]\n",
      "loss: 0.071160  [32000/60000]\n",
      "loss: 0.222742  [38400/60000]\n",
      "loss: 0.095579  [44800/60000]\n",
      "loss: 0.147064  [51200/60000]\n",
      "loss: 0.099345  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.8%, Avg loss: 0.076063 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.040330  [    0/60000]\n",
      "loss: 0.033457  [ 6400/60000]\n",
      "loss: 0.056751  [12800/60000]\n",
      "loss: 0.085987  [19200/60000]\n",
      "loss: 0.026828  [25600/60000]\n",
      "loss: 0.138698  [32000/60000]\n",
      "loss: 0.130037  [38400/60000]\n",
      "loss: 0.063688  [44800/60000]\n",
      "loss: 0.144923  [51200/60000]\n",
      "loss: 0.079728  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 30.7%, Avg loss: 0.082584 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.072738  [    0/60000]\n",
      "loss: 0.088002  [ 6400/60000]\n",
      "loss: 0.186480  [12800/60000]\n",
      "loss: 0.136382  [19200/60000]\n",
      "loss: 0.051573  [25600/60000]\n",
      "loss: 0.161180  [32000/60000]\n",
      "loss: 0.029035  [38400/60000]\n",
      "loss: 0.023528  [44800/60000]\n",
      "loss: 0.076421  [51200/60000]\n",
      "loss: 0.145663  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 30.1%, Avg loss: 0.086251 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.040346  [    0/60000]\n",
      "loss: 0.089249  [ 6400/60000]\n",
      "loss: 0.160347  [12800/60000]\n",
      "loss: 0.126092  [19200/60000]\n",
      "loss: 0.085672  [25600/60000]\n",
      "loss: 0.048149  [32000/60000]\n",
      "loss: 0.038345  [38400/60000]\n",
      "loss: 0.154326  [44800/60000]\n",
      "loss: 0.078521  [51200/60000]\n",
      "loss: 0.080353  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.5%, Avg loss: 0.084282 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.033656  [    0/60000]\n",
      "loss: 0.145453  [ 6400/60000]\n",
      "loss: 0.031092  [12800/60000]\n",
      "loss: 0.042179  [19200/60000]\n",
      "loss: 0.029116  [25600/60000]\n",
      "loss: 0.073225  [32000/60000]\n",
      "loss: 0.087100  [38400/60000]\n",
      "loss: 0.032982  [44800/60000]\n",
      "loss: 0.073794  [51200/60000]\n",
      "loss: 0.052813  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.088775 \n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader_rot, net, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader_rot, net, loss_fn)\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f665fd8ed1386b9605bd6d1d95408943e5396eca0f77e44c2585e6a9876cbe3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('reu-code': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}