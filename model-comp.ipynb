{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Jupyter notebook\r\n",
    "\r\n",
    "This notebook will load nets as defined int the imported python modules with certain preformance characteristics for comparison.\r\n",
    "This file will also contain the tensorboard that helps visualize the models accuracy over time and the training process.\r\n",
    "\r\n",
    "Components:\r\n",
    "- initialize training parameters and fetch dataset (including RotMNIST dataset)\r\n",
    "- compare model attributes (such as total parameters and structure)\r\n",
    "- define hyperparameters\r\n",
    "- create tensorboard and set up preformance graphs\r\n",
    "- compare model training and preformance under different conditions\r\n",
    "- save models to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports for pytorch and dataset\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "from RotMNIST import RotMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "### Define dataloaders\r\n",
    "### Instatiate RotMNIST and verify behaviour below with the dataloaders\r\n",
    "dataset_rot = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=True\r\n",
    ")\r\n",
    "\r\n",
    "test_dataset_rot = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=False,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=True\r\n",
    ")\r\n",
    "\r\n",
    "dataset_upright = RotMNIST(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=torchvision.transforms.Compose(\r\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\r\n",
    "    ),\r\n",
    "    rotation_mirroring=False,\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P4MNet(\n",
      "  (conv1): P4MConvZ2()\n",
      "  (conv2): P4MConvP4M()\n",
      "  (conv3): P4MConvP4M()\n",
      "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "P4Net(\n",
      "  (conv1): P4MConvZ2()\n",
      "  (conv2): P4MConvP4M()\n",
      "  (conv3): P4MConvP4M()\n",
      "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "ConvNet(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=184, bias=True)\n",
      "  (fc2): Linear(in_features=184, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "P4M  --\tTrainable Params: 128954\n",
      "P4   --\tTrainable Params: 128954\n",
      "Conv --\tTrainable Params: 119598\n"
     ]
    }
   ],
   "source": [
    "### Import different networks from python files\r\n",
    "# TODO: Uncomment other networks and import\r\n",
    "from p4m_conv import P4MNet\r\n",
    "from p4_conv import P4Net\r\n",
    "from z2_conv import ConvNet\r\n",
    "\r\n",
    "p4m_net = P4MNet()\r\n",
    "p4_net = P4Net()\r\n",
    "conv_net = ConvNet()\r\n",
    "\r\n",
    "p4m_total_params = sum(p.numel() for p in p4m_net.parameters() if p.requires_grad)\r\n",
    "p4_total_params = sum(p.numel() for p in p4_net.parameters() if p.requires_grad)\r\n",
    "z2_total_params = sum(p.numel() for p in conv_net.parameters() if p.requires_grad)\r\n",
    "\r\n",
    "print(p4m_net)\r\n",
    "print(p4_net)\r\n",
    "print(conv_net)\r\n",
    "\r\n",
    "print(\"P4M  --\\tTrainable Params: \" + str(p4m_total_params))\r\n",
    "print(\"P4   --\\tTrainable Params: \" + str(p4_total_params))\r\n",
    "print(\"Conv --\\tTrainable Params: \" + str(z2_total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\r\n",
    "learning_rate = 0.001\r\n",
    "batch_size = 64\r\n",
    "epochs = 25\r\n",
    "\r\n",
    "### Objectives/Loss fn\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "### Dataloaders\r\n",
    "train_dataloader_rot = DataLoader(dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "test_dataloader_rot = DataLoader(test_dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "train_dataloader_upright = DataLoader(dataset_upright, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tensorboard helpers\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# helper function to show an image (copied from https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\r\n",
    "# (used in the `plot_classes_preds` function below)\r\n",
    "def imshow(img):\r\n",
    "    img = img.mean(dim=0)\r\n",
    "    img = img / 2 + 0.5     # unnormalize\r\n",
    "    npimg = img.numpy()\r\n",
    "    plt.imshow(npimg, cmap=\"Greys\")\r\n",
    "\r\n",
    "### Tensorboard\r\n",
    "import torch.utils.tensorboard\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "writer = SummaryWriter('runs/p4m_mnist_1')\r\n",
    "\r\n",
    "# Get grid of training images\r\n",
    "dataiter = iter(train_dataloader_upright)\r\n",
    "images, labels = dataiter.next()\r\n",
    "img_grid = torchvision.utils.make_grid(images)\r\n",
    "imshow(img_grid)\r\n",
    "\r\n",
    "# To tensorboard\r\n",
    "writer.add_image('Training Batch', img_grid)\r\n",
    "\r\n",
    "writer.add_graph(p4m_net, images)\r\n",
    "writer.close()\r\n",
    "\r\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\r\n",
    "# helper function\r\n",
    "def select_n_random(data, labels, n=100):\r\n",
    "    '''\r\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\r\n",
    "    '''\r\n",
    "    assert len(data) == len(labels)\r\n",
    "\r\n",
    "    perm = torch.randperm(len(data))\r\n",
    "    return data[perm][:n], labels[perm][:n]\r\n",
    "\r\n",
    "# select random images and their target indices\r\n",
    "images, labels = select_n_random(dataset_upright.data, dataset_upright.targets)\r\n",
    "\r\n",
    "# get the class labels for each image\r\n",
    "class_labels = [classes[lab] for lab in labels]\r\n",
    "\r\n",
    "# log embeddings\r\n",
    "features = images.view(-1, 28 * 28)\r\n",
    "writer.add_embedding(features,\r\n",
    "                    metadata=class_labels,\r\n",
    "                    label_img=images.unsqueeze(1))\r\n",
    "writer.close()\r\n",
    "\r\n",
    "# helper functions\r\n",
    "\r\n",
    "def images_to_probs(net, images):\r\n",
    "    '''\r\n",
    "    Generates predictions and corresponding probabilities from a trained\r\n",
    "    network and a list of images\r\n",
    "    '''\r\n",
    "    output = net(images)\r\n",
    "    # convert output probabilities to predicted class\r\n",
    "    _, preds_tensor = torch.max(output, 1)\r\n",
    "    preds = np.squeeze(preds_tensor.numpy())\r\n",
    "    return preds, [torch.nn.functional.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\r\n",
    "\r\n",
    "\r\n",
    "def plot_classes_preds(net, images, labels):\r\n",
    "    '''\r\n",
    "    Generates matplotlib Figure using a trained network, along with images\r\n",
    "    and labels from a batch, that shows the network's top prediction along\r\n",
    "    with its probability, alongside the actual label, coloring this\r\n",
    "    information based on whether the prediction was correct or not.\r\n",
    "    Uses the \"images_to_probs\" function.\r\n",
    "    '''\r\n",
    "    preds, probs = images_to_probs(net, images)\r\n",
    "    # plot the images in the batch, along with predicted and true labels\r\n",
    "    fig = plt.figure(figsize=(12, 48))\r\n",
    "    for idx in np.arange(4):\r\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\r\n",
    "        imshow(images[idx])\r\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\r\n",
    "            classes[preds[idx]],\r\n",
    "            probs[idx] * 100.0,\r\n",
    "            classes[labels[idx]]),\r\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\r\n",
    "    return fig\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, cur_epoch):\r\n",
    "    running_loss = 0.0\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        model.to(device)\r\n",
    "        # Compute prediction and loss for backprop\r\n",
    "        pred = model(X.to(device))\r\n",
    "        loss = loss_fn(pred, y.to(device))\r\n",
    "\r\n",
    "        # Backpropagation by setting grad to zero, calculating using backprop engine and stepping (using learning rate)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        running_loss += loss.item()\r\n",
    "\r\n",
    "        if batch % 100 == 99:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\r\n",
    "\r\n",
    "            writer.add_scalar('training loss', running_loss / 100, cur_epoch * len(dataloader) + batch)\r\n",
    "            writer.add_figure('predictions vs actuals', plot_classes_preds(model.to('cpu'), X, labels), global_step=cur_epoch * len(dataloader) + batch)\r\n",
    "            running_loss = 0.0\r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    model.to(device)\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "    \r\n",
    "    # No gradient on training data (faster computation and no optimization happening here anyway)\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, y in dataloader:\r\n",
    "            pred = model(X.to(device))\r\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\r\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\r\n",
    "\r\n",
    "    test_loss /= size\r\n",
    "    correct /= size\r\n",
    "    \r\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train all networks\r\n",
    "def train_test_net(net, train_upright):\r\n",
    "    # Add option to train networks with RotMNIST\r\n",
    "    test_dataloader = train_dataloader_rot\r\n",
    "    if (train_upright):\r\n",
    "        test_dataloader = train_dataloader_upright\r\n",
    "\r\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\r\n",
    "    for t in range(epochs):\r\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "        train_loop(test_dataloader, net, loss_fn, optimizer, t)\r\n",
    "        test_loop(test_dataloader_rot, net, loss_fn)\r\n",
    "    print('Finished Training Net + ' + str(type(net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.227786  [ 6336/60000]\n",
      "loss: 1.717432  [12736/60000]\n",
      "loss: 1.009154  [19136/60000]\n",
      "loss: 1.060277  [25536/60000]\n",
      "loss: 0.527818  [31936/60000]\n",
      "loss: 0.814895  [38336/60000]\n",
      "loss: 0.470743  [44736/60000]\n",
      "loss: 0.434093  [51136/60000]\n",
      "loss: 0.506959  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.005566 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.436925  [ 6336/60000]\n",
      "loss: 0.276506  [12736/60000]\n",
      "loss: 0.201145  [19136/60000]\n",
      "loss: 0.287752  [25536/60000]\n",
      "loss: 0.241458  [31936/60000]\n",
      "loss: 0.176344  [38336/60000]\n",
      "loss: 0.189895  [44736/60000]\n",
      "loss: 0.173746  [51136/60000]\n",
      "loss: 0.147828  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.003338 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.206761  [ 6336/60000]\n",
      "loss: 0.230065  [12736/60000]\n",
      "loss: 0.107278  [19136/60000]\n",
      "loss: 0.307148  [25536/60000]\n",
      "loss: 0.122575  [31936/60000]\n",
      "loss: 0.206051  [38336/60000]\n",
      "loss: 0.149772  [44736/60000]\n",
      "loss: 0.184279  [51136/60000]\n",
      "loss: 0.178045  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.002487 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.191608  [ 6336/60000]\n",
      "loss: 0.260677  [12736/60000]\n",
      "loss: 0.142490  [19136/60000]\n",
      "loss: 0.087379  [25536/60000]\n",
      "loss: 0.034783  [31936/60000]\n",
      "loss: 0.164374  [38336/60000]\n",
      "loss: 0.066246  [44736/60000]\n",
      "loss: 0.207720  [51136/60000]\n",
      "loss: 0.164809  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002479 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.092427  [ 6336/60000]\n",
      "loss: 0.184687  [12736/60000]\n",
      "loss: 0.121136  [19136/60000]\n",
      "loss: 0.118896  [25536/60000]\n",
      "loss: 0.194735  [31936/60000]\n",
      "loss: 0.106515  [38336/60000]\n",
      "loss: 0.028318  [44736/60000]\n",
      "loss: 0.173510  [51136/60000]\n",
      "loss: 0.111096  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.002035 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.168776  [ 6336/60000]\n",
      "loss: 0.078664  [12736/60000]\n",
      "loss: 0.080227  [19136/60000]\n",
      "loss: 0.035605  [25536/60000]\n",
      "loss: 0.119625  [31936/60000]\n",
      "loss: 0.049234  [38336/60000]\n",
      "loss: 0.158811  [44736/60000]\n",
      "loss: 0.306619  [51136/60000]\n",
      "loss: 0.089191  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002005 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.089248  [ 6336/60000]\n",
      "loss: 0.071793  [12736/60000]\n",
      "loss: 0.125569  [19136/60000]\n",
      "loss: 0.059427  [25536/60000]\n",
      "loss: 0.044446  [31936/60000]\n",
      "loss: 0.062256  [38336/60000]\n",
      "loss: 0.278264  [44736/60000]\n",
      "loss: 0.113825  [51136/60000]\n",
      "loss: 0.068594  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.001635 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.043997  [ 6336/60000]\n",
      "loss: 0.124530  [12736/60000]\n",
      "loss: 0.057261  [19136/60000]\n",
      "loss: 0.027452  [25536/60000]\n",
      "loss: 0.145472  [31936/60000]\n",
      "loss: 0.108881  [38336/60000]\n",
      "loss: 0.059822  [44736/60000]\n",
      "loss: 0.111030  [51136/60000]\n",
      "loss: 0.131421  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.001784 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.122498  [ 6336/60000]\n",
      "loss: 0.012128  [12736/60000]\n",
      "loss: 0.079354  [19136/60000]\n",
      "loss: 0.111751  [25536/60000]\n",
      "loss: 0.162732  [31936/60000]\n",
      "loss: 0.077265  [38336/60000]\n",
      "loss: 0.129679  [44736/60000]\n",
      "loss: 0.107038  [51136/60000]\n",
      "loss: 0.039100  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.001693 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.018103  [ 6336/60000]\n",
      "loss: 0.191783  [12736/60000]\n",
      "loss: 0.117469  [19136/60000]\n",
      "loss: 0.031035  [25536/60000]\n",
      "loss: 0.022241  [31936/60000]\n",
      "loss: 0.022145  [38336/60000]\n",
      "loss: 0.081585  [44736/60000]\n",
      "loss: 0.118230  [51136/60000]\n",
      "loss: 0.065400  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.001592 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.024765  [ 6336/60000]\n",
      "loss: 0.088438  [12736/60000]\n",
      "loss: 0.064284  [19136/60000]\n",
      "loss: 0.004789  [25536/60000]\n",
      "loss: 0.015045  [31936/60000]\n",
      "loss: 0.043934  [38336/60000]\n",
      "loss: 0.021092  [44736/60000]\n",
      "loss: 0.127053  [51136/60000]\n",
      "loss: 0.076303  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.001739 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.163386  [ 6336/60000]\n",
      "loss: 0.072919  [12736/60000]\n",
      "loss: 0.089763  [19136/60000]\n",
      "loss: 0.045834  [25536/60000]\n",
      "loss: 0.033723  [31936/60000]\n",
      "loss: 0.055825  [38336/60000]\n",
      "loss: 0.086567  [44736/60000]\n",
      "loss: 0.043102  [51136/60000]\n",
      "loss: 0.041786  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001470 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.120530  [ 6336/60000]\n",
      "loss: 0.021576  [12736/60000]\n",
      "loss: 0.061597  [19136/60000]\n",
      "loss: 0.039623  [25536/60000]\n",
      "loss: 0.004525  [31936/60000]\n",
      "loss: 0.098807  [38336/60000]\n",
      "loss: 0.132371  [44736/60000]\n",
      "loss: 0.124124  [51136/60000]\n",
      "loss: 0.081987  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.001595 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.019081  [ 6336/60000]\n",
      "loss: 0.056128  [12736/60000]\n",
      "loss: 0.028930  [19136/60000]\n",
      "loss: 0.098377  [25536/60000]\n",
      "loss: 0.037923  [31936/60000]\n",
      "loss: 0.005376  [38336/60000]\n",
      "loss: 0.096349  [44736/60000]\n",
      "loss: 0.036450  [51136/60000]\n",
      "loss: 0.065779  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.001359 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.137333  [ 6336/60000]\n",
      "loss: 0.051445  [12736/60000]\n",
      "loss: 0.001272  [19136/60000]\n",
      "loss: 0.062347  [25536/60000]\n",
      "loss: 0.008467  [31936/60000]\n",
      "loss: 0.064176  [38336/60000]\n",
      "loss: 0.023276  [44736/60000]\n",
      "loss: 0.068853  [51136/60000]\n",
      "loss: 0.075696  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.001506 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.091780  [ 6336/60000]\n",
      "loss: 0.013427  [12736/60000]\n",
      "loss: 0.035527  [19136/60000]\n",
      "loss: 0.073431  [25536/60000]\n",
      "loss: 0.015931  [31936/60000]\n",
      "loss: 0.012110  [38336/60000]\n",
      "loss: 0.013668  [44736/60000]\n",
      "loss: 0.025041  [51136/60000]\n",
      "loss: 0.094420  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001572 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.005736  [ 6336/60000]\n",
      "loss: 0.008395  [12736/60000]\n",
      "loss: 0.013566  [19136/60000]\n",
      "loss: 0.044421  [25536/60000]\n",
      "loss: 0.022300  [31936/60000]\n",
      "loss: 0.047292  [38336/60000]\n",
      "loss: 0.001804  [44736/60000]\n",
      "loss: 0.075419  [51136/60000]\n",
      "loss: 0.177753  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001564 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.099136  [ 6336/60000]\n",
      "loss: 0.079025  [12736/60000]\n",
      "loss: 0.117661  [19136/60000]\n",
      "loss: 0.011575  [25536/60000]\n",
      "loss: 0.005810  [31936/60000]\n",
      "loss: 0.091845  [38336/60000]\n",
      "loss: 0.018172  [44736/60000]\n",
      "loss: 0.017063  [51136/60000]\n",
      "loss: 0.013881  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.001477 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.001734  [ 6336/60000]\n",
      "loss: 0.010319  [12736/60000]\n",
      "loss: 0.043196  [19136/60000]\n",
      "loss: 0.017092  [25536/60000]\n",
      "loss: 0.021468  [31936/60000]\n",
      "loss: 0.014110  [38336/60000]\n",
      "loss: 0.095693  [44736/60000]\n",
      "loss: 0.008035  [51136/60000]\n",
      "loss: 0.009905  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.001630 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.017530  [ 6336/60000]\n",
      "loss: 0.122177  [12736/60000]\n",
      "loss: 0.030707  [19136/60000]\n",
      "loss: 0.001781  [25536/60000]\n",
      "loss: 0.230328  [31936/60000]\n",
      "loss: 0.034528  [38336/60000]\n",
      "loss: 0.041925  [44736/60000]\n",
      "loss: 0.024699  [51136/60000]\n",
      "loss: 0.009685  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.001469 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.003300  [ 6336/60000]\n",
      "loss: 0.114916  [12736/60000]\n",
      "loss: 0.013825  [19136/60000]\n",
      "loss: 0.139962  [25536/60000]\n",
      "loss: 0.078829  [31936/60000]\n",
      "loss: 0.049239  [38336/60000]\n",
      "loss: 0.009756  [44736/60000]\n",
      "loss: 0.014071  [51136/60000]\n",
      "loss: 0.135981  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001614 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.019345  [ 6336/60000]\n",
      "loss: 0.056656  [12736/60000]\n",
      "loss: 0.002343  [19136/60000]\n",
      "loss: 0.026153  [25536/60000]\n",
      "loss: 0.009572  [31936/60000]\n",
      "loss: 0.094261  [38336/60000]\n",
      "loss: 0.045069  [44736/60000]\n",
      "loss: 0.049653  [51136/60000]\n",
      "loss: 0.020977  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.001438 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.137062  [ 6336/60000]\n",
      "loss: 0.008335  [12736/60000]\n",
      "loss: 0.017113  [19136/60000]\n",
      "loss: 0.014354  [25536/60000]\n",
      "loss: 0.150435  [31936/60000]\n",
      "loss: 0.025889  [38336/60000]\n",
      "loss: 0.006493  [44736/60000]\n",
      "loss: 0.000985  [51136/60000]\n",
      "loss: 0.011484  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.001511 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.018081  [ 6336/60000]\n",
      "loss: 0.061255  [12736/60000]\n",
      "loss: 0.070152  [19136/60000]\n",
      "loss: 0.023766  [25536/60000]\n",
      "loss: 0.005062  [31936/60000]\n",
      "loss: 0.039284  [38336/60000]\n",
      "loss: 0.012622  [44736/60000]\n",
      "loss: 0.034612  [51136/60000]\n",
      "loss: 0.006963  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001631 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.069036  [ 6336/60000]\n",
      "loss: 0.047710  [12736/60000]\n",
      "loss: 0.042719  [19136/60000]\n",
      "loss: 0.015715  [25536/60000]\n",
      "loss: 0.001817  [31936/60000]\n",
      "loss: 0.001429  [38336/60000]\n",
      "loss: 0.008639  [44736/60000]\n",
      "loss: 0.032186  [51136/60000]\n",
      "loss: 0.006918  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001523 \n",
      "\n",
      "Finished Training Net + <class 'p4m_conv.P4MNet'>\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.228917  [ 6336/60000]\n",
      "loss: 1.818784  [12736/60000]\n",
      "loss: 1.200590  [19136/60000]\n",
      "loss: 1.046174  [25536/60000]\n",
      "loss: 0.652070  [31936/60000]\n",
      "loss: 0.563370  [38336/60000]\n",
      "loss: 0.413960  [44736/60000]\n",
      "loss: 0.472240  [51136/60000]\n",
      "loss: 0.430137  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.005183 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.357941  [ 6336/60000]\n",
      "loss: 0.297413  [12736/60000]\n",
      "loss: 0.134390  [19136/60000]\n",
      "loss: 0.485098  [25536/60000]\n",
      "loss: 0.206321  [31936/60000]\n",
      "loss: 0.328070  [38336/60000]\n",
      "loss: 0.278082  [44736/60000]\n",
      "loss: 0.388256  [51136/60000]\n",
      "loss: 0.124162  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.003647 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.139051  [ 6336/60000]\n",
      "loss: 0.125220  [12736/60000]\n",
      "loss: 0.426324  [19136/60000]\n",
      "loss: 0.107011  [25536/60000]\n",
      "loss: 0.211729  [31936/60000]\n",
      "loss: 0.145975  [38336/60000]\n",
      "loss: 0.181725  [44736/60000]\n",
      "loss: 0.157748  [51136/60000]\n",
      "loss: 0.104038  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.002481 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.102295  [ 6336/60000]\n",
      "loss: 0.136741  [12736/60000]\n",
      "loss: 0.080950  [19136/60000]\n",
      "loss: 0.103816  [25536/60000]\n",
      "loss: 0.120874  [31936/60000]\n",
      "loss: 0.372451  [38336/60000]\n",
      "loss: 0.221390  [44736/60000]\n",
      "loss: 0.084639  [51136/60000]\n",
      "loss: 0.025694  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002377 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.045554  [ 6336/60000]\n",
      "loss: 0.208095  [12736/60000]\n",
      "loss: 0.072332  [19136/60000]\n",
      "loss: 0.146880  [25536/60000]\n",
      "loss: 0.153669  [31936/60000]\n",
      "loss: 0.087386  [38336/60000]\n",
      "loss: 0.060637  [44736/60000]\n",
      "loss: 0.116413  [51136/60000]\n",
      "loss: 0.110673  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.001970 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.038154  [ 6336/60000]\n",
      "loss: 0.077691  [12736/60000]\n",
      "loss: 0.139332  [19136/60000]\n",
      "loss: 0.187901  [25536/60000]\n",
      "loss: 0.033033  [31936/60000]\n",
      "loss: 0.023930  [38336/60000]\n",
      "loss: 0.042247  [44736/60000]\n",
      "loss: 0.082886  [51136/60000]\n",
      "loss: 0.138439  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.001979 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.047146  [ 6336/60000]\n",
      "loss: 0.102116  [12736/60000]\n",
      "loss: 0.179477  [19136/60000]\n",
      "loss: 0.035919  [25536/60000]\n",
      "loss: 0.093736  [31936/60000]\n",
      "loss: 0.030009  [38336/60000]\n",
      "loss: 0.121820  [44736/60000]\n",
      "loss: 0.080577  [51136/60000]\n",
      "loss: 0.188487  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.001605 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.034251  [ 6336/60000]\n",
      "loss: 0.027246  [12736/60000]\n",
      "loss: 0.095935  [19136/60000]\n",
      "loss: 0.151982  [25536/60000]\n",
      "loss: 0.087078  [31936/60000]\n",
      "loss: 0.033324  [38336/60000]\n",
      "loss: 0.108946  [44736/60000]\n",
      "loss: 0.126163  [51136/60000]\n",
      "loss: 0.109422  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002048 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.106228  [ 6336/60000]\n",
      "loss: 0.193903  [12736/60000]\n",
      "loss: 0.032898  [19136/60000]\n",
      "loss: 0.031357  [25536/60000]\n",
      "loss: 0.112251  [31936/60000]\n",
      "loss: 0.036633  [38336/60000]\n",
      "loss: 0.071496  [44736/60000]\n",
      "loss: 0.061914  [51136/60000]\n",
      "loss: 0.142770  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.001577 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.017843  [ 6336/60000]\n",
      "loss: 0.022699  [12736/60000]\n",
      "loss: 0.053357  [19136/60000]\n",
      "loss: 0.034584  [25536/60000]\n",
      "loss: 0.096443  [31936/60000]\n",
      "loss: 0.069856  [38336/60000]\n",
      "loss: 0.022431  [44736/60000]\n",
      "loss: 0.030962  [51136/60000]\n",
      "loss: 0.046812  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.001458 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.033864  [ 6336/60000]\n",
      "loss: 0.113658  [12736/60000]\n",
      "loss: 0.039030  [19136/60000]\n",
      "loss: 0.043284  [25536/60000]\n",
      "loss: 0.007678  [31936/60000]\n",
      "loss: 0.032680  [38336/60000]\n",
      "loss: 0.014060  [44736/60000]\n",
      "loss: 0.047898  [51136/60000]\n",
      "loss: 0.135373  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.001548 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.106666  [ 6336/60000]\n",
      "loss: 0.113670  [12736/60000]\n",
      "loss: 0.072346  [19136/60000]\n",
      "loss: 0.052067  [25536/60000]\n",
      "loss: 0.073936  [31936/60000]\n",
      "loss: 0.077508  [38336/60000]\n",
      "loss: 0.098044  [44736/60000]\n",
      "loss: 0.023916  [51136/60000]\n",
      "loss: 0.067602  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.001821 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.168381  [ 6336/60000]\n",
      "loss: 0.112920  [12736/60000]\n",
      "loss: 0.067169  [19136/60000]\n",
      "loss: 0.039263  [25536/60000]\n",
      "loss: 0.087020  [31936/60000]\n",
      "loss: 0.055905  [38336/60000]\n",
      "loss: 0.033246  [44736/60000]\n",
      "loss: 0.019795  [51136/60000]\n",
      "loss: 0.007761  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001440 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.014319  [ 6336/60000]\n",
      "loss: 0.090884  [12736/60000]\n",
      "loss: 0.036399  [19136/60000]\n",
      "loss: 0.024981  [25536/60000]\n",
      "loss: 0.034330  [31936/60000]\n",
      "loss: 0.022901  [38336/60000]\n",
      "loss: 0.025026  [44736/60000]\n",
      "loss: 0.038674  [51136/60000]\n",
      "loss: 0.044917  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.001582 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.054234  [ 6336/60000]\n",
      "loss: 0.006563  [12736/60000]\n",
      "loss: 0.021951  [19136/60000]\n",
      "loss: 0.078124  [25536/60000]\n",
      "loss: 0.038598  [31936/60000]\n",
      "loss: 0.027613  [38336/60000]\n",
      "loss: 0.094957  [44736/60000]\n",
      "loss: 0.030864  [51136/60000]\n",
      "loss: 0.133532  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.001485 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.044441  [ 6336/60000]\n",
      "loss: 0.097240  [12736/60000]\n",
      "loss: 0.223953  [19136/60000]\n",
      "loss: 0.053750  [25536/60000]\n",
      "loss: 0.061892  [31936/60000]\n",
      "loss: 0.037103  [38336/60000]\n",
      "loss: 0.040464  [44736/60000]\n",
      "loss: 0.015889  [51136/60000]\n",
      "loss: 0.037049  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001564 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.070578  [ 6336/60000]\n",
      "loss: 0.038734  [12736/60000]\n",
      "loss: 0.004388  [19136/60000]\n",
      "loss: 0.041680  [25536/60000]\n",
      "loss: 0.051652  [31936/60000]\n",
      "loss: 0.007641  [38336/60000]\n",
      "loss: 0.016544  [44736/60000]\n",
      "loss: 0.004544  [51136/60000]\n",
      "loss: 0.026639  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001448 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.035394  [ 6336/60000]\n",
      "loss: 0.005277  [12736/60000]\n",
      "loss: 0.019773  [19136/60000]\n",
      "loss: 0.017686  [25536/60000]\n",
      "loss: 0.004556  [31936/60000]\n",
      "loss: 0.294066  [38336/60000]\n",
      "loss: 0.002631  [44736/60000]\n",
      "loss: 0.009313  [51136/60000]\n",
      "loss: 0.025184  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.001389 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.006532  [ 6336/60000]\n",
      "loss: 0.015402  [12736/60000]\n",
      "loss: 0.016365  [19136/60000]\n",
      "loss: 0.015766  [25536/60000]\n",
      "loss: 0.011575  [31936/60000]\n",
      "loss: 0.050284  [38336/60000]\n",
      "loss: 0.115223  [44736/60000]\n",
      "loss: 0.034062  [51136/60000]\n",
      "loss: 0.016539  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001497 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.021387  [ 6336/60000]\n",
      "loss: 0.016408  [12736/60000]\n",
      "loss: 0.060120  [19136/60000]\n",
      "loss: 0.047031  [25536/60000]\n",
      "loss: 0.203159  [31936/60000]\n",
      "loss: 0.020076  [38336/60000]\n",
      "loss: 0.084380  [44736/60000]\n",
      "loss: 0.008645  [51136/60000]\n",
      "loss: 0.019057  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.001487 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.031355  [ 6336/60000]\n",
      "loss: 0.051283  [12736/60000]\n",
      "loss: 0.000800  [19136/60000]\n",
      "loss: 0.017122  [25536/60000]\n",
      "loss: 0.054100  [31936/60000]\n",
      "loss: 0.000519  [38336/60000]\n",
      "loss: 0.063132  [44736/60000]\n",
      "loss: 0.071561  [51136/60000]\n",
      "loss: 0.054186  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.001674 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.010358  [ 6336/60000]\n",
      "loss: 0.022372  [12736/60000]\n",
      "loss: 0.055652  [19136/60000]\n",
      "loss: 0.016445  [25536/60000]\n",
      "loss: 0.036082  [31936/60000]\n",
      "loss: 0.061881  [38336/60000]\n",
      "loss: 0.010700  [44736/60000]\n",
      "loss: 0.053471  [51136/60000]\n",
      "loss: 0.047779  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.001474 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.039170  [ 6336/60000]\n",
      "loss: 0.003019  [12736/60000]\n",
      "loss: 0.040861  [19136/60000]\n",
      "loss: 0.019160  [25536/60000]\n",
      "loss: 0.028559  [31936/60000]\n",
      "loss: 0.004778  [38336/60000]\n",
      "loss: 0.002968  [44736/60000]\n",
      "loss: 0.012381  [51136/60000]\n",
      "loss: 0.032109  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.001304 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.007034  [ 6336/60000]\n",
      "loss: 0.029953  [12736/60000]\n",
      "loss: 0.012279  [19136/60000]\n",
      "loss: 0.007143  [25536/60000]\n",
      "loss: 0.033568  [31936/60000]\n",
      "loss: 0.005980  [38336/60000]\n",
      "loss: 0.008670  [44736/60000]\n",
      "loss: 0.030837  [51136/60000]\n",
      "loss: 0.000286  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.001501 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.006597  [ 6336/60000]\n",
      "loss: 0.026518  [12736/60000]\n",
      "loss: 0.015717  [19136/60000]\n",
      "loss: 0.018106  [25536/60000]\n",
      "loss: 0.002491  [31936/60000]\n",
      "loss: 0.092227  [38336/60000]\n",
      "loss: 0.005337  [44736/60000]\n",
      "loss: 0.025607  [51136/60000]\n",
      "loss: 0.002355  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.001506 \n",
      "\n",
      "Finished Training Net + <class 'p4_conv.P4Net'>\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300419  [ 6336/60000]\n",
      "loss: 2.296063  [12736/60000]\n",
      "loss: 2.302153  [19136/60000]\n",
      "loss: 2.295718  [25536/60000]\n",
      "loss: 2.289200  [31936/60000]\n",
      "loss: 2.283154  [38336/60000]\n",
      "loss: 2.285741  [44736/60000]\n",
      "loss: 2.265701  [51136/60000]\n",
      "loss: 2.276354  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 0.035289 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.215349  [ 6336/60000]\n",
      "loss: 2.093188  [12736/60000]\n",
      "loss: 1.818834  [19136/60000]\n",
      "loss: 1.709732  [25536/60000]\n",
      "loss: 1.402018  [31936/60000]\n",
      "loss: 1.568158  [38336/60000]\n",
      "loss: 1.290687  [44736/60000]\n",
      "loss: 1.028758  [51136/60000]\n",
      "loss: 1.094766  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.019551 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.227533  [ 6336/60000]\n",
      "loss: 1.002795  [12736/60000]\n",
      "loss: 1.220016  [19136/60000]\n",
      "loss: 1.133436  [25536/60000]\n",
      "loss: 1.442077  [31936/60000]\n",
      "loss: 1.089965  [38336/60000]\n",
      "loss: 0.985974  [44736/60000]\n",
      "loss: 1.109375  [51136/60000]\n",
      "loss: 1.012792  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.014993 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.713086  [ 6336/60000]\n",
      "loss: 0.883042  [12736/60000]\n",
      "loss: 0.880082  [19136/60000]\n",
      "loss: 0.886580  [25536/60000]\n",
      "loss: 0.878997  [31936/60000]\n",
      "loss: 0.892013  [38336/60000]\n",
      "loss: 0.971687  [44736/60000]\n",
      "loss: 0.631861  [51136/60000]\n",
      "loss: 0.856841  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.011549 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.904348  [ 6336/60000]\n",
      "loss: 1.012999  [12736/60000]\n",
      "loss: 0.855185  [19136/60000]\n",
      "loss: 0.892289  [25536/60000]\n",
      "loss: 0.755772  [31936/60000]\n",
      "loss: 0.781474  [38336/60000]\n",
      "loss: 0.741581  [44736/60000]\n",
      "loss: 0.949768  [51136/60000]\n",
      "loss: 0.577011  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.010250 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.755279  [ 6336/60000]\n",
      "loss: 0.483171  [12736/60000]\n",
      "loss: 0.545500  [19136/60000]\n",
      "loss: 0.852595  [25536/60000]\n",
      "loss: 0.493256  [31936/60000]\n",
      "loss: 0.788293  [38336/60000]\n",
      "loss: 0.479485  [44736/60000]\n",
      "loss: 0.689614  [51136/60000]\n",
      "loss: 0.548876  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.008843 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.599628  [ 6336/60000]\n",
      "loss: 0.659423  [12736/60000]\n",
      "loss: 0.676400  [19136/60000]\n",
      "loss: 0.387412  [25536/60000]\n",
      "loss: 0.570755  [31936/60000]\n",
      "loss: 0.409164  [38336/60000]\n",
      "loss: 0.807106  [44736/60000]\n",
      "loss: 0.578705  [51136/60000]\n",
      "loss: 0.613252  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.007354 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.410877  [ 6336/60000]\n",
      "loss: 0.647048  [12736/60000]\n",
      "loss: 0.393892  [19136/60000]\n",
      "loss: 0.435402  [25536/60000]\n",
      "loss: 0.365459  [31936/60000]\n",
      "loss: 0.402257  [38336/60000]\n",
      "loss: 0.380195  [44736/60000]\n",
      "loss: 0.463131  [51136/60000]\n",
      "loss: 0.351501  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.007115 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.391675  [ 6336/60000]\n",
      "loss: 0.491581  [12736/60000]\n",
      "loss: 0.382093  [19136/60000]\n",
      "loss: 0.355945  [25536/60000]\n",
      "loss: 0.437269  [31936/60000]\n",
      "loss: 0.387657  [38336/60000]\n",
      "loss: 0.741058  [44736/60000]\n",
      "loss: 0.626549  [51136/60000]\n",
      "loss: 0.383231  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.005990 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.390294  [ 6336/60000]\n",
      "loss: 0.551893  [12736/60000]\n",
      "loss: 0.568289  [19136/60000]\n",
      "loss: 0.351695  [25536/60000]\n",
      "loss: 0.303351  [31936/60000]\n",
      "loss: 0.526805  [38336/60000]\n",
      "loss: 0.659253  [44736/60000]\n",
      "loss: 0.409854  [51136/60000]\n",
      "loss: 0.293603  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.006024 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.293418  [ 6336/60000]\n",
      "loss: 0.264759  [12736/60000]\n",
      "loss: 0.348213  [19136/60000]\n",
      "loss: 0.331081  [25536/60000]\n",
      "loss: 0.329675  [31936/60000]\n",
      "loss: 0.379133  [38336/60000]\n",
      "loss: 0.299553  [44736/60000]\n",
      "loss: 0.412552  [51136/60000]\n",
      "loss: 0.406019  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.005159 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.297380  [ 6336/60000]\n",
      "loss: 0.362295  [12736/60000]\n",
      "loss: 0.208409  [19136/60000]\n",
      "loss: 0.365220  [25536/60000]\n",
      "loss: 0.396083  [31936/60000]\n",
      "loss: 0.346004  [38336/60000]\n",
      "loss: 0.345391  [44736/60000]\n",
      "loss: 0.180871  [51136/60000]\n",
      "loss: 0.405435  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.005244 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.392959  [ 6336/60000]\n",
      "loss: 0.489617  [12736/60000]\n",
      "loss: 0.284098  [19136/60000]\n",
      "loss: 0.336886  [25536/60000]\n",
      "loss: 0.287945  [31936/60000]\n",
      "loss: 0.429045  [38336/60000]\n",
      "loss: 0.244747  [44736/60000]\n",
      "loss: 0.410657  [51136/60000]\n",
      "loss: 0.206015  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.004756 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.287499  [ 6336/60000]\n",
      "loss: 0.265394  [12736/60000]\n",
      "loss: 0.178166  [19136/60000]\n",
      "loss: 0.372949  [25536/60000]\n",
      "loss: 0.391857  [31936/60000]\n",
      "loss: 0.279958  [38336/60000]\n",
      "loss: 0.178258  [44736/60000]\n",
      "loss: 0.317259  [51136/60000]\n",
      "loss: 0.187214  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.005157 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.239928  [ 6336/60000]\n",
      "loss: 0.467250  [12736/60000]\n",
      "loss: 0.401101  [19136/60000]\n",
      "loss: 0.429519  [25536/60000]\n",
      "loss: 0.270717  [31936/60000]\n",
      "loss: 0.376369  [38336/60000]\n",
      "loss: 0.383991  [44736/60000]\n",
      "loss: 0.245735  [51136/60000]\n",
      "loss: 0.259575  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.004537 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.177844  [ 6336/60000]\n",
      "loss: 0.296898  [12736/60000]\n",
      "loss: 0.316462  [19136/60000]\n",
      "loss: 0.222292  [25536/60000]\n",
      "loss: 0.314651  [31936/60000]\n",
      "loss: 0.334666  [38336/60000]\n",
      "loss: 0.388690  [44736/60000]\n",
      "loss: 0.246701  [51136/60000]\n",
      "loss: 0.251184  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.004058 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.242589  [ 6336/60000]\n",
      "loss: 0.166151  [12736/60000]\n",
      "loss: 0.235621  [19136/60000]\n",
      "loss: 0.483275  [25536/60000]\n",
      "loss: 0.253688  [31936/60000]\n",
      "loss: 0.117351  [38336/60000]\n",
      "loss: 0.283668  [44736/60000]\n",
      "loss: 0.205918  [51136/60000]\n",
      "loss: 0.129209  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.003923 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.216041  [ 6336/60000]\n",
      "loss: 0.192265  [12736/60000]\n",
      "loss: 0.187193  [19136/60000]\n",
      "loss: 0.296322  [25536/60000]\n",
      "loss: 0.180381  [31936/60000]\n",
      "loss: 0.152699  [38336/60000]\n",
      "loss: 0.253758  [44736/60000]\n",
      "loss: 0.183981  [51136/60000]\n",
      "loss: 0.219169  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.003723 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.286845  [ 6336/60000]\n",
      "loss: 0.305196  [12736/60000]\n",
      "loss: 0.101194  [19136/60000]\n",
      "loss: 0.197639  [25536/60000]\n",
      "loss: 0.187610  [31936/60000]\n",
      "loss: 0.265320  [38336/60000]\n",
      "loss: 0.285930  [44736/60000]\n",
      "loss: 0.322406  [51136/60000]\n",
      "loss: 0.151785  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.003743 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.171246  [ 6336/60000]\n",
      "loss: 0.248727  [12736/60000]\n",
      "loss: 0.385506  [19136/60000]\n",
      "loss: 0.247468  [25536/60000]\n",
      "loss: 0.115252  [31936/60000]\n",
      "loss: 0.133225  [38336/60000]\n",
      "loss: 0.352871  [44736/60000]\n",
      "loss: 0.101597  [51136/60000]\n",
      "loss: 0.305803  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.003603 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.431754  [ 6336/60000]\n",
      "loss: 0.102901  [12736/60000]\n",
      "loss: 0.182234  [19136/60000]\n",
      "loss: 0.230806  [25536/60000]\n",
      "loss: 0.174782  [31936/60000]\n",
      "loss: 0.191727  [38336/60000]\n",
      "loss: 0.327104  [44736/60000]\n",
      "loss: 0.239726  [51136/60000]\n",
      "loss: 0.337872  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.003506 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.072504  [ 6336/60000]\n",
      "loss: 0.286948  [12736/60000]\n",
      "loss: 0.242689  [19136/60000]\n",
      "loss: 0.359288  [25536/60000]\n",
      "loss: 0.239073  [31936/60000]\n",
      "loss: 0.235691  [38336/60000]\n",
      "loss: 0.306960  [44736/60000]\n",
      "loss: 0.267451  [51136/60000]\n",
      "loss: 0.216656  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.003503 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.131916  [ 6336/60000]\n",
      "loss: 0.129561  [12736/60000]\n",
      "loss: 0.237474  [19136/60000]\n",
      "loss: 0.117929  [25536/60000]\n",
      "loss: 0.260168  [31936/60000]\n",
      "loss: 0.353992  [38336/60000]\n",
      "loss: 0.201838  [44736/60000]\n",
      "loss: 0.174684  [51136/60000]\n",
      "loss: 0.066154  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.003471 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.092320  [ 6336/60000]\n",
      "loss: 0.327234  [12736/60000]\n",
      "loss: 0.256278  [19136/60000]\n",
      "loss: 0.101238  [25536/60000]\n",
      "loss: 0.231155  [31936/60000]\n",
      "loss: 0.241260  [38336/60000]\n",
      "loss: 0.296851  [44736/60000]\n",
      "loss: 0.266783  [51136/60000]\n",
      "loss: 0.178699  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.003282 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.502676  [ 6336/60000]\n",
      "loss: 0.237046  [12736/60000]\n",
      "loss: 0.160971  [19136/60000]\n",
      "loss: 0.167431  [25536/60000]\n",
      "loss: 0.224666  [31936/60000]\n",
      "loss: 0.187581  [38336/60000]\n",
      "loss: 0.186476  [44736/60000]\n",
      "loss: 0.358217  [51136/60000]\n",
      "loss: 0.307124  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.003135 \n",
      "\n",
      "Finished Training Net + <class 'z2_conv.ConvNet'>\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306058  [ 6336/60000]\n",
      "loss: 2.290393  [12736/60000]\n",
      "loss: 2.290296  [19136/60000]\n",
      "loss: 2.286065  [25536/60000]\n",
      "loss: 2.268838  [31936/60000]\n",
      "loss: 2.253626  [38336/60000]\n",
      "loss: 2.215266  [44736/60000]\n",
      "loss: 2.135193  [51136/60000]\n",
      "loss: 1.614471  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 23.7%, Avg loss: 0.036121 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.822575  [ 6336/60000]\n",
      "loss: 0.793226  [12736/60000]\n",
      "loss: 0.642024  [19136/60000]\n",
      "loss: 0.495516  [25536/60000]\n",
      "loss: 0.432928  [31936/60000]\n",
      "loss: 0.512462  [38336/60000]\n",
      "loss: 0.411547  [44736/60000]\n",
      "loss: 0.503687  [51136/60000]\n",
      "loss: 0.390491  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 29.8%, Avg loss: 0.066635 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.285173  [ 6336/60000]\n",
      "loss: 0.454676  [12736/60000]\n",
      "loss: 0.241451  [19136/60000]\n",
      "loss: 0.250649  [25536/60000]\n",
      "loss: 0.368583  [31936/60000]\n",
      "loss: 0.112222  [38336/60000]\n",
      "loss: 0.230385  [44736/60000]\n",
      "loss: 0.291485  [51136/60000]\n",
      "loss: 0.451892  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.7%, Avg loss: 0.065225 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.279089  [ 6336/60000]\n",
      "loss: 0.259244  [12736/60000]\n",
      "loss: 0.219546  [19136/60000]\n",
      "loss: 0.176620  [25536/60000]\n",
      "loss: 0.271438  [31936/60000]\n",
      "loss: 0.300268  [38336/60000]\n",
      "loss: 0.219923  [44736/60000]\n",
      "loss: 0.181867  [51136/60000]\n",
      "loss: 0.220779  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.063987 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.333158  [ 6336/60000]\n",
      "loss: 0.189930  [12736/60000]\n",
      "loss: 0.195466  [19136/60000]\n",
      "loss: 0.156811  [25536/60000]\n",
      "loss: 0.230803  [31936/60000]\n",
      "loss: 0.166990  [38336/60000]\n",
      "loss: 0.143026  [44736/60000]\n",
      "loss: 0.107308  [51136/60000]\n",
      "loss: 0.134363  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.064516 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.241681  [ 6336/60000]\n",
      "loss: 0.190300  [12736/60000]\n",
      "loss: 0.112232  [19136/60000]\n",
      "loss: 0.089405  [25536/60000]\n",
      "loss: 0.157436  [31936/60000]\n",
      "loss: 0.142624  [38336/60000]\n",
      "loss: 0.174817  [44736/60000]\n",
      "loss: 0.129199  [51136/60000]\n",
      "loss: 0.184352  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.8%, Avg loss: 0.070939 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.110417  [ 6336/60000]\n",
      "loss: 0.069441  [12736/60000]\n",
      "loss: 0.082494  [19136/60000]\n",
      "loss: 0.066408  [25536/60000]\n",
      "loss: 0.126291  [31936/60000]\n",
      "loss: 0.070682  [38336/60000]\n",
      "loss: 0.048387  [44736/60000]\n",
      "loss: 0.156141  [51136/60000]\n",
      "loss: 0.133408  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.072830 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.068673  [ 6336/60000]\n",
      "loss: 0.034559  [12736/60000]\n",
      "loss: 0.015390  [19136/60000]\n",
      "loss: 0.115260  [25536/60000]\n",
      "loss: 0.101534  [31936/60000]\n",
      "loss: 0.105454  [38336/60000]\n",
      "loss: 0.187911  [44736/60000]\n",
      "loss: 0.112060  [51136/60000]\n",
      "loss: 0.072086  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.7%, Avg loss: 0.077252 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.035591  [ 6336/60000]\n",
      "loss: 0.098430  [12736/60000]\n",
      "loss: 0.157373  [19136/60000]\n",
      "loss: 0.043690  [25536/60000]\n",
      "loss: 0.016358  [31936/60000]\n",
      "loss: 0.038727  [38336/60000]\n",
      "loss: 0.047796  [44736/60000]\n",
      "loss: 0.038325  [51136/60000]\n",
      "loss: 0.148791  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.1%, Avg loss: 0.076199 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.121349  [ 6336/60000]\n",
      "loss: 0.025194  [12736/60000]\n",
      "loss: 0.063317  [19136/60000]\n",
      "loss: 0.144520  [25536/60000]\n",
      "loss: 0.045671  [31936/60000]\n",
      "loss: 0.105671  [38336/60000]\n",
      "loss: 0.114902  [44736/60000]\n",
      "loss: 0.131998  [51136/60000]\n",
      "loss: 0.015487  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.0%, Avg loss: 0.079128 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.053746  [ 6336/60000]\n",
      "loss: 0.027702  [12736/60000]\n",
      "loss: 0.066417  [19136/60000]\n",
      "loss: 0.167796  [25536/60000]\n",
      "loss: 0.043109  [31936/60000]\n",
      "loss: 0.009282  [38336/60000]\n",
      "loss: 0.068491  [44736/60000]\n",
      "loss: 0.083858  [51136/60000]\n",
      "loss: 0.022516  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.2%, Avg loss: 0.085199 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.056667  [ 6336/60000]\n",
      "loss: 0.053441  [12736/60000]\n",
      "loss: 0.039501  [19136/60000]\n",
      "loss: 0.044620  [25536/60000]\n",
      "loss: 0.114561  [31936/60000]\n",
      "loss: 0.059987  [38336/60000]\n",
      "loss: 0.142207  [44736/60000]\n",
      "loss: 0.016236  [51136/60000]\n",
      "loss: 0.131871  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 33.2%, Avg loss: 0.083121 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.032055  [ 6336/60000]\n",
      "loss: 0.039654  [12736/60000]\n",
      "loss: 0.027892  [19136/60000]\n",
      "loss: 0.153694  [25536/60000]\n",
      "loss: 0.080807  [31936/60000]\n",
      "loss: 0.018281  [38336/60000]\n",
      "loss: 0.033847  [44736/60000]\n",
      "loss: 0.100443  [51136/60000]\n",
      "loss: 0.047973  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.087723 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.185808  [ 6336/60000]\n",
      "loss: 0.008714  [12736/60000]\n",
      "loss: 0.067400  [19136/60000]\n",
      "loss: 0.026902  [25536/60000]\n",
      "loss: 0.045031  [31936/60000]\n",
      "loss: 0.113440  [38336/60000]\n",
      "loss: 0.145029  [44736/60000]\n",
      "loss: 0.059661  [51136/60000]\n",
      "loss: 0.086694  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.085209 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.097742  [ 6336/60000]\n",
      "loss: 0.065925  [12736/60000]\n",
      "loss: 0.046195  [19136/60000]\n",
      "loss: 0.065760  [25536/60000]\n",
      "loss: 0.080375  [31936/60000]\n",
      "loss: 0.019980  [38336/60000]\n",
      "loss: 0.017523  [44736/60000]\n",
      "loss: 0.071752  [51136/60000]\n",
      "loss: 0.093236  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 0.088870 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.041534  [ 6336/60000]\n",
      "loss: 0.092065  [12736/60000]\n",
      "loss: 0.042825  [19136/60000]\n",
      "loss: 0.057962  [25536/60000]\n",
      "loss: 0.023810  [31936/60000]\n",
      "loss: 0.115131  [38336/60000]\n",
      "loss: 0.008878  [44736/60000]\n",
      "loss: 0.129176  [51136/60000]\n",
      "loss: 0.048764  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.4%, Avg loss: 0.093295 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.165281  [ 6336/60000]\n",
      "loss: 0.090517  [12736/60000]\n",
      "loss: 0.022796  [19136/60000]\n",
      "loss: 0.130999  [25536/60000]\n",
      "loss: 0.003969  [31936/60000]\n",
      "loss: 0.012619  [38336/60000]\n",
      "loss: 0.017275  [44736/60000]\n",
      "loss: 0.025959  [51136/60000]\n",
      "loss: 0.028783  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.1%, Avg loss: 0.091513 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.013599  [ 6336/60000]\n",
      "loss: 0.005787  [12736/60000]\n",
      "loss: 0.016399  [19136/60000]\n",
      "loss: 0.029368  [25536/60000]\n",
      "loss: 0.134240  [31936/60000]\n",
      "loss: 0.054120  [38336/60000]\n",
      "loss: 0.012074  [44736/60000]\n",
      "loss: 0.047839  [51136/60000]\n",
      "loss: 0.111672  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 0.095299 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.034250  [ 6336/60000]\n",
      "loss: 0.052045  [12736/60000]\n",
      "loss: 0.077766  [19136/60000]\n",
      "loss: 0.004629  [25536/60000]\n",
      "loss: 0.040105  [31936/60000]\n",
      "loss: 0.009802  [38336/60000]\n",
      "loss: 0.030020  [44736/60000]\n",
      "loss: 0.016881  [51136/60000]\n",
      "loss: 0.014381  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.9%, Avg loss: 0.092837 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.011070  [ 6336/60000]\n",
      "loss: 0.039353  [12736/60000]\n",
      "loss: 0.026760  [19136/60000]\n",
      "loss: 0.009347  [25536/60000]\n",
      "loss: 0.036083  [31936/60000]\n",
      "loss: 0.027086  [38336/60000]\n",
      "loss: 0.024078  [44736/60000]\n",
      "loss: 0.042679  [51136/60000]\n",
      "loss: 0.024043  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.7%, Avg loss: 0.095994 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.011011  [ 6336/60000]\n",
      "loss: 0.041022  [12736/60000]\n",
      "loss: 0.086042  [19136/60000]\n",
      "loss: 0.014451  [25536/60000]\n",
      "loss: 0.020774  [31936/60000]\n",
      "loss: 0.013367  [38336/60000]\n",
      "loss: 0.043787  [44736/60000]\n",
      "loss: 0.036612  [51136/60000]\n",
      "loss: 0.027606  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.7%, Avg loss: 0.096445 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.065133  [ 6336/60000]\n",
      "loss: 0.003623  [12736/60000]\n",
      "loss: 0.009526  [19136/60000]\n",
      "loss: 0.066852  [25536/60000]\n",
      "loss: 0.082643  [31936/60000]\n",
      "loss: 0.079451  [38336/60000]\n",
      "loss: 0.003368  [44736/60000]\n",
      "loss: 0.044530  [51136/60000]\n",
      "loss: 0.043481  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.0%, Avg loss: 0.100478 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.021287  [ 6336/60000]\n",
      "loss: 0.016751  [12736/60000]\n",
      "loss: 0.005933  [19136/60000]\n",
      "loss: 0.005524  [25536/60000]\n",
      "loss: 0.003859  [31936/60000]\n",
      "loss: 0.027764  [38336/60000]\n",
      "loss: 0.008021  [44736/60000]\n",
      "loss: 0.026385  [51136/60000]\n",
      "loss: 0.033270  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.099501 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.126545  [ 6336/60000]\n",
      "loss: 0.029185  [12736/60000]\n",
      "loss: 0.059998  [19136/60000]\n",
      "loss: 0.109017  [25536/60000]\n",
      "loss: 0.016869  [31936/60000]\n",
      "loss: 0.079188  [38336/60000]\n",
      "loss: 0.018685  [44736/60000]\n",
      "loss: 0.037763  [51136/60000]\n",
      "loss: 0.020490  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.2%, Avg loss: 0.102723 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.060810  [ 6336/60000]\n",
      "loss: 0.003647  [12736/60000]\n",
      "loss: 0.005931  [19136/60000]\n",
      "loss: 0.021801  [25536/60000]\n",
      "loss: 0.040516  [31936/60000]\n",
      "loss: 0.008241  [38336/60000]\n",
      "loss: 0.095921  [44736/60000]\n",
      "loss: 0.005523  [51136/60000]\n",
      "loss: 0.033351  [57536/60000]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 0.101833 \n",
      "\n",
      "Finished Training Net + <class 'z2_conv.ConvNet'>\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "# writer remains the same\r\n",
    "train_test_net(p4m_net, True)\r\n",
    "\r\n",
    "writer = SummaryWriter('runs/p4_mnist_1')\r\n",
    "train_test_net(p4_net, True)\r\n",
    "\r\n",
    "writer = SummaryWriter('runs/conv_mnist_1')\r\n",
    "train_test_net(conv_net, False)\r\n",
    "\r\n",
    "convu_net = ConvNet()\r\n",
    "writer = SummaryWriter('runs/convu_mnist_1')\r\n",
    "train_test_net(convu_net, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparisons\r\n",
    "\r\n",
    "There are a few comparisons between the models to be made here. Here is a list of the following that I log\r\n",
    "- Model accuracy on 10000 test images\r\n",
    "- Model accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net):\r\n",
    "    correct = 0\r\n",
    "    total = 0\r\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in test_dataloader_rot:\r\n",
    "            images, labels = data[0].to(device), data[1].to(device)\r\n",
    "            # calculate outputs by running images through the network\r\n",
    "            outputs = net(images)\r\n",
    "            # the class with the highest energy is what we choose as prediction\r\n",
    "            _, predicted = torch.max(outputs.data, 1)\r\n",
    "            total += labels.size(0)\r\n",
    "            correct += (predicted == labels.to(device)).sum().item()\r\n",
    "\r\n",
    "    print('Accuracy of the ' + str(type(net)) + ' on the 10000 test images: %f %%' % (\r\n",
    "        100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_labels(net):\r\n",
    "    # prepare to count predictions for each class\r\n",
    "    correct_pred = {num : 0 for num in range(0, 10)}\r\n",
    "    total_pred = {num : 0 for num in range(0, 10)}\r\n",
    "\r\n",
    "    # again no gradients needed\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in test_dataloader_rot:\r\n",
    "            images, labels = data[0].to(device), data[1].to(device)\r\n",
    "            outputs = net(images.to(device))\r\n",
    "            _, predictions = torch.max(outputs, 1)\r\n",
    "            # collect the correct predictions for each class\r\n",
    "            for label, prediction in zip(labels, predictions):\r\n",
    "                if label == prediction:\r\n",
    "                    correct_pred[label.item()] += 1\r\n",
    "                total_pred[label.item()] += 1\r\n",
    "\r\n",
    "    print('Classes for ' + str(type(net)))\r\n",
    "\r\n",
    "    # print accuracy for each class\r\n",
    "    for classname, correct_count in correct_pred.items():\r\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\r\n",
    "        print(\"Accuracy for num {} is: {:.1f} %\".format(classname,\r\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the <class 'p4m_conv.P4MNet'> on the 10000 test images: 97.250000 %\n",
      "Classes for <class 'p4m_conv.P4MNet'>\n",
      "Accuracy for num 0 is: 99.3 %\n",
      "Accuracy for num 1 is: 98.9 %\n",
      "Accuracy for num 2 is: 91.9 %\n",
      "Accuracy for num 3 is: 98.5 %\n",
      "Accuracy for num 4 is: 97.0 %\n",
      "Accuracy for num 5 is: 95.9 %\n",
      "Accuracy for num 6 is: 96.7 %\n",
      "Accuracy for num 7 is: 97.2 %\n",
      "Accuracy for num 8 is: 99.3 %\n",
      "Accuracy for num 9 is: 97.8 %\n",
      "Accuracy of the <class 'p4_conv.P4Net'> on the 10000 test images: 97.400000 %\n",
      "Classes for <class 'p4_conv.P4Net'>\n",
      "Accuracy for num 0 is: 99.4 %\n",
      "Accuracy for num 1 is: 99.5 %\n",
      "Accuracy for num 2 is: 95.9 %\n",
      "Accuracy for num 3 is: 99.0 %\n",
      "Accuracy for num 4 is: 97.1 %\n",
      "Accuracy for num 5 is: 96.1 %\n",
      "Accuracy for num 6 is: 95.8 %\n",
      "Accuracy for num 7 is: 96.1 %\n",
      "Accuracy for num 8 is: 97.9 %\n",
      "Accuracy for num 9 is: 96.7 %\n",
      "Accuracy of the <class 'z2_conv.ConvNet'> on the 10000 test images: 93.610000 %\n",
      "Classes for <class 'z2_conv.ConvNet'>\n",
      "Accuracy for num 0 is: 98.2 %\n",
      "Accuracy for num 1 is: 98.9 %\n",
      "Accuracy for num 2 is: 86.9 %\n",
      "Accuracy for num 3 is: 95.4 %\n",
      "Accuracy for num 4 is: 95.3 %\n",
      "Accuracy for num 5 is: 83.6 %\n",
      "Accuracy for num 6 is: 92.2 %\n",
      "Accuracy for num 7 is: 93.7 %\n",
      "Accuracy for num 8 is: 94.4 %\n",
      "Accuracy for num 9 is: 94.6 %\n",
      "Accuracy of the <class 'z2_conv.ConvNet'> on the 10000 test images: 32.280000 %\n",
      "Classes for <class 'z2_conv.ConvNet'>\n",
      "Accuracy for num 0 is: 77.6 %\n",
      "Accuracy for num 1 is: 53.2 %\n",
      "Accuracy for num 2 is: 12.7 %\n",
      "Accuracy for num 3 is: 24.1 %\n",
      "Accuracy for num 4 is: 32.5 %\n",
      "Accuracy for num 5 is: 14.6 %\n",
      "Accuracy for num 6 is: 16.9 %\n",
      "Accuracy for num 7 is: 27.0 %\n",
      "Accuracy for num 8 is: 50.2 %\n",
      "Accuracy for num 9 is: 14.0 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(p4m_net)\r\n",
    "class_labels(p4m_net)\r\n",
    "\r\n",
    "test_accuracy(p4_net)\r\n",
    "class_labels(p4_net)\r\n",
    "\r\n",
    "test_accuracy(conv_net)\r\n",
    "class_labels(conv_net)\r\n",
    "\r\n",
    "test_accuracy(convu_net)\r\n",
    "class_labels(convu_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(p4m_net, 'upright-trained-p4m-2.pth')\r\n",
    "torch.save(p4_net, 'upright-trained-p4.pth')\r\n",
    "torch.save(conv_net, 'rot-trained-conv.pth')\r\n",
    "torch.save(convu_net, 'upright-trained-conv.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f665fd8ed1386b9605bd6d1d95408943e5396eca0f77e44c2585e6a9876cbe3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('reu-code': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}