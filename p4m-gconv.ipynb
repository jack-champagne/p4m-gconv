{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports for pytorch\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "from groupy.gconv.pytorch_gconv import P4MConvZ2, P4MConvP4M, P4ConvZ2, P4ConvP4\r\n",
    "\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from RotMNIST import RotMNIST\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "### Instatiate RotMNIST and verify behaviour below with the dataloaders\n",
    "dataset_rot = RotMNIST(\n",
    "    root = 'data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    "    rotation_mirroring=True\n",
    ")\n",
    "\n",
    "test_dataset_rot = RotMNIST(\n",
    "    root = 'data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    "    rotation_mirroring=True\n",
    ")\n",
    "\n",
    "dataset_upright = RotMNIST(\n",
    "    root = 'data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.Resize(32), torchvision.transforms.ToTensor()]\n",
    "    ),\n",
    "    rotation_mirroring=False,\n",
    ")\n",
    "\n",
    "### Instantiate dataloader for RotMNIST and get batches\n",
    "train_dataloader_rot = DataLoader(dataset_rot, batch_size=64, shuffle=True)\n",
    "test_dataloader_rot = DataLoader(test_dataset_rot, batch_size=64, shuffle=True)\n",
    "train_dataloader_upright = DataLoader(dataset_upright, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "# Define max pooling as from @COGNAR and mnist expiriments from @adambielski (found through pytorch implementation of GrouPy)\r\n",
    "\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "def plane_group_spatial_max_pooling(x, ksize, stride=None, pad=0):\r\n",
    "    xs = x.size()\r\n",
    "    x = x.view(xs[0], xs[1] * xs[2], xs[3], xs[4])\r\n",
    "    x = F.max_pool2d(input=x, kernel_size=ksize, stride=stride, padding=pad)\r\n",
    "    x = x.view(xs[0], xs[1], xs[2], x.size()[2], x.size()[3])\r\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): P4MConvZ2()\n",
      "  (conv2): P4MConvP4M()\n",
      "  (conv3): P4MConvP4M()\n",
      "  (fc1): Linear(in_features=32, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable params: 128696\n"
     ]
    }
   ],
   "source": [
    "### G-Conv p4m training\n",
    "\n",
    "# Three settings for convolutional layers:\n",
    "#   * self.conv1 = P4MConvZ2(in_channels=1, out_channels=2, kernel_size=5, stride=1),   self.conv2 = P4MConvP4M(in_channels=2, out_channels=4, kernel_size=5, stride=1)\n",
    "#   * self.conv1 = P4ConvZ2(in_channels=1, out_channels=4, kernel_size=5, stride=1),    self.conv2 = P4ConvP4(in_channels=4, out_channels=6, kernel_size=5, stride=1)\n",
    "#   * self.conv1 = nn.Conv2d(1, 6, 5), self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() \n",
    "        self.conv1 = P4MConvZ2(in_channels=1, out_channels=8, kernel_size=5, stride=1)\n",
    "        self.conv2 = P4MConvP4M(in_channels=8, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.conv3 = P4MConvP4M(in_channels=16, out_channels=32, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = plane_group_spatial_max_pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = plane_group_spatial_max_pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = plane_group_spatial_max_pooling(x, 2, 2)\n",
    "        x = torch.max(x, dim=2)[0]\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "net = Net()\n",
    "\n",
    "\n",
    "print(net)\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable params: \" + str(pytorch_total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): P4MConvZ2()\n",
      "  (conv2): P4MConvP4M()\n",
      "  (conv3): P4MConvP4M()\n",
      "  (fc1): Linear(in_features=32, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n",
      "Number of trainable params: 122244\n"
     ]
    }
   ],
   "source": [
    "### G-Conv p4 training\n",
    "\n",
    "# Three settings for convolutional layers:\n",
    "#   * self.conv1 = P4MConvZ2(in_channels=1, out_channels=2, kernel_size=5, stride=1),   self.conv2 = P4MConvP4M(in_channels=2, out_channels=4, kernel_size=5, stride=1)\n",
    "#   * self.conv1 = P4ConvZ2(in_channels=1, out_channels=4, kernel_size=5, stride=1),    self.conv2 = P4ConvP4(in_channels=4, out_channels=6, kernel_size=5, stride=1)\n",
    "#   * self.conv1 = nn.Conv2d(1, 6, 5), self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() \n",
    "        # self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv1 = P4MConvZ2(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        # self.pool = nn.MaxPool2d(2, 2) - getting replaced by plane_group_max_pooling\n",
    "        # self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv2 = P4MConvP4M(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.conv3 = P4MConvP4M(in_channels=16, out_channels=32, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = plane_group_spatial_max_pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = plane_group_spatial_max_pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = plane_group_spatial_max_pooling(x, 1, 1)\n",
    "        x = torch.max(x, dim=2)[0]\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "\n",
    "print(net)\n",
    "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable params: \" + str(pytorch_total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper-parameters\r\n",
    "\r\n",
    "learning_rate = 0.001\r\n",
    "batch_size = 64\r\n",
    "epochs = 25\r\n",
    "\r\n",
    "### Optimizers, Objectives \r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training and testing function definitions\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Compute prediction and loss for backprop\n",
    "        pred = model(X.to(device))\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "        # Backpropagation by setting grad to zero, calculating using backprop engine and stepping (using learning rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # No gradient on training data (faster computation and no optimization happening here anyway)\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    \n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.000089  [    0/60000]\n",
      "loss: 0.000012  [ 6400/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-69448321a5e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader_rot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Test loop will always have testing done with rotations and scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-dd0a910e2429>\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Compute prediction and loss for backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-6e018a03b200>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplane_group_spatial_max_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplane_group_spatial_max_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\groupy\\gconv\\pytorch_gconv\\splitgconv2d.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_channels\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_stabilizer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         y = F.conv2d(input, weight=tw, bias=None, stride=self.stride,\n\u001b[0m\u001b[0;32m     77\u001b[0m                         padding=self.padding)\n\u001b[0;32m     78\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader_rot, net, loss_fn, optimizer)\n",
    "\n",
    "    # Test loop will always have testing done with rotations and scaling\n",
    "    test_loop(test_dataloader_rot, net, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 10000 test images: 97.480000 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\r\n",
    "total = 0\r\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\r\n",
    "with torch.no_grad():\r\n",
    "    for data in test_dataloader_rot:\r\n",
    "        images, labels = data[0].to(device), data[1].to(device)\r\n",
    "        # calculate outputs by running images through the network\r\n",
    "        outputs = net(images)\r\n",
    "        # the class with the highest energy is what we choose as prediction\r\n",
    "        _, predicted = torch.max(outputs.data, 1)\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels.to(device)).sum().item()\r\n",
    "\r\n",
    "print('Accuracy of the network on %i test images: %f %%' % (total, 100.0 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net, 'upright-trained-p4m.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('upright-trained-p4m.pth')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 10000 test images: 97.480000 %\n",
      "Accuracy for num 0 is: 98.9 %\n",
      "Accuracy for num 1 is: 98.9 %\n",
      "Accuracy for num 2 is: 95.8 %\n",
      "Accuracy for num 3 is: 98.4 %\n",
      "Accuracy for num 4 is: 97.3 %\n",
      "Accuracy for num 5 is: 95.5 %\n",
      "Accuracy for num 6 is: 96.1 %\n",
      "Accuracy for num 7 is: 96.8 %\n",
      "Accuracy for num 8 is: 98.9 %\n",
      "Accuracy for num 9 is: 97.8 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\r\n",
    "total = 0\r\n",
    "\r\n",
    "# prepare to count predictions for each class\r\n",
    "correct_pred = {num : 0 for num in range(0, 10)}\r\n",
    "total_pred = {num : 0 for num in range(0, 10)}\r\n",
    "\r\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\r\n",
    "with torch.no_grad():\r\n",
    "    for data in test_dataloader_rot:\r\n",
    "        images, labels = data[0].to(device), data[1].to(device)\r\n",
    "        # calculate outputs by running images through the network\r\n",
    "        outputs = net(images)\r\n",
    "        # the class with the highest energy is what we choose as prediction\r\n",
    "        _, predicted = torch.max(outputs.data, 1)\r\n",
    "\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels.to(device)).sum().item()\r\n",
    "\r\n",
    "        for label, prediction in zip(labels, predicted):\r\n",
    "            if label == prediction:\r\n",
    "                correct_pred[label.item()] += 1\r\n",
    "            total_pred[label.item()] += 1\r\n",
    "\r\n",
    "print('Accuracy of the network on %i test images: %f %%' % (total, 100.0 * correct / total))\r\n",
    "\r\n",
    "for classname, correct_count in correct_pred.items():\r\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\r\n",
    "    print(\"Accuracy for num {} is: {:.1f} %\".format(classname,\r\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f665fd8ed1386b9605bd6d1d95408943e5396eca0f77e44c2585e6a9876cbe3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('reu-code': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}