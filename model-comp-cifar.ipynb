{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Model Comparison Jupyter notebook\r\n",
    "\r\n",
    "This notebook will load nets as defined int the imported python modules with certain preformance characteristics for comparison.\r\n",
    "This file will also contain the tensorboard that helps visualize the models accuracy over time and the training process.\r\n",
    "\r\n",
    "Components:\r\n",
    "- initialize training parameters and fetch dataset (including RotMNIST dataset)\r\n",
    "- compare model attributes (such as total parameters and structure)\r\n",
    "- define hyperparameters\r\n",
    "- create tensorboard and set up preformance graphs\r\n",
    "- compare model training and preformance under different conditions\r\n",
    "- save models to files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "### Imports for pytorch and dataset\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.autograd import Variable\r\n",
    "\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "from torchvision.datasets.cifar import CIFAR10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "### Defining simple composition for rotations for following compose\r\n",
    "import torchvision.transforms.functional as TF\r\n",
    "import random\r\n",
    "\r\n",
    "class RotationP4:\r\n",
    "    \"\"\"Rotate randomly in p4 group\"\"\"\r\n",
    "\r\n",
    "    def __init__(self):\r\n",
    "        self.angles = [-90, 0, 90, 180]\r\n",
    "        \r\n",
    "    def __call__(self, x):\r\n",
    "        angle = random.choice(self.angles)\r\n",
    "        return TF.rotate(x, angle)\r\n",
    "\r\n",
    "augmented_transform = transforms.Compose(\r\n",
    "    [transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.ToTensor(),\r\n",
    "    RotationP4(),\r\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
    "\r\n",
    "normal_transforms = transform_train = transforms.Compose(\r\n",
    "    [transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### Define dataloaders\r\n",
    "### Instatiate RotMNIST and verify behaviour below with the dataloaders\r\n",
    "dataset_rot = CIFAR10(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=augmented_transform\r\n",
    ")\r\n",
    "\r\n",
    "test_dataset_rot = CIFAR10(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=False,\r\n",
    "    transform=augmented_transform\r\n",
    ")\r\n",
    "\r\n",
    "dataset_upright = CIFAR10(\r\n",
    "    root = 'data',\r\n",
    "    download=True,\r\n",
    "    train=True,\r\n",
    "    transform=normal_transforms,\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "### Import different networks from python files\r\n",
    "# TODO: Uncomment other networks and import\r\n",
    "from p4m_conv import P4MNetC\r\n",
    "from p4_conv import P4NetC\r\n",
    "from z2_conv import ConvNetC\r\n",
    "\r\n",
    "p4m_net = P4MNetC()\r\n",
    "p4_net = P4NetC()\r\n",
    "conv_net = ConvNetC()\r\n",
    "\r\n",
    "p4m_total_params = sum(p.numel() for p in p4m_net.parameters() if p.requires_grad)\r\n",
    "p4_total_params = sum(p.numel() for p in p4_net.parameters() if p.requires_grad)\r\n",
    "z2_total_params = sum(p.numel() for p in conv_net.parameters() if p.requires_grad)\r\n",
    "\r\n",
    "print(p4m_net)\r\n",
    "print(p4_net)\r\n",
    "print(conv_net)\r\n",
    "\r\n",
    "print(\"P4M  --\\tTrainable Params: \" + str(p4m_total_params))\r\n",
    "print(\"P4   --\\tTrainable Params: \" + str(p4_total_params))\r\n",
    "print(\"Conv --\\tTrainable Params: \" + str(z2_total_params))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "P4MNetC(\n",
      "  (conv1): P4MConvZ2()\n",
      "  (conv2): P4MConvP4M()\n",
      "  (conv3): P4MConvP4M()\n",
      "  (fc1): Linear(in_features=48, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "P4NetC(\n",
      "  (conv1): P4ConvZ2()\n",
      "  (conv2): P4ConvP4()\n",
      "  (conv3): P4ConvP4()\n",
      "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "ConvNetC(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "P4M  --\tTrainable Params: 290882\n",
      "P4   --\tTrainable Params: 372202\n",
      "Conv --\tTrainable Params: 210290\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "### Hyperparameters\r\n",
    "learning_rate = 0.001\r\n",
    "batch_size = 64\r\n",
    "epochs = 128\r\n",
    "\r\n",
    "### Objectives/Loss fn\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "### Dataloaders\r\n",
    "train_dataloader_rot = DataLoader(dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "test_dataloader_rot = DataLoader(test_dataset_rot, batch_size=batch_size, shuffle=True)\r\n",
    "train_dataloader_upright = DataLoader(dataset_upright, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, cur_epoch):\r\n",
    "    running_loss = 0.0\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        model.to(device)\r\n",
    "        # Compute prediction and loss for backprop\r\n",
    "        pred = model(X.to(device))\r\n",
    "        loss = loss_fn(pred, y.to(device))\r\n",
    "\r\n",
    "        # Backpropagation by setting grad to zero, calculating using backprop engine and stepping (using learning rate)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        running_loss += loss.item()\r\n",
    "\r\n",
    "        if batch % 100 == 99:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\r\n",
    "\r\n",
    "            writer.add_scalar('training loss', running_loss / 100, cur_epoch * len(dataloader) + batch)\r\n",
    "            running_loss = 0.0\r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    model.to(device)\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "    \r\n",
    "    # No gradient on training data (faster computation and no optimization happening here anyway)\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, y in dataloader:\r\n",
    "            pred = model(X.to(device))\r\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\r\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\r\n",
    "\r\n",
    "    test_loss /= size\r\n",
    "    correct /= size\r\n",
    "    \r\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\r\n",
    "    return correct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "### Train all networks\r\n",
    "def train_test_net(net, train_upright):\r\n",
    "    # Add option to train networks with RotMNIST\r\n",
    "    test_dataloader = train_dataloader_rot\r\n",
    "    if (train_upright):\r\n",
    "        test_dataloader = train_dataloader_upright\r\n",
    "\r\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\r\n",
    "    for t in range(epochs):\r\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "        train_loop(test_dataloader, net, loss_fn, optimizer, t)\r\n",
    "        correct = test_loop(test_dataloader_rot, net, loss_fn)\r\n",
    "        writer.add_scalar('Test Performance', correct, t * len(test_dataloader_rot) + batch_size)\r\n",
    "    print('Finished Training Net + ' + str(type(net)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "import torch.utils.tensorboard\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "# NOTE: Model results are in but model was not saved\r\n",
    "# writer = SummaryWriter('runs/p4m_CIFAR_2')\r\n",
    "# train_test_net(p4m_net, True)\r\n",
    "# torch.save(p4m_net, 'upright-trained-p4m-cifar-1.pth')\r\n",
    "\r\n",
    "# NOTE: run 0 results got interrupted, run 1 is first full run.\r\n",
    "writer = SummaryWriter('runs/p4_CIFAR_2')\r\n",
    "train_test_net(p4_net, True)\r\n",
    "# torch.save(p4_net, 'upright-trained-p4-cifar-1.pth')\r\n",
    "\r\n",
    "writer = SummaryWriter('runs/conv_CIFAR_2')\r\n",
    "train_test_net(conv_net, False)\r\n",
    "# torch.save(conv_net, 'rot-trained-conv-cifar-1.pth')\r\n",
    "\r\n",
    "convu_net = ConvNetC()\r\n",
    "writer = SummaryWriter('runs/convu_CIFAR_2')\r\n",
    "train_test_net(convu_net, True)\r\n",
    "# torch.save(convu_net, 'upright-trained-conv-cifar-1.pth')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303651  [ 6336/50000]\n",
      "loss: 2.294425  [12736/50000]\n",
      "loss: 2.297361  [19136/50000]\n",
      "loss: 2.292597  [25536/50000]\n",
      "loss: 2.271895  [31936/50000]\n",
      "loss: 2.226951  [38336/50000]\n",
      "loss: 2.134883  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 16.9%, Avg loss: 0.034948 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.023307  [ 6336/50000]\n",
      "loss: 1.891639  [12736/50000]\n",
      "loss: 2.022181  [19136/50000]\n",
      "loss: 1.878084  [25536/50000]\n",
      "loss: 1.915148  [31936/50000]\n",
      "loss: 1.787825  [38336/50000]\n",
      "loss: 1.847863  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 27.5%, Avg loss: 0.031561 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.725083  [ 6336/50000]\n",
      "loss: 1.757586  [12736/50000]\n",
      "loss: 1.846630  [19136/50000]\n",
      "loss: 1.689961  [25536/50000]\n",
      "loss: 1.697914  [31936/50000]\n",
      "loss: 1.864043  [38336/50000]\n",
      "loss: 1.506481  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 29.8%, Avg loss: 0.030870 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.731581  [ 6336/50000]\n",
      "loss: 1.441891  [12736/50000]\n",
      "loss: 1.633130  [19136/50000]\n",
      "loss: 1.464473  [25536/50000]\n",
      "loss: 1.415053  [31936/50000]\n",
      "loss: 1.748787  [38336/50000]\n",
      "loss: 1.545504  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.030753 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.446974  [ 6336/50000]\n",
      "loss: 1.608136  [12736/50000]\n",
      "loss: 1.502089  [19136/50000]\n",
      "loss: 1.529821  [25536/50000]\n",
      "loss: 1.432313  [31936/50000]\n",
      "loss: 1.308403  [38336/50000]\n",
      "loss: 1.561000  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 0.028712 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.436354  [ 6336/50000]\n",
      "loss: 1.385802  [12736/50000]\n",
      "loss: 1.609181  [19136/50000]\n",
      "loss: 1.563792  [25536/50000]\n",
      "loss: 1.444001  [31936/50000]\n",
      "loss: 1.469315  [38336/50000]\n",
      "loss: 1.381342  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 0.027894 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.322534  [ 6336/50000]\n",
      "loss: 1.336336  [12736/50000]\n",
      "loss: 1.552013  [19136/50000]\n",
      "loss: 1.529359  [25536/50000]\n",
      "loss: 1.408207  [31936/50000]\n",
      "loss: 1.321755  [38336/50000]\n",
      "loss: 1.524132  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.4%, Avg loss: 0.027489 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.360435  [ 6336/50000]\n",
      "loss: 1.175838  [12736/50000]\n",
      "loss: 1.264376  [19136/50000]\n",
      "loss: 1.315308  [25536/50000]\n",
      "loss: 1.495162  [31936/50000]\n",
      "loss: 1.261792  [38336/50000]\n",
      "loss: 1.223184  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 0.027739 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.177093  [ 6336/50000]\n",
      "loss: 1.083305  [12736/50000]\n",
      "loss: 1.332915  [19136/50000]\n",
      "loss: 1.293689  [25536/50000]\n",
      "loss: 1.291581  [31936/50000]\n",
      "loss: 1.270635  [38336/50000]\n",
      "loss: 1.163656  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 0.026368 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.229650  [ 6336/50000]\n",
      "loss: 1.238868  [12736/50000]\n",
      "loss: 1.168741  [19136/50000]\n",
      "loss: 1.150455  [25536/50000]\n",
      "loss: 1.182383  [31936/50000]\n",
      "loss: 1.074751  [38336/50000]\n",
      "loss: 1.137601  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.025860 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.144235  [ 6336/50000]\n",
      "loss: 1.266731  [12736/50000]\n",
      "loss: 1.273777  [19136/50000]\n",
      "loss: 1.155427  [25536/50000]\n",
      "loss: 1.189262  [31936/50000]\n",
      "loss: 0.876520  [38336/50000]\n",
      "loss: 1.302288  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 0.026808 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.040840  [ 6336/50000]\n",
      "loss: 1.144353  [12736/50000]\n",
      "loss: 0.939619  [19136/50000]\n",
      "loss: 1.220787  [25536/50000]\n",
      "loss: 1.195398  [31936/50000]\n",
      "loss: 1.030234  [38336/50000]\n",
      "loss: 0.959498  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.026881 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.976952  [ 6336/50000]\n",
      "loss: 1.037633  [12736/50000]\n",
      "loss: 0.936080  [19136/50000]\n",
      "loss: 1.027054  [25536/50000]\n",
      "loss: 1.139679  [31936/50000]\n",
      "loss: 0.760357  [38336/50000]\n",
      "loss: 0.817300  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 0.026337 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.016260  [ 6336/50000]\n",
      "loss: 1.020762  [12736/50000]\n",
      "loss: 0.819878  [19136/50000]\n",
      "loss: 0.953861  [25536/50000]\n",
      "loss: 1.107605  [31936/50000]\n",
      "loss: 0.627161  [38336/50000]\n",
      "loss: 0.963598  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.027093 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.986508  [ 6336/50000]\n",
      "loss: 0.991443  [12736/50000]\n",
      "loss: 1.220522  [19136/50000]\n",
      "loss: 0.789140  [25536/50000]\n",
      "loss: 0.772111  [31936/50000]\n",
      "loss: 1.000628  [38336/50000]\n",
      "loss: 0.874492  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.025344 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.006152  [ 6336/50000]\n",
      "loss: 0.916774  [12736/50000]\n",
      "loss: 0.771996  [19136/50000]\n",
      "loss: 0.617485  [25536/50000]\n",
      "loss: 0.858116  [31936/50000]\n",
      "loss: 0.775769  [38336/50000]\n",
      "loss: 1.032972  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.026755 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.739239  [ 6336/50000]\n",
      "loss: 0.725195  [12736/50000]\n",
      "loss: 0.894379  [19136/50000]\n",
      "loss: 0.948661  [25536/50000]\n",
      "loss: 0.430449  [31936/50000]\n",
      "loss: 0.596338  [38336/50000]\n",
      "loss: 0.789008  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 0.025954 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.696969  [ 6336/50000]\n",
      "loss: 1.037868  [12736/50000]\n",
      "loss: 0.726590  [19136/50000]\n",
      "loss: 0.854675  [25536/50000]\n",
      "loss: 0.917569  [31936/50000]\n",
      "loss: 0.555032  [38336/50000]\n",
      "loss: 1.023024  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.026507 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.760538  [ 6336/50000]\n",
      "loss: 0.919529  [12736/50000]\n",
      "loss: 0.781599  [19136/50000]\n",
      "loss: 0.778115  [25536/50000]\n",
      "loss: 0.817702  [31936/50000]\n",
      "loss: 0.724456  [38336/50000]\n",
      "loss: 0.865291  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.026416 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.939548  [ 6336/50000]\n",
      "loss: 0.833887  [12736/50000]\n",
      "loss: 0.802171  [19136/50000]\n",
      "loss: 0.559830  [25536/50000]\n",
      "loss: 0.758453  [31936/50000]\n",
      "loss: 0.672592  [38336/50000]\n",
      "loss: 0.681785  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 0.027849 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.811214  [ 6336/50000]\n",
      "loss: 0.621429  [12736/50000]\n",
      "loss: 0.860973  [19136/50000]\n",
      "loss: 0.548799  [25536/50000]\n",
      "loss: 0.708424  [31936/50000]\n",
      "loss: 0.896667  [38336/50000]\n",
      "loss: 0.900605  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 0.029339 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.842444  [ 6336/50000]\n",
      "loss: 0.565982  [12736/50000]\n",
      "loss: 0.652155  [19136/50000]\n",
      "loss: 0.814493  [25536/50000]\n",
      "loss: 0.776877  [31936/50000]\n",
      "loss: 0.643114  [38336/50000]\n",
      "loss: 0.798571  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 0.026678 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.608716  [ 6336/50000]\n",
      "loss: 0.475197  [12736/50000]\n",
      "loss: 0.648008  [19136/50000]\n",
      "loss: 0.607765  [25536/50000]\n",
      "loss: 0.720847  [31936/50000]\n",
      "loss: 0.485354  [38336/50000]\n",
      "loss: 0.616009  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 0.027944 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.578553  [ 6336/50000]\n",
      "loss: 0.576347  [12736/50000]\n",
      "loss: 0.614037  [19136/50000]\n",
      "loss: 0.428852  [25536/50000]\n",
      "loss: 0.576151  [31936/50000]\n",
      "loss: 0.637421  [38336/50000]\n",
      "loss: 0.451162  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.028413 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.479930  [ 6336/50000]\n",
      "loss: 0.544094  [12736/50000]\n",
      "loss: 0.639253  [19136/50000]\n",
      "loss: 0.548746  [25536/50000]\n",
      "loss: 0.527813  [31936/50000]\n",
      "loss: 0.554039  [38336/50000]\n",
      "loss: 0.420241  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.031208 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.663824  [ 6336/50000]\n",
      "loss: 0.624437  [12736/50000]\n",
      "loss: 0.469288  [19136/50000]\n",
      "loss: 0.657085  [25536/50000]\n",
      "loss: 0.462253  [31936/50000]\n",
      "loss: 0.620101  [38336/50000]\n",
      "loss: 0.573350  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.029973 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.415502  [ 6336/50000]\n",
      "loss: 0.602617  [12736/50000]\n",
      "loss: 0.585749  [19136/50000]\n",
      "loss: 0.416526  [25536/50000]\n",
      "loss: 0.472409  [31936/50000]\n",
      "loss: 0.662348  [38336/50000]\n",
      "loss: 0.540823  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 0.030829 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.537457  [ 6336/50000]\n",
      "loss: 0.378541  [12736/50000]\n",
      "loss: 0.503518  [19136/50000]\n",
      "loss: 0.536037  [25536/50000]\n",
      "loss: 0.752473  [31936/50000]\n",
      "loss: 0.510092  [38336/50000]\n",
      "loss: 0.426980  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.032172 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.556292  [ 6336/50000]\n",
      "loss: 0.419645  [12736/50000]\n",
      "loss: 0.601602  [19136/50000]\n",
      "loss: 0.742021  [25536/50000]\n",
      "loss: 0.461491  [31936/50000]\n",
      "loss: 0.371075  [38336/50000]\n",
      "loss: 0.314754  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 0.030840 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.526830  [ 6336/50000]\n",
      "loss: 0.525832  [12736/50000]\n",
      "loss: 0.365383  [19136/50000]\n",
      "loss: 0.358889  [25536/50000]\n",
      "loss: 0.438590  [31936/50000]\n",
      "loss: 0.471130  [38336/50000]\n",
      "loss: 0.469507  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 0.032484 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.532029  [ 6336/50000]\n",
      "loss: 0.558692  [12736/50000]\n",
      "loss: 0.705314  [19136/50000]\n",
      "loss: 0.411962  [25536/50000]\n",
      "loss: 0.510996  [31936/50000]\n",
      "loss: 0.373329  [38336/50000]\n",
      "loss: 0.368706  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.035297 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.457268  [ 6336/50000]\n",
      "loss: 0.254130  [12736/50000]\n",
      "loss: 0.533998  [19136/50000]\n",
      "loss: 0.355887  [25536/50000]\n",
      "loss: 0.308234  [31936/50000]\n",
      "loss: 0.454840  [38336/50000]\n",
      "loss: 0.289772  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.034705 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.324495  [ 6336/50000]\n",
      "loss: 0.316501  [12736/50000]\n",
      "loss: 0.259840  [19136/50000]\n",
      "loss: 0.459034  [25536/50000]\n",
      "loss: 0.343926  [31936/50000]\n",
      "loss: 0.365472  [38336/50000]\n",
      "loss: 0.295171  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 0.033810 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.402036  [ 6336/50000]\n",
      "loss: 0.271957  [12736/50000]\n",
      "loss: 0.354357  [19136/50000]\n",
      "loss: 0.313868  [25536/50000]\n",
      "loss: 0.343918  [31936/50000]\n",
      "loss: 0.245716  [38336/50000]\n",
      "loss: 0.215206  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.036473 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.228232  [ 6336/50000]\n",
      "loss: 0.334451  [12736/50000]\n",
      "loss: 0.314836  [19136/50000]\n",
      "loss: 0.416747  [25536/50000]\n",
      "loss: 0.272359  [31936/50000]\n",
      "loss: 0.431099  [38336/50000]\n",
      "loss: 0.259457  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.037080 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.137076  [ 6336/50000]\n",
      "loss: 0.394617  [12736/50000]\n",
      "loss: 0.241099  [19136/50000]\n",
      "loss: 0.308522  [25536/50000]\n",
      "loss: 0.189832  [31936/50000]\n",
      "loss: 0.156387  [38336/50000]\n",
      "loss: 0.384467  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.038455 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.270149  [ 6336/50000]\n",
      "loss: 0.262300  [12736/50000]\n",
      "loss: 0.200362  [19136/50000]\n",
      "loss: 0.179501  [25536/50000]\n",
      "loss: 0.380146  [31936/50000]\n",
      "loss: 0.257602  [38336/50000]\n",
      "loss: 0.345918  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.044941 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.259227  [ 6336/50000]\n",
      "loss: 0.254501  [12736/50000]\n",
      "loss: 0.163463  [19136/50000]\n",
      "loss: 0.327165  [25536/50000]\n",
      "loss: 0.269150  [31936/50000]\n",
      "loss: 0.291181  [38336/50000]\n",
      "loss: 0.410059  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 0.046467 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.184311  [ 6336/50000]\n",
      "loss: 0.114164  [12736/50000]\n",
      "loss: 0.293244  [19136/50000]\n",
      "loss: 0.227803  [25536/50000]\n",
      "loss: 0.367668  [31936/50000]\n",
      "loss: 0.252650  [38336/50000]\n",
      "loss: 0.164438  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 0.045138 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.285441  [ 6336/50000]\n",
      "loss: 0.168664  [12736/50000]\n",
      "loss: 0.281704  [19136/50000]\n",
      "loss: 0.281271  [25536/50000]\n",
      "loss: 0.275391  [31936/50000]\n",
      "loss: 0.210816  [38336/50000]\n",
      "loss: 0.119435  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.047109 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.176697  [ 6336/50000]\n",
      "loss: 0.298963  [12736/50000]\n",
      "loss: 0.262358  [19136/50000]\n",
      "loss: 0.183795  [25536/50000]\n",
      "loss: 0.115420  [31936/50000]\n",
      "loss: 0.207960  [38336/50000]\n",
      "loss: 0.161401  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.046990 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.161074  [ 6336/50000]\n",
      "loss: 0.199218  [12736/50000]\n",
      "loss: 0.204587  [19136/50000]\n",
      "loss: 0.429376  [25536/50000]\n",
      "loss: 0.199588  [31936/50000]\n",
      "loss: 0.106628  [38336/50000]\n",
      "loss: 0.233642  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.051045 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.132541  [ 6336/50000]\n",
      "loss: 0.168092  [12736/50000]\n",
      "loss: 0.163204  [19136/50000]\n",
      "loss: 0.177498  [25536/50000]\n",
      "loss: 0.125568  [31936/50000]\n",
      "loss: 0.222424  [38336/50000]\n",
      "loss: 0.146237  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.051152 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.146376  [ 6336/50000]\n",
      "loss: 0.133477  [12736/50000]\n",
      "loss: 0.092003  [19136/50000]\n",
      "loss: 0.127770  [25536/50000]\n",
      "loss: 0.094325  [31936/50000]\n",
      "loss: 0.268970  [38336/50000]\n",
      "loss: 0.254513  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 0.048131 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.144221  [ 6336/50000]\n",
      "loss: 0.264035  [12736/50000]\n",
      "loss: 0.112865  [19136/50000]\n",
      "loss: 0.158724  [25536/50000]\n",
      "loss: 0.091770  [31936/50000]\n",
      "loss: 0.118358  [38336/50000]\n",
      "loss: 0.245243  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 0.049716 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.218161  [ 6336/50000]\n",
      "loss: 0.224138  [12736/50000]\n",
      "loss: 0.091803  [19136/50000]\n",
      "loss: 0.199666  [25536/50000]\n",
      "loss: 0.180553  [31936/50000]\n",
      "loss: 0.242365  [38336/50000]\n",
      "loss: 0.250667  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.050717 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.054028  [ 6336/50000]\n",
      "loss: 0.205506  [12736/50000]\n",
      "loss: 0.142596  [19136/50000]\n",
      "loss: 0.092311  [25536/50000]\n",
      "loss: 0.085516  [31936/50000]\n",
      "loss: 0.178430  [38336/50000]\n",
      "loss: 0.165976  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.053815 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.139426  [ 6336/50000]\n",
      "loss: 0.146245  [12736/50000]\n",
      "loss: 0.126412  [19136/50000]\n",
      "loss: 0.155309  [25536/50000]\n",
      "loss: 0.122883  [31936/50000]\n",
      "loss: 0.078115  [38336/50000]\n",
      "loss: 0.112837  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.053717 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.164317  [ 6336/50000]\n",
      "loss: 0.167359  [12736/50000]\n",
      "loss: 0.141861  [19136/50000]\n",
      "loss: 0.113593  [25536/50000]\n",
      "loss: 0.150605  [31936/50000]\n",
      "loss: 0.285811  [38336/50000]\n",
      "loss: 0.182504  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.056665 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.143909  [ 6336/50000]\n",
      "loss: 0.141329  [12736/50000]\n",
      "loss: 0.092928  [19136/50000]\n",
      "loss: 0.140643  [25536/50000]\n",
      "loss: 0.184296  [31936/50000]\n",
      "loss: 0.144055  [38336/50000]\n",
      "loss: 0.282043  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.051963 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.194829  [ 6336/50000]\n",
      "loss: 0.133385  [12736/50000]\n",
      "loss: 0.126198  [19136/50000]\n",
      "loss: 0.086407  [25536/50000]\n",
      "loss: 0.156561  [31936/50000]\n",
      "loss: 0.283137  [38336/50000]\n",
      "loss: 0.146205  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.055463 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.186932  [ 6336/50000]\n",
      "loss: 0.083623  [12736/50000]\n",
      "loss: 0.093219  [19136/50000]\n",
      "loss: 0.130656  [25536/50000]\n",
      "loss: 0.151054  [31936/50000]\n",
      "loss: 0.122053  [38336/50000]\n",
      "loss: 0.166361  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 0.056235 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.054496  [ 6336/50000]\n",
      "loss: 0.210553  [12736/50000]\n",
      "loss: 0.163349  [19136/50000]\n",
      "loss: 0.183643  [25536/50000]\n",
      "loss: 0.073422  [31936/50000]\n",
      "loss: 0.126162  [38336/50000]\n",
      "loss: 0.153578  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 0.058811 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.109161  [ 6336/50000]\n",
      "loss: 0.045102  [12736/50000]\n",
      "loss: 0.029359  [19136/50000]\n",
      "loss: 0.065706  [25536/50000]\n",
      "loss: 0.158082  [31936/50000]\n",
      "loss: 0.113939  [38336/50000]\n",
      "loss: 0.063430  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.060788 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.037938  [ 6336/50000]\n",
      "loss: 0.024677  [12736/50000]\n",
      "loss: 0.085345  [19136/50000]\n",
      "loss: 0.030691  [25536/50000]\n",
      "loss: 0.134694  [31936/50000]\n",
      "loss: 0.183819  [38336/50000]\n",
      "loss: 0.074252  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.060828 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.122980  [ 6336/50000]\n",
      "loss: 0.109874  [12736/50000]\n",
      "loss: 0.152040  [19136/50000]\n",
      "loss: 0.029763  [25536/50000]\n",
      "loss: 0.094461  [31936/50000]\n",
      "loss: 0.023096  [38336/50000]\n",
      "loss: 0.176397  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.061376 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.061445  [ 6336/50000]\n",
      "loss: 0.136955  [12736/50000]\n",
      "loss: 0.202030  [19136/50000]\n",
      "loss: 0.082334  [25536/50000]\n",
      "loss: 0.138322  [31936/50000]\n",
      "loss: 0.075850  [38336/50000]\n",
      "loss: 0.042600  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.062190 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.089980  [ 6336/50000]\n",
      "loss: 0.161782  [12736/50000]\n",
      "loss: 0.113021  [19136/50000]\n",
      "loss: 0.046565  [25536/50000]\n",
      "loss: 0.142123  [31936/50000]\n",
      "loss: 0.128571  [38336/50000]\n",
      "loss: 0.073114  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 0.066129 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.058018  [ 6336/50000]\n",
      "loss: 0.232188  [12736/50000]\n",
      "loss: 0.066815  [19136/50000]\n",
      "loss: 0.019738  [25536/50000]\n",
      "loss: 0.087895  [31936/50000]\n",
      "loss: 0.052236  [38336/50000]\n",
      "loss: 0.084192  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.062239 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.123613  [ 6336/50000]\n",
      "loss: 0.083223  [12736/50000]\n",
      "loss: 0.098581  [19136/50000]\n",
      "loss: 0.046664  [25536/50000]\n",
      "loss: 0.065134  [31936/50000]\n",
      "loss: 0.169168  [38336/50000]\n",
      "loss: 0.023340  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.062934 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.028371  [ 6336/50000]\n",
      "loss: 0.109276  [12736/50000]\n",
      "loss: 0.022382  [19136/50000]\n",
      "loss: 0.054585  [25536/50000]\n",
      "loss: 0.195174  [31936/50000]\n",
      "loss: 0.079967  [38336/50000]\n",
      "loss: 0.203163  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 0.062731 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.045330  [ 6336/50000]\n",
      "loss: 0.020997  [12736/50000]\n",
      "loss: 0.104875  [19136/50000]\n",
      "loss: 0.034923  [25536/50000]\n",
      "loss: 0.060586  [31936/50000]\n",
      "loss: 0.092460  [38336/50000]\n",
      "loss: 0.115163  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.069354 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.098362  [ 6336/50000]\n",
      "loss: 0.054101  [12736/50000]\n",
      "loss: 0.069294  [19136/50000]\n",
      "loss: 0.059745  [25536/50000]\n",
      "loss: 0.051833  [31936/50000]\n",
      "loss: 0.100761  [38336/50000]\n",
      "loss: 0.069462  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.065972 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.036374  [ 6336/50000]\n",
      "loss: 0.058826  [12736/50000]\n",
      "loss: 0.030674  [19136/50000]\n",
      "loss: 0.061382  [25536/50000]\n",
      "loss: 0.107859  [31936/50000]\n",
      "loss: 0.029132  [38336/50000]\n",
      "loss: 0.035990  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.065393 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.022164  [ 6336/50000]\n",
      "loss: 0.073346  [12736/50000]\n",
      "loss: 0.068657  [19136/50000]\n",
      "loss: 0.074463  [25536/50000]\n",
      "loss: 0.167176  [31936/50000]\n",
      "loss: 0.030294  [38336/50000]\n",
      "loss: 0.075538  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.067923 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.114643  [ 6336/50000]\n",
      "loss: 0.077614  [12736/50000]\n",
      "loss: 0.063761  [19136/50000]\n",
      "loss: 0.021510  [25536/50000]\n",
      "loss: 0.058046  [31936/50000]\n",
      "loss: 0.066609  [38336/50000]\n",
      "loss: 0.036794  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.073224 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.081745  [ 6336/50000]\n",
      "loss: 0.144087  [12736/50000]\n",
      "loss: 0.065925  [19136/50000]\n",
      "loss: 0.138981  [25536/50000]\n",
      "loss: 0.018339  [31936/50000]\n",
      "loss: 0.079924  [38336/50000]\n",
      "loss: 0.154974  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 0.068569 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.089519  [ 6336/50000]\n",
      "loss: 0.027966  [12736/50000]\n",
      "loss: 0.052514  [19136/50000]\n",
      "loss: 0.033075  [25536/50000]\n",
      "loss: 0.174291  [31936/50000]\n",
      "loss: 0.127507  [38336/50000]\n",
      "loss: 0.056945  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.072731 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.046984  [ 6336/50000]\n",
      "loss: 0.016253  [12736/50000]\n",
      "loss: 0.059630  [19136/50000]\n",
      "loss: 0.045715  [25536/50000]\n",
      "loss: 0.082189  [31936/50000]\n",
      "loss: 0.075758  [38336/50000]\n",
      "loss: 0.114060  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.067170 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.073555  [ 6336/50000]\n",
      "loss: 0.017271  [12736/50000]\n",
      "loss: 0.100657  [19136/50000]\n",
      "loss: 0.063890  [25536/50000]\n",
      "loss: 0.011161  [31936/50000]\n",
      "loss: 0.092819  [38336/50000]\n",
      "loss: 0.051003  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.069873 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.099163  [ 6336/50000]\n",
      "loss: 0.091359  [12736/50000]\n",
      "loss: 0.083545  [19136/50000]\n",
      "loss: 0.111384  [25536/50000]\n",
      "loss: 0.013948  [31936/50000]\n",
      "loss: 0.022548  [38336/50000]\n",
      "loss: 0.038549  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.073564 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.098060  [ 6336/50000]\n",
      "loss: 0.049386  [12736/50000]\n",
      "loss: 0.072582  [19136/50000]\n",
      "loss: 0.094254  [25536/50000]\n",
      "loss: 0.057429  [31936/50000]\n",
      "loss: 0.087046  [38336/50000]\n",
      "loss: 0.089682  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.073971 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.075673  [ 6336/50000]\n",
      "loss: 0.040126  [12736/50000]\n",
      "loss: 0.017479  [19136/50000]\n",
      "loss: 0.068071  [25536/50000]\n",
      "loss: 0.023271  [31936/50000]\n",
      "loss: 0.026382  [38336/50000]\n",
      "loss: 0.072146  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 0.069659 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.076085  [ 6336/50000]\n",
      "loss: 0.092258  [12736/50000]\n",
      "loss: 0.051694  [19136/50000]\n",
      "loss: 0.096027  [25536/50000]\n",
      "loss: 0.043748  [31936/50000]\n",
      "loss: 0.102183  [38336/50000]\n",
      "loss: 0.056749  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.073123 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.042175  [ 6336/50000]\n",
      "loss: 0.044009  [12736/50000]\n",
      "loss: 0.091740  [19136/50000]\n",
      "loss: 0.006456  [25536/50000]\n",
      "loss: 0.039277  [31936/50000]\n",
      "loss: 0.075767  [38336/50000]\n",
      "loss: 0.008975  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.073737 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.044269  [ 6336/50000]\n",
      "loss: 0.089409  [12736/50000]\n",
      "loss: 0.021533  [19136/50000]\n",
      "loss: 0.035324  [25536/50000]\n",
      "loss: 0.045061  [31936/50000]\n",
      "loss: 0.088121  [38336/50000]\n",
      "loss: 0.084267  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.072043 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.027352  [ 6336/50000]\n",
      "loss: 0.041455  [12736/50000]\n",
      "loss: 0.016755  [19136/50000]\n",
      "loss: 0.115955  [25536/50000]\n",
      "loss: 0.075725  [31936/50000]\n",
      "loss: 0.025625  [38336/50000]\n",
      "loss: 0.054968  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 0.078002 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.132625  [ 6336/50000]\n",
      "loss: 0.014708  [12736/50000]\n",
      "loss: 0.022518  [19136/50000]\n",
      "loss: 0.016008  [25536/50000]\n",
      "loss: 0.103314  [31936/50000]\n",
      "loss: 0.143135  [38336/50000]\n",
      "loss: 0.030266  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.077630 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.058578  [ 6336/50000]\n",
      "loss: 0.048829  [12736/50000]\n",
      "loss: 0.056183  [19136/50000]\n",
      "loss: 0.053479  [25536/50000]\n",
      "loss: 0.066956  [31936/50000]\n",
      "loss: 0.042939  [38336/50000]\n",
      "loss: 0.059852  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.073839 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.012130  [ 6336/50000]\n",
      "loss: 0.040350  [12736/50000]\n",
      "loss: 0.022881  [19136/50000]\n",
      "loss: 0.045652  [25536/50000]\n",
      "loss: 0.083255  [31936/50000]\n",
      "loss: 0.035383  [38336/50000]\n",
      "loss: 0.015546  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.074123 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.045995  [ 6336/50000]\n",
      "loss: 0.020200  [12736/50000]\n",
      "loss: 0.066647  [19136/50000]\n",
      "loss: 0.058156  [25536/50000]\n",
      "loss: 0.056809  [31936/50000]\n",
      "loss: 0.050575  [38336/50000]\n",
      "loss: 0.086070  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.080699 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.135881  [ 6336/50000]\n",
      "loss: 0.074710  [12736/50000]\n",
      "loss: 0.049270  [19136/50000]\n",
      "loss: 0.068434  [25536/50000]\n",
      "loss: 0.006583  [31936/50000]\n",
      "loss: 0.009928  [38336/50000]\n",
      "loss: 0.095803  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.074890 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.069371  [ 6336/50000]\n",
      "loss: 0.033403  [12736/50000]\n",
      "loss: 0.051441  [19136/50000]\n",
      "loss: 0.014659  [25536/50000]\n",
      "loss: 0.019847  [31936/50000]\n",
      "loss: 0.023503  [38336/50000]\n",
      "loss: 0.057114  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.076956 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.022929  [ 6336/50000]\n",
      "loss: 0.016377  [12736/50000]\n",
      "loss: 0.062749  [19136/50000]\n",
      "loss: 0.079262  [25536/50000]\n",
      "loss: 0.063987  [31936/50000]\n",
      "loss: 0.019511  [38336/50000]\n",
      "loss: 0.043051  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.072141 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.004454  [ 6336/50000]\n",
      "loss: 0.021509  [12736/50000]\n",
      "loss: 0.058259  [19136/50000]\n",
      "loss: 0.017596  [25536/50000]\n",
      "loss: 0.030082  [31936/50000]\n",
      "loss: 0.057023  [38336/50000]\n",
      "loss: 0.015425  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 0.078418 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.010936  [ 6336/50000]\n",
      "loss: 0.005070  [12736/50000]\n",
      "loss: 0.017794  [19136/50000]\n",
      "loss: 0.050307  [25536/50000]\n",
      "loss: 0.021751  [31936/50000]\n",
      "loss: 0.070263  [38336/50000]\n",
      "loss: 0.053422  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.088173 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.031671  [ 6336/50000]\n",
      "loss: 0.017335  [12736/50000]\n",
      "loss: 0.090405  [19136/50000]\n",
      "loss: 0.118702  [25536/50000]\n",
      "loss: 0.085263  [31936/50000]\n",
      "loss: 0.007016  [38336/50000]\n",
      "loss: 0.015452  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.077553 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.024711  [ 6336/50000]\n",
      "loss: 0.016436  [12736/50000]\n",
      "loss: 0.001952  [19136/50000]\n",
      "loss: 0.037720  [25536/50000]\n",
      "loss: 0.041058  [31936/50000]\n",
      "loss: 0.066704  [38336/50000]\n",
      "loss: 0.129078  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.081820 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.017072  [ 6336/50000]\n",
      "loss: 0.007236  [12736/50000]\n",
      "loss: 0.024021  [19136/50000]\n",
      "loss: 0.015549  [25536/50000]\n",
      "loss: 0.028052  [31936/50000]\n",
      "loss: 0.062884  [38336/50000]\n",
      "loss: 0.038485  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.084218 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.003911  [ 6336/50000]\n",
      "loss: 0.064082  [12736/50000]\n",
      "loss: 0.068539  [19136/50000]\n",
      "loss: 0.055020  [25536/50000]\n",
      "loss: 0.059878  [31936/50000]\n",
      "loss: 0.018979  [38336/50000]\n",
      "loss: 0.173293  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 0.083074 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.029512  [ 6336/50000]\n",
      "loss: 0.023293  [12736/50000]\n",
      "loss: 0.027129  [19136/50000]\n",
      "loss: 0.010217  [25536/50000]\n",
      "loss: 0.009969  [31936/50000]\n",
      "loss: 0.064010  [38336/50000]\n",
      "loss: 0.040366  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.077137 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.015993  [ 6336/50000]\n",
      "loss: 0.021378  [12736/50000]\n",
      "loss: 0.013985  [19136/50000]\n",
      "loss: 0.043342  [25536/50000]\n",
      "loss: 0.037898  [31936/50000]\n",
      "loss: 0.044004  [38336/50000]\n",
      "loss: 0.010624  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 0.085004 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.013446  [ 6336/50000]\n",
      "loss: 0.029182  [12736/50000]\n",
      "loss: 0.022470  [19136/50000]\n",
      "loss: 0.044424  [25536/50000]\n",
      "loss: 0.027867  [31936/50000]\n",
      "loss: 0.075678  [38336/50000]\n",
      "loss: 0.043869  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 0.076559 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.120474  [ 6336/50000]\n",
      "loss: 0.017607  [12736/50000]\n",
      "loss: 0.054180  [19136/50000]\n",
      "loss: 0.082519  [25536/50000]\n",
      "loss: 0.005855  [31936/50000]\n",
      "loss: 0.024710  [38336/50000]\n",
      "loss: 0.031477  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.084234 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.018490  [ 6336/50000]\n",
      "loss: 0.130668  [12736/50000]\n",
      "loss: 0.072445  [19136/50000]\n",
      "loss: 0.017453  [25536/50000]\n",
      "loss: 0.020245  [31936/50000]\n",
      "loss: 0.049411  [38336/50000]\n",
      "loss: 0.033105  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.080051 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.053082  [ 6336/50000]\n",
      "loss: 0.025452  [12736/50000]\n",
      "loss: 0.116380  [19136/50000]\n",
      "loss: 0.039877  [25536/50000]\n",
      "loss: 0.026094  [31936/50000]\n",
      "loss: 0.047601  [38336/50000]\n",
      "loss: 0.024140  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 0.079212 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.033973  [ 6336/50000]\n",
      "loss: 0.029238  [12736/50000]\n",
      "loss: 0.008969  [19136/50000]\n",
      "loss: 0.058843  [25536/50000]\n",
      "loss: 0.017112  [31936/50000]\n",
      "loss: 0.013554  [38336/50000]\n",
      "loss: 0.014042  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 0.083067 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.016150  [ 6336/50000]\n",
      "loss: 0.005295  [12736/50000]\n",
      "loss: 0.093905  [19136/50000]\n",
      "loss: 0.062930  [25536/50000]\n",
      "loss: 0.068726  [31936/50000]\n",
      "loss: 0.012610  [38336/50000]\n",
      "loss: 0.158203  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.080406 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.026770  [ 6336/50000]\n",
      "loss: 0.014710  [12736/50000]\n",
      "loss: 0.015166  [19136/50000]\n",
      "loss: 0.016868  [25536/50000]\n",
      "loss: 0.096076  [31936/50000]\n",
      "loss: 0.017814  [38336/50000]\n",
      "loss: 0.019710  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.081793 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.038047  [ 6336/50000]\n",
      "loss: 0.005406  [12736/50000]\n",
      "loss: 0.025831  [19136/50000]\n",
      "loss: 0.019902  [25536/50000]\n",
      "loss: 0.063793  [31936/50000]\n",
      "loss: 0.043800  [38336/50000]\n",
      "loss: 0.033618  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.080060 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.021696  [ 6336/50000]\n",
      "loss: 0.027585  [12736/50000]\n",
      "loss: 0.045630  [19136/50000]\n",
      "loss: 0.007836  [25536/50000]\n",
      "loss: 0.040348  [31936/50000]\n",
      "loss: 0.060588  [38336/50000]\n",
      "loss: 0.085643  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 0.082761 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.007733  [ 6336/50000]\n",
      "loss: 0.111839  [12736/50000]\n",
      "loss: 0.010318  [19136/50000]\n",
      "loss: 0.059541  [25536/50000]\n",
      "loss: 0.060804  [31936/50000]\n",
      "loss: 0.025336  [38336/50000]\n",
      "loss: 0.002095  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.085087 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.107234  [ 6336/50000]\n",
      "loss: 0.001128  [12736/50000]\n",
      "loss: 0.038549  [19136/50000]\n",
      "loss: 0.004285  [25536/50000]\n",
      "loss: 0.072402  [31936/50000]\n",
      "loss: 0.040181  [38336/50000]\n",
      "loss: 0.030333  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.083584 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.067013  [ 6336/50000]\n",
      "loss: 0.005954  [12736/50000]\n",
      "loss: 0.002678  [19136/50000]\n",
      "loss: 0.008476  [25536/50000]\n",
      "loss: 0.018074  [31936/50000]\n",
      "loss: 0.104102  [38336/50000]\n",
      "loss: 0.117337  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.082529 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.014949  [ 6336/50000]\n",
      "loss: 0.023500  [12736/50000]\n",
      "loss: 0.014204  [19136/50000]\n",
      "loss: 0.043028  [25536/50000]\n",
      "loss: 0.019429  [31936/50000]\n",
      "loss: 0.114336  [38336/50000]\n",
      "loss: 0.230046  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.079314 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.022395  [ 6336/50000]\n",
      "loss: 0.077931  [12736/50000]\n",
      "loss: 0.064679  [19136/50000]\n",
      "loss: 0.025075  [25536/50000]\n",
      "loss: 0.024098  [31936/50000]\n",
      "loss: 0.041381  [38336/50000]\n",
      "loss: 0.046715  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 0.082054 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.022839  [ 6336/50000]\n",
      "loss: 0.029207  [12736/50000]\n",
      "loss: 0.004453  [19136/50000]\n",
      "loss: 0.037773  [25536/50000]\n",
      "loss: 0.021888  [31936/50000]\n",
      "loss: 0.012531  [38336/50000]\n",
      "loss: 0.006964  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.084233 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.004784  [ 6336/50000]\n",
      "loss: 0.001300  [12736/50000]\n",
      "loss: 0.143716  [19136/50000]\n",
      "loss: 0.040882  [25536/50000]\n",
      "loss: 0.025120  [31936/50000]\n",
      "loss: 0.019813  [38336/50000]\n",
      "loss: 0.028927  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 0.083459 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.005429  [ 6336/50000]\n",
      "loss: 0.065451  [12736/50000]\n",
      "loss: 0.030697  [19136/50000]\n",
      "loss: 0.003239  [25536/50000]\n",
      "loss: 0.005510  [31936/50000]\n",
      "loss: 0.002023  [38336/50000]\n",
      "loss: 0.003680  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.083185 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.008995  [ 6336/50000]\n",
      "loss: 0.027638  [12736/50000]\n",
      "loss: 0.061572  [19136/50000]\n",
      "loss: 0.035243  [25536/50000]\n",
      "loss: 0.047276  [31936/50000]\n",
      "loss: 0.004814  [38336/50000]\n",
      "loss: 0.113164  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 0.089551 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.025612  [ 6336/50000]\n",
      "loss: 0.021465  [12736/50000]\n",
      "loss: 0.019137  [19136/50000]\n",
      "loss: 0.015945  [25536/50000]\n",
      "loss: 0.119713  [31936/50000]\n",
      "loss: 0.009622  [38336/50000]\n",
      "loss: 0.035904  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.080590 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.153273  [ 6336/50000]\n",
      "loss: 0.075434  [12736/50000]\n",
      "loss: 0.033884  [19136/50000]\n",
      "loss: 0.032157  [25536/50000]\n",
      "loss: 0.007789  [31936/50000]\n",
      "loss: 0.012216  [38336/50000]\n",
      "loss: 0.008289  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 0.084143 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.029891  [ 6336/50000]\n",
      "loss: 0.005263  [12736/50000]\n",
      "loss: 0.027737  [19136/50000]\n",
      "loss: 0.126819  [25536/50000]\n",
      "loss: 0.051921  [31936/50000]\n",
      "loss: 0.018015  [38336/50000]\n",
      "loss: 0.078264  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 0.084193 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.053688  [ 6336/50000]\n",
      "loss: 0.008825  [12736/50000]\n",
      "loss: 0.009805  [19136/50000]\n",
      "loss: 0.039742  [25536/50000]\n",
      "loss: 0.007281  [31936/50000]\n",
      "loss: 0.001832  [38336/50000]\n",
      "loss: 0.015711  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.089821 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.008845  [ 6336/50000]\n",
      "loss: 0.006671  [12736/50000]\n",
      "loss: 0.004313  [19136/50000]\n",
      "loss: 0.059416  [25536/50000]\n",
      "loss: 0.004369  [31936/50000]\n",
      "loss: 0.020288  [38336/50000]\n",
      "loss: 0.038204  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.092675 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.021900  [ 6336/50000]\n",
      "loss: 0.024399  [12736/50000]\n",
      "loss: 0.008213  [19136/50000]\n",
      "loss: 0.014737  [25536/50000]\n",
      "loss: 0.037742  [31936/50000]\n",
      "loss: 0.129048  [38336/50000]\n",
      "loss: 0.022943  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 0.089093 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.003585  [ 6336/50000]\n",
      "loss: 0.002936  [12736/50000]\n",
      "loss: 0.010948  [19136/50000]\n",
      "loss: 0.006154  [25536/50000]\n",
      "loss: 0.025781  [31936/50000]\n",
      "loss: 0.078515  [38336/50000]\n",
      "loss: 0.029374  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.092814 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.003809  [ 6336/50000]\n",
      "loss: 0.026032  [12736/50000]\n",
      "loss: 0.049475  [19136/50000]\n",
      "loss: 0.005619  [25536/50000]\n",
      "loss: 0.012307  [31936/50000]\n",
      "loss: 0.018190  [38336/50000]\n",
      "loss: 0.048173  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 0.088278 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.073078  [ 6336/50000]\n",
      "loss: 0.127345  [12736/50000]\n",
      "loss: 0.013154  [19136/50000]\n",
      "loss: 0.047104  [25536/50000]\n",
      "loss: 0.050358  [31936/50000]\n",
      "loss: 0.008386  [38336/50000]\n",
      "loss: 0.012076  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.086433 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.105768  [ 6336/50000]\n",
      "loss: 0.008335  [12736/50000]\n",
      "loss: 0.076799  [19136/50000]\n",
      "loss: 0.000482  [25536/50000]\n",
      "loss: 0.009023  [31936/50000]\n",
      "loss: 0.026257  [38336/50000]\n",
      "loss: 0.054429  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.089199 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.038917  [ 6336/50000]\n",
      "loss: 0.004831  [12736/50000]\n",
      "loss: 0.001451  [19136/50000]\n",
      "loss: 0.003152  [25536/50000]\n",
      "loss: 0.003452  [31936/50000]\n",
      "loss: 0.025574  [38336/50000]\n",
      "loss: 0.002092  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.091694 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.006304  [ 6336/50000]\n",
      "loss: 0.013940  [12736/50000]\n",
      "loss: 0.004840  [19136/50000]\n",
      "loss: 0.011742  [25536/50000]\n",
      "loss: 0.161866  [31936/50000]\n",
      "loss: 0.034873  [38336/50000]\n",
      "loss: 0.003087  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.089983 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.028829  [ 6336/50000]\n",
      "loss: 0.009615  [12736/50000]\n",
      "loss: 0.004972  [19136/50000]\n",
      "loss: 0.034502  [25536/50000]\n",
      "loss: 0.009248  [31936/50000]\n",
      "loss: 0.006367  [38336/50000]\n",
      "loss: 0.008063  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.091132 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.062951  [ 6336/50000]\n",
      "loss: 0.023761  [12736/50000]\n",
      "loss: 0.011727  [19136/50000]\n",
      "loss: 0.011160  [25536/50000]\n",
      "loss: 0.003483  [31936/50000]\n",
      "loss: 0.038781  [38336/50000]\n",
      "loss: 0.017742  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.094935 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.096761  [ 6336/50000]\n",
      "loss: 0.018811  [12736/50000]\n",
      "loss: 0.003927  [19136/50000]\n",
      "loss: 0.062389  [25536/50000]\n",
      "loss: 0.025175  [31936/50000]\n",
      "loss: 0.016668  [38336/50000]\n",
      "loss: 0.015588  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 0.090611 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.023782  [ 6336/50000]\n",
      "loss: 0.023901  [12736/50000]\n",
      "loss: 0.063957  [19136/50000]\n",
      "loss: 0.009574  [25536/50000]\n",
      "loss: 0.052929  [31936/50000]\n",
      "loss: 0.007078  [38336/50000]\n",
      "loss: 0.006314  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 0.097051 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.003607  [ 6336/50000]\n",
      "loss: 0.073127  [12736/50000]\n",
      "loss: 0.008330  [19136/50000]\n",
      "loss: 0.006333  [25536/50000]\n",
      "loss: 0.029868  [31936/50000]\n",
      "loss: 0.000306  [38336/50000]\n",
      "loss: 0.015369  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 0.095775 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.030817  [ 6336/50000]\n",
      "loss: 0.011665  [12736/50000]\n",
      "loss: 0.003421  [19136/50000]\n",
      "loss: 0.014229  [25536/50000]\n",
      "loss: 0.009938  [31936/50000]\n",
      "loss: 0.002746  [38336/50000]\n",
      "loss: 0.013574  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.093229 \n",
      "\n",
      "Finished Training Net + <class 'p4_conv.P4NetC'>\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300050  [ 6336/50000]\n",
      "loss: 2.297399  [12736/50000]\n",
      "loss: 2.303571  [19136/50000]\n",
      "loss: 2.304504  [25536/50000]\n",
      "loss: 2.301829  [31936/50000]\n",
      "loss: 2.304017  [38336/50000]\n",
      "loss: 2.302432  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 0.036145 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.300688  [ 6336/50000]\n",
      "loss: 2.301158  [12736/50000]\n",
      "loss: 2.303060  [19136/50000]\n",
      "loss: 2.304592  [25536/50000]\n",
      "loss: 2.302181  [31936/50000]\n",
      "loss: 2.300474  [38336/50000]\n",
      "loss: 2.302902  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 11.7%, Avg loss: 0.036129 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.301471  [ 6336/50000]\n",
      "loss: 2.303496  [12736/50000]\n",
      "loss: 2.299271  [19136/50000]\n",
      "loss: 2.299543  [25536/50000]\n",
      "loss: 2.301142  [31936/50000]\n",
      "loss: 2.298394  [38336/50000]\n",
      "loss: 2.299608  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 17.0%, Avg loss: 0.036077 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.299234  [ 6336/50000]\n",
      "loss: 2.290246  [12736/50000]\n",
      "loss: 2.298251  [19136/50000]\n",
      "loss: 2.295521  [25536/50000]\n",
      "loss: 2.284866  [31936/50000]\n",
      "loss: 2.274828  [38336/50000]\n",
      "loss: 2.272063  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 15.6%, Avg loss: 0.035311 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.252866  [ 6336/50000]\n",
      "loss: 2.222094  [12736/50000]\n",
      "loss: 2.248920  [19136/50000]\n",
      "loss: 2.181937  [25536/50000]\n",
      "loss: 2.221164  [31936/50000]\n",
      "loss: 2.232299  [38336/50000]\n",
      "loss: 2.113596  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 19.7%, Avg loss: 0.033388 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.086988  [ 6336/50000]\n",
      "loss: 2.123118  [12736/50000]\n",
      "loss: 2.189270  [19136/50000]\n",
      "loss: 2.094241  [25536/50000]\n",
      "loss: 2.124585  [31936/50000]\n",
      "loss: 2.092415  [38336/50000]\n",
      "loss: 2.014879  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 23.6%, Avg loss: 0.031806 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.169233  [ 6336/50000]\n",
      "loss: 1.870644  [12736/50000]\n",
      "loss: 1.971808  [19136/50000]\n",
      "loss: 2.071916  [25536/50000]\n",
      "loss: 2.083783  [31936/50000]\n",
      "loss: 2.004271  [38336/50000]\n",
      "loss: 1.962164  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 26.4%, Avg loss: 0.030940 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.834353  [ 6336/50000]\n",
      "loss: 1.988752  [12736/50000]\n",
      "loss: 1.885321  [19136/50000]\n",
      "loss: 1.774854  [25536/50000]\n",
      "loss: 1.937442  [31936/50000]\n",
      "loss: 1.801102  [38336/50000]\n",
      "loss: 1.839362  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 0.030532 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.910420  [ 6336/50000]\n",
      "loss: 1.950713  [12736/50000]\n",
      "loss: 1.875613  [19136/50000]\n",
      "loss: 1.865365  [25536/50000]\n",
      "loss: 1.994395  [31936/50000]\n",
      "loss: 1.943593  [38336/50000]\n",
      "loss: 1.825885  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 0.029319 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.785833  [ 6336/50000]\n",
      "loss: 1.784762  [12736/50000]\n",
      "loss: 1.753838  [19136/50000]\n",
      "loss: 1.905685  [25536/50000]\n",
      "loss: 1.687817  [31936/50000]\n",
      "loss: 2.015439  [38336/50000]\n",
      "loss: 1.783659  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 29.8%, Avg loss: 0.029911 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.786306  [ 6336/50000]\n",
      "loss: 1.890200  [12736/50000]\n",
      "loss: 1.825359  [19136/50000]\n",
      "loss: 1.754101  [25536/50000]\n",
      "loss: 1.682000  [31936/50000]\n",
      "loss: 1.970614  [38336/50000]\n",
      "loss: 1.945485  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.9%, Avg loss: 0.028095 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.803674  [ 6336/50000]\n",
      "loss: 1.838776  [12736/50000]\n",
      "loss: 1.898283  [19136/50000]\n",
      "loss: 1.739686  [25536/50000]\n",
      "loss: 1.656083  [31936/50000]\n",
      "loss: 1.786185  [38336/50000]\n",
      "loss: 1.968658  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.027298 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.914259  [ 6336/50000]\n",
      "loss: 1.621931  [12736/50000]\n",
      "loss: 1.871353  [19136/50000]\n",
      "loss: 1.731828  [25536/50000]\n",
      "loss: 1.534607  [31936/50000]\n",
      "loss: 1.726395  [38336/50000]\n",
      "loss: 1.717133  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 0.027008 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.693645  [ 6336/50000]\n",
      "loss: 1.916145  [12736/50000]\n",
      "loss: 1.737958  [19136/50000]\n",
      "loss: 1.796095  [25536/50000]\n",
      "loss: 1.708344  [31936/50000]\n",
      "loss: 1.740147  [38336/50000]\n",
      "loss: 1.789636  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 0.026375 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.596501  [ 6336/50000]\n",
      "loss: 1.832830  [12736/50000]\n",
      "loss: 1.712072  [19136/50000]\n",
      "loss: 1.680213  [25536/50000]\n",
      "loss: 1.546962  [31936/50000]\n",
      "loss: 1.841364  [38336/50000]\n",
      "loss: 1.608098  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.2%, Avg loss: 0.025936 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.774072  [ 6336/50000]\n",
      "loss: 1.647998  [12736/50000]\n",
      "loss: 1.690147  [19136/50000]\n",
      "loss: 1.633873  [25536/50000]\n",
      "loss: 1.694487  [31936/50000]\n",
      "loss: 1.813164  [38336/50000]\n",
      "loss: 1.630235  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 0.025751 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.614885  [ 6336/50000]\n",
      "loss: 1.563854  [12736/50000]\n",
      "loss: 1.617362  [19136/50000]\n",
      "loss: 1.628215  [25536/50000]\n",
      "loss: 1.523418  [31936/50000]\n",
      "loss: 1.802354  [38336/50000]\n",
      "loss: 1.791004  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 0.025261 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.499311  [ 6336/50000]\n",
      "loss: 1.489545  [12736/50000]\n",
      "loss: 1.682064  [19136/50000]\n",
      "loss: 1.558322  [25536/50000]\n",
      "loss: 1.496351  [31936/50000]\n",
      "loss: 1.499860  [38336/50000]\n",
      "loss: 1.471712  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.3%, Avg loss: 0.025859 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.629394  [ 6336/50000]\n",
      "loss: 1.503561  [12736/50000]\n",
      "loss: 1.571549  [19136/50000]\n",
      "loss: 1.629487  [25536/50000]\n",
      "loss: 1.593824  [31936/50000]\n",
      "loss: 1.598477  [38336/50000]\n",
      "loss: 1.536693  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 0.024744 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.530107  [ 6336/50000]\n",
      "loss: 1.466494  [12736/50000]\n",
      "loss: 1.685486  [19136/50000]\n",
      "loss: 1.544272  [25536/50000]\n",
      "loss: 1.554073  [31936/50000]\n",
      "loss: 1.486170  [38336/50000]\n",
      "loss: 1.719670  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 42.6%, Avg loss: 0.024323 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.826821  [ 6336/50000]\n",
      "loss: 1.285851  [12736/50000]\n",
      "loss: 1.533898  [19136/50000]\n",
      "loss: 1.745903  [25536/50000]\n",
      "loss: 1.614731  [31936/50000]\n",
      "loss: 1.764579  [38336/50000]\n",
      "loss: 1.553255  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 0.024058 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.610917  [ 6336/50000]\n",
      "loss: 1.703307  [12736/50000]\n",
      "loss: 1.531644  [19136/50000]\n",
      "loss: 1.281091  [25536/50000]\n",
      "loss: 1.649787  [31936/50000]\n",
      "loss: 1.314022  [38336/50000]\n",
      "loss: 1.590516  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 0.023839 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.418184  [ 6336/50000]\n",
      "loss: 1.440819  [12736/50000]\n",
      "loss: 1.515096  [19136/50000]\n",
      "loss: 1.243988  [25536/50000]\n",
      "loss: 1.436926  [31936/50000]\n",
      "loss: 1.579813  [38336/50000]\n",
      "loss: 1.353329  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.023495 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.531663  [ 6336/50000]\n",
      "loss: 1.072656  [12736/50000]\n",
      "loss: 1.786087  [19136/50000]\n",
      "loss: 1.480606  [25536/50000]\n",
      "loss: 1.452970  [31936/50000]\n",
      "loss: 1.619552  [38336/50000]\n",
      "loss: 1.471883  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 0.023053 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.677842  [ 6336/50000]\n",
      "loss: 1.460236  [12736/50000]\n",
      "loss: 1.373275  [19136/50000]\n",
      "loss: 1.641922  [25536/50000]\n",
      "loss: 1.436335  [31936/50000]\n",
      "loss: 1.417753  [38336/50000]\n",
      "loss: 1.362924  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 0.022948 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.400921  [ 6336/50000]\n",
      "loss: 1.337333  [12736/50000]\n",
      "loss: 1.521255  [19136/50000]\n",
      "loss: 1.583449  [25536/50000]\n",
      "loss: 1.432839  [31936/50000]\n",
      "loss: 1.318352  [38336/50000]\n",
      "loss: 1.428787  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.023064 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.452805  [ 6336/50000]\n",
      "loss: 1.631295  [12736/50000]\n",
      "loss: 1.327714  [19136/50000]\n",
      "loss: 1.526352  [25536/50000]\n",
      "loss: 1.629877  [31936/50000]\n",
      "loss: 1.478464  [38336/50000]\n",
      "loss: 1.406905  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 0.022430 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.628866  [ 6336/50000]\n",
      "loss: 1.603314  [12736/50000]\n",
      "loss: 1.670145  [19136/50000]\n",
      "loss: 1.275692  [25536/50000]\n",
      "loss: 1.380424  [31936/50000]\n",
      "loss: 1.310581  [38336/50000]\n",
      "loss: 1.376221  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 0.022568 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.448293  [ 6336/50000]\n",
      "loss: 1.264852  [12736/50000]\n",
      "loss: 1.471870  [19136/50000]\n",
      "loss: 1.297933  [25536/50000]\n",
      "loss: 1.398077  [31936/50000]\n",
      "loss: 1.413260  [38336/50000]\n",
      "loss: 1.469878  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.022571 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.379973  [ 6336/50000]\n",
      "loss: 1.468211  [12736/50000]\n",
      "loss: 1.458611  [19136/50000]\n",
      "loss: 1.293281  [25536/50000]\n",
      "loss: 1.515304  [31936/50000]\n",
      "loss: 1.294044  [38336/50000]\n",
      "loss: 1.394027  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 0.021953 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.314088  [ 6336/50000]\n",
      "loss: 1.456668  [12736/50000]\n",
      "loss: 1.330496  [19136/50000]\n",
      "loss: 1.594681  [25536/50000]\n",
      "loss: 1.468174  [31936/50000]\n",
      "loss: 1.300982  [38336/50000]\n",
      "loss: 1.244864  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: 0.021627 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.146395  [ 6336/50000]\n",
      "loss: 1.226919  [12736/50000]\n",
      "loss: 1.569223  [19136/50000]\n",
      "loss: 1.452292  [25536/50000]\n",
      "loss: 1.380403  [31936/50000]\n",
      "loss: 1.314887  [38336/50000]\n",
      "loss: 1.521253  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: 0.021548 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.375216  [ 6336/50000]\n",
      "loss: 1.325517  [12736/50000]\n",
      "loss: 1.433744  [19136/50000]\n",
      "loss: 1.462551  [25536/50000]\n",
      "loss: 1.377648  [31936/50000]\n",
      "loss: 1.443758  [38336/50000]\n",
      "loss: 1.228432  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 0.021359 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.539871  [ 6336/50000]\n",
      "loss: 1.394187  [12736/50000]\n",
      "loss: 1.358655  [19136/50000]\n",
      "loss: 1.169449  [25536/50000]\n",
      "loss: 1.284037  [31936/50000]\n",
      "loss: 1.273516  [38336/50000]\n",
      "loss: 1.203901  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 0.021738 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.407605  [ 6336/50000]\n",
      "loss: 1.343198  [12736/50000]\n",
      "loss: 1.255063  [19136/50000]\n",
      "loss: 1.483497  [25536/50000]\n",
      "loss: 1.158005  [31936/50000]\n",
      "loss: 1.138954  [38336/50000]\n",
      "loss: 1.218751  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.020975 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.131387  [ 6336/50000]\n",
      "loss: 1.635582  [12736/50000]\n",
      "loss: 1.353428  [19136/50000]\n",
      "loss: 1.191727  [25536/50000]\n",
      "loss: 1.387322  [31936/50000]\n",
      "loss: 1.314129  [38336/50000]\n",
      "loss: 1.461973  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 0.020860 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.295848  [ 6336/50000]\n",
      "loss: 1.243198  [12736/50000]\n",
      "loss: 1.064924  [19136/50000]\n",
      "loss: 1.128863  [25536/50000]\n",
      "loss: 1.162868  [31936/50000]\n",
      "loss: 1.238554  [38336/50000]\n",
      "loss: 1.135152  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 0.020793 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.486604  [ 6336/50000]\n",
      "loss: 1.281496  [12736/50000]\n",
      "loss: 1.107954  [19136/50000]\n",
      "loss: 1.166358  [25536/50000]\n",
      "loss: 1.199422  [31936/50000]\n",
      "loss: 1.397196  [38336/50000]\n",
      "loss: 1.375466  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.020340 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.439415  [ 6336/50000]\n",
      "loss: 1.385512  [12736/50000]\n",
      "loss: 1.245609  [19136/50000]\n",
      "loss: 1.381981  [25536/50000]\n",
      "loss: 1.090310  [31936/50000]\n",
      "loss: 1.279378  [38336/50000]\n",
      "loss: 1.354207  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.020521 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.390819  [ 6336/50000]\n",
      "loss: 1.193955  [12736/50000]\n",
      "loss: 1.128105  [19136/50000]\n",
      "loss: 1.248076  [25536/50000]\n",
      "loss: 1.177728  [31936/50000]\n",
      "loss: 1.387751  [38336/50000]\n",
      "loss: 1.314547  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.019966 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.238836  [ 6336/50000]\n",
      "loss: 1.454069  [12736/50000]\n",
      "loss: 1.384297  [19136/50000]\n",
      "loss: 1.175972  [25536/50000]\n",
      "loss: 1.089774  [31936/50000]\n",
      "loss: 1.451460  [38336/50000]\n",
      "loss: 1.494356  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.019980 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.376172  [ 6336/50000]\n",
      "loss: 1.255884  [12736/50000]\n",
      "loss: 1.183329  [19136/50000]\n",
      "loss: 1.160449  [25536/50000]\n",
      "loss: 1.233445  [31936/50000]\n",
      "loss: 1.303084  [38336/50000]\n",
      "loss: 1.377918  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.020209 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.223951  [ 6336/50000]\n",
      "loss: 1.348557  [12736/50000]\n",
      "loss: 1.132020  [19136/50000]\n",
      "loss: 1.324566  [25536/50000]\n",
      "loss: 1.270386  [31936/50000]\n",
      "loss: 1.232838  [38336/50000]\n",
      "loss: 1.047979  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 0.019673 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.025980  [ 6336/50000]\n",
      "loss: 1.226393  [12736/50000]\n",
      "loss: 1.180923  [19136/50000]\n",
      "loss: 1.253469  [25536/50000]\n",
      "loss: 1.214697  [31936/50000]\n",
      "loss: 1.056466  [38336/50000]\n",
      "loss: 1.361944  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.019913 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.217397  [ 6336/50000]\n",
      "loss: 1.098996  [12736/50000]\n",
      "loss: 1.262887  [19136/50000]\n",
      "loss: 1.288269  [25536/50000]\n",
      "loss: 1.244167  [31936/50000]\n",
      "loss: 1.400796  [38336/50000]\n",
      "loss: 1.288923  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 0.019500 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.968328  [ 6336/50000]\n",
      "loss: 1.282979  [12736/50000]\n",
      "loss: 1.130183  [19136/50000]\n",
      "loss: 1.078754  [25536/50000]\n",
      "loss: 1.224140  [31936/50000]\n",
      "loss: 1.176395  [38336/50000]\n",
      "loss: 1.529783  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.020330 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.270620  [ 6336/50000]\n",
      "loss: 1.454347  [12736/50000]\n",
      "loss: 1.306613  [19136/50000]\n",
      "loss: 1.349938  [25536/50000]\n",
      "loss: 1.040839  [31936/50000]\n",
      "loss: 1.238651  [38336/50000]\n",
      "loss: 1.106090  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 0.019087 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.304412  [ 6336/50000]\n",
      "loss: 1.115443  [12736/50000]\n",
      "loss: 1.171994  [19136/50000]\n",
      "loss: 1.098715  [25536/50000]\n",
      "loss: 1.280354  [31936/50000]\n",
      "loss: 1.245300  [38336/50000]\n",
      "loss: 1.322240  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.019087 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.363549  [ 6336/50000]\n",
      "loss: 1.323605  [12736/50000]\n",
      "loss: 0.965923  [19136/50000]\n",
      "loss: 1.302204  [25536/50000]\n",
      "loss: 1.046522  [31936/50000]\n",
      "loss: 1.258255  [38336/50000]\n",
      "loss: 0.974051  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.018932 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.207223  [ 6336/50000]\n",
      "loss: 1.189210  [12736/50000]\n",
      "loss: 1.212705  [19136/50000]\n",
      "loss: 1.310234  [25536/50000]\n",
      "loss: 1.241651  [31936/50000]\n",
      "loss: 1.246240  [38336/50000]\n",
      "loss: 1.263470  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.019455 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.328078  [ 6336/50000]\n",
      "loss: 1.138386  [12736/50000]\n",
      "loss: 1.172116  [19136/50000]\n",
      "loss: 1.123240  [25536/50000]\n",
      "loss: 1.047074  [31936/50000]\n",
      "loss: 1.430408  [38336/50000]\n",
      "loss: 1.292992  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.019106 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.056146  [ 6336/50000]\n",
      "loss: 0.992072  [12736/50000]\n",
      "loss: 1.110505  [19136/50000]\n",
      "loss: 1.031964  [25536/50000]\n",
      "loss: 1.042386  [31936/50000]\n",
      "loss: 1.145176  [38336/50000]\n",
      "loss: 1.166866  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.018887 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 1.249152  [ 6336/50000]\n",
      "loss: 1.217759  [12736/50000]\n",
      "loss: 1.312704  [19136/50000]\n",
      "loss: 1.158152  [25536/50000]\n",
      "loss: 1.340018  [31936/50000]\n",
      "loss: 1.161177  [38336/50000]\n",
      "loss: 1.090362  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.018811 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.228828  [ 6336/50000]\n",
      "loss: 1.070899  [12736/50000]\n",
      "loss: 1.107920  [19136/50000]\n",
      "loss: 1.206003  [25536/50000]\n",
      "loss: 1.199263  [31936/50000]\n",
      "loss: 1.158200  [38336/50000]\n",
      "loss: 1.283151  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.018287 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.116055  [ 6336/50000]\n",
      "loss: 1.126751  [12736/50000]\n",
      "loss: 0.970850  [19136/50000]\n",
      "loss: 1.134854  [25536/50000]\n",
      "loss: 1.178936  [31936/50000]\n",
      "loss: 1.129017  [38336/50000]\n",
      "loss: 1.077189  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.018724 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.034010  [ 6336/50000]\n",
      "loss: 1.168132  [12736/50000]\n",
      "loss: 1.346572  [19136/50000]\n",
      "loss: 1.162765  [25536/50000]\n",
      "loss: 1.342199  [31936/50000]\n",
      "loss: 0.893985  [38336/50000]\n",
      "loss: 1.094578  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.017998 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.044600  [ 6336/50000]\n",
      "loss: 0.999533  [12736/50000]\n",
      "loss: 1.245873  [19136/50000]\n",
      "loss: 1.009265  [25536/50000]\n",
      "loss: 1.008976  [31936/50000]\n",
      "loss: 0.861661  [38336/50000]\n",
      "loss: 1.114707  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.018334 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.097975  [ 6336/50000]\n",
      "loss: 1.039015  [12736/50000]\n",
      "loss: 1.400485  [19136/50000]\n",
      "loss: 0.975207  [25536/50000]\n",
      "loss: 1.191294  [31936/50000]\n",
      "loss: 1.015397  [38336/50000]\n",
      "loss: 0.907398  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 0.018029 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.995035  [ 6336/50000]\n",
      "loss: 1.566437  [12736/50000]\n",
      "loss: 0.999712  [19136/50000]\n",
      "loss: 0.837565  [25536/50000]\n",
      "loss: 0.886322  [31936/50000]\n",
      "loss: 1.040563  [38336/50000]\n",
      "loss: 1.154721  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.018064 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.175181  [ 6336/50000]\n",
      "loss: 1.006282  [12736/50000]\n",
      "loss: 1.061891  [19136/50000]\n",
      "loss: 1.179618  [25536/50000]\n",
      "loss: 1.000247  [31936/50000]\n",
      "loss: 1.066863  [38336/50000]\n",
      "loss: 1.202129  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 0.018569 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.187582  [ 6336/50000]\n",
      "loss: 1.023935  [12736/50000]\n",
      "loss: 1.185893  [19136/50000]\n",
      "loss: 1.088476  [25536/50000]\n",
      "loss: 0.926569  [31936/50000]\n",
      "loss: 1.066596  [38336/50000]\n",
      "loss: 1.127167  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.017633 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 1.174072  [ 6336/50000]\n",
      "loss: 0.894529  [12736/50000]\n",
      "loss: 1.189452  [19136/50000]\n",
      "loss: 1.205062  [25536/50000]\n",
      "loss: 1.169349  [31936/50000]\n",
      "loss: 0.975006  [38336/50000]\n",
      "loss: 1.123804  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.017449 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.170017  [ 6336/50000]\n",
      "loss: 1.048741  [12736/50000]\n",
      "loss: 1.228212  [19136/50000]\n",
      "loss: 1.197612  [25536/50000]\n",
      "loss: 0.847811  [31936/50000]\n",
      "loss: 1.239748  [38336/50000]\n",
      "loss: 0.924507  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 0.017707 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.826741  [ 6336/50000]\n",
      "loss: 0.936343  [12736/50000]\n",
      "loss: 1.352047  [19136/50000]\n",
      "loss: 1.095192  [25536/50000]\n",
      "loss: 1.188744  [31936/50000]\n",
      "loss: 1.006142  [38336/50000]\n",
      "loss: 1.085684  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.017661 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.007430  [ 6336/50000]\n",
      "loss: 0.953291  [12736/50000]\n",
      "loss: 0.994630  [19136/50000]\n",
      "loss: 1.007682  [25536/50000]\n",
      "loss: 1.223244  [31936/50000]\n",
      "loss: 0.956102  [38336/50000]\n",
      "loss: 1.027691  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.017323 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 1.068081  [ 6336/50000]\n",
      "loss: 1.147129  [12736/50000]\n",
      "loss: 1.232568  [19136/50000]\n",
      "loss: 1.329767  [25536/50000]\n",
      "loss: 1.173620  [31936/50000]\n",
      "loss: 0.739671  [38336/50000]\n",
      "loss: 1.152769  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.017780 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.937230  [ 6336/50000]\n",
      "loss: 0.917391  [12736/50000]\n",
      "loss: 1.306505  [19136/50000]\n",
      "loss: 0.926311  [25536/50000]\n",
      "loss: 0.967951  [31936/50000]\n",
      "loss: 0.821218  [38336/50000]\n",
      "loss: 1.049252  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.017337 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.198508  [ 6336/50000]\n",
      "loss: 1.012102  [12736/50000]\n",
      "loss: 1.034931  [19136/50000]\n",
      "loss: 1.194624  [25536/50000]\n",
      "loss: 0.869008  [31936/50000]\n",
      "loss: 1.250716  [38336/50000]\n",
      "loss: 0.836463  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.016828 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.885101  [ 6336/50000]\n",
      "loss: 0.899584  [12736/50000]\n",
      "loss: 0.930546  [19136/50000]\n",
      "loss: 1.018843  [25536/50000]\n",
      "loss: 0.970924  [31936/50000]\n",
      "loss: 1.103464  [38336/50000]\n",
      "loss: 0.826725  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.016813 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.051949  [ 6336/50000]\n",
      "loss: 1.012014  [12736/50000]\n",
      "loss: 1.113398  [19136/50000]\n",
      "loss: 0.949340  [25536/50000]\n",
      "loss: 0.947607  [31936/50000]\n",
      "loss: 1.038211  [38336/50000]\n",
      "loss: 1.131097  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.016998 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.801270  [ 6336/50000]\n",
      "loss: 1.055391  [12736/50000]\n",
      "loss: 1.032917  [19136/50000]\n",
      "loss: 1.221386  [25536/50000]\n",
      "loss: 0.810242  [31936/50000]\n",
      "loss: 1.064992  [38336/50000]\n",
      "loss: 0.907539  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 0.017509 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.882938  [ 6336/50000]\n",
      "loss: 0.761358  [12736/50000]\n",
      "loss: 0.980826  [19136/50000]\n",
      "loss: 1.293264  [25536/50000]\n",
      "loss: 1.097282  [31936/50000]\n",
      "loss: 0.897763  [38336/50000]\n",
      "loss: 0.817115  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.016998 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.862005  [ 6336/50000]\n",
      "loss: 0.930723  [12736/50000]\n",
      "loss: 1.101508  [19136/50000]\n",
      "loss: 1.208261  [25536/50000]\n",
      "loss: 1.206793  [31936/50000]\n",
      "loss: 1.033385  [38336/50000]\n",
      "loss: 1.066067  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.017131 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.992224  [ 6336/50000]\n",
      "loss: 1.154157  [12736/50000]\n",
      "loss: 1.098290  [19136/50000]\n",
      "loss: 0.982734  [25536/50000]\n",
      "loss: 1.223370  [31936/50000]\n",
      "loss: 0.869876  [38336/50000]\n",
      "loss: 1.177244  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.016874 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.883954  [ 6336/50000]\n",
      "loss: 0.920214  [12736/50000]\n",
      "loss: 1.178675  [19136/50000]\n",
      "loss: 1.151699  [25536/50000]\n",
      "loss: 1.002267  [31936/50000]\n",
      "loss: 0.981908  [38336/50000]\n",
      "loss: 1.147696  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 0.016542 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.859762  [ 6336/50000]\n",
      "loss: 1.267265  [12736/50000]\n",
      "loss: 0.867100  [19136/50000]\n",
      "loss: 0.843700  [25536/50000]\n",
      "loss: 0.929557  [31936/50000]\n",
      "loss: 1.011629  [38336/50000]\n",
      "loss: 0.887241  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.017207 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.962838  [ 6336/50000]\n",
      "loss: 1.010645  [12736/50000]\n",
      "loss: 1.132215  [19136/50000]\n",
      "loss: 0.993934  [25536/50000]\n",
      "loss: 1.018203  [31936/50000]\n",
      "loss: 1.051359  [38336/50000]\n",
      "loss: 1.093655  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.016616 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 1.145618  [ 6336/50000]\n",
      "loss: 0.759971  [12736/50000]\n",
      "loss: 0.921995  [19136/50000]\n",
      "loss: 1.089979  [25536/50000]\n",
      "loss: 1.114237  [31936/50000]\n",
      "loss: 1.038157  [38336/50000]\n",
      "loss: 0.770768  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.016724 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.155456  [ 6336/50000]\n",
      "loss: 0.850159  [12736/50000]\n",
      "loss: 0.865082  [19136/50000]\n",
      "loss: 1.004698  [25536/50000]\n",
      "loss: 0.888002  [31936/50000]\n",
      "loss: 0.926324  [38336/50000]\n",
      "loss: 1.143960  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.016425 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.011260  [ 6336/50000]\n",
      "loss: 1.128967  [12736/50000]\n",
      "loss: 0.863618  [19136/50000]\n",
      "loss: 0.969029  [25536/50000]\n",
      "loss: 0.845278  [31936/50000]\n",
      "loss: 1.314390  [38336/50000]\n",
      "loss: 1.065833  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.016370 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.108267  [ 6336/50000]\n",
      "loss: 0.937862  [12736/50000]\n",
      "loss: 0.887966  [19136/50000]\n",
      "loss: 1.076546  [25536/50000]\n",
      "loss: 0.874124  [31936/50000]\n",
      "loss: 1.048896  [38336/50000]\n",
      "loss: 1.253454  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.016626 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 1.019696  [ 6336/50000]\n",
      "loss: 1.145054  [12736/50000]\n",
      "loss: 0.861455  [19136/50000]\n",
      "loss: 1.064984  [25536/50000]\n",
      "loss: 1.007762  [31936/50000]\n",
      "loss: 0.815055  [38336/50000]\n",
      "loss: 0.956483  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 0.016823 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.871204  [ 6336/50000]\n",
      "loss: 0.875960  [12736/50000]\n",
      "loss: 0.999788  [19136/50000]\n",
      "loss: 1.008081  [25536/50000]\n",
      "loss: 1.029719  [31936/50000]\n",
      "loss: 1.053790  [38336/50000]\n",
      "loss: 0.987416  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.016562 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.861172  [ 6336/50000]\n",
      "loss: 0.814990  [12736/50000]\n",
      "loss: 0.999748  [19136/50000]\n",
      "loss: 0.980137  [25536/50000]\n",
      "loss: 0.762116  [31936/50000]\n",
      "loss: 0.919305  [38336/50000]\n",
      "loss: 0.835782  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.016643 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 1.122607  [ 6336/50000]\n",
      "loss: 1.223762  [12736/50000]\n",
      "loss: 0.819261  [19136/50000]\n",
      "loss: 0.997939  [25536/50000]\n",
      "loss: 0.556310  [31936/50000]\n",
      "loss: 0.879153  [38336/50000]\n",
      "loss: 1.015865  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.015826 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.770375  [ 6336/50000]\n",
      "loss: 0.870762  [12736/50000]\n",
      "loss: 0.860225  [19136/50000]\n",
      "loss: 1.037024  [25536/50000]\n",
      "loss: 1.147403  [31936/50000]\n",
      "loss: 0.968720  [38336/50000]\n",
      "loss: 0.842615  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.016279 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.219899  [ 6336/50000]\n",
      "loss: 0.725068  [12736/50000]\n",
      "loss: 0.963362  [19136/50000]\n",
      "loss: 1.015023  [25536/50000]\n",
      "loss: 0.881135  [31936/50000]\n",
      "loss: 1.069826  [38336/50000]\n",
      "loss: 1.055359  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.016267 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.955268  [ 6336/50000]\n",
      "loss: 1.354719  [12736/50000]\n",
      "loss: 0.905214  [19136/50000]\n",
      "loss: 1.163171  [25536/50000]\n",
      "loss: 0.664818  [31936/50000]\n",
      "loss: 0.862120  [38336/50000]\n",
      "loss: 0.895459  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.015801 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.897532  [ 6336/50000]\n",
      "loss: 0.915031  [12736/50000]\n",
      "loss: 0.895960  [19136/50000]\n",
      "loss: 1.064029  [25536/50000]\n",
      "loss: 0.915378  [31936/50000]\n",
      "loss: 1.231378  [38336/50000]\n",
      "loss: 0.786457  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.016151 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.677688  [ 6336/50000]\n",
      "loss: 1.106367  [12736/50000]\n",
      "loss: 0.867409  [19136/50000]\n",
      "loss: 1.051050  [25536/50000]\n",
      "loss: 1.029729  [31936/50000]\n",
      "loss: 1.007060  [38336/50000]\n",
      "loss: 0.900814  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.016280 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.930210  [ 6336/50000]\n",
      "loss: 1.051096  [12736/50000]\n",
      "loss: 0.877329  [19136/50000]\n",
      "loss: 0.846077  [25536/50000]\n",
      "loss: 0.761601  [31936/50000]\n",
      "loss: 0.897222  [38336/50000]\n",
      "loss: 0.833500  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.016124 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.816971  [ 6336/50000]\n",
      "loss: 0.926792  [12736/50000]\n",
      "loss: 0.974754  [19136/50000]\n",
      "loss: 0.796493  [25536/50000]\n",
      "loss: 1.030128  [31936/50000]\n",
      "loss: 0.874767  [38336/50000]\n",
      "loss: 0.869700  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.016626 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.878987  [ 6336/50000]\n",
      "loss: 0.725159  [12736/50000]\n",
      "loss: 0.956033  [19136/50000]\n",
      "loss: 1.028397  [25536/50000]\n",
      "loss: 0.998467  [31936/50000]\n",
      "loss: 0.924205  [38336/50000]\n",
      "loss: 1.188396  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 0.015609 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.079898  [ 6336/50000]\n",
      "loss: 0.993777  [12736/50000]\n",
      "loss: 0.943188  [19136/50000]\n",
      "loss: 0.912527  [25536/50000]\n",
      "loss: 0.597967  [31936/50000]\n",
      "loss: 1.249970  [38336/50000]\n",
      "loss: 0.904774  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.016162 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.871362  [ 6336/50000]\n",
      "loss: 0.934292  [12736/50000]\n",
      "loss: 0.983074  [19136/50000]\n",
      "loss: 0.801166  [25536/50000]\n",
      "loss: 0.906700  [31936/50000]\n",
      "loss: 0.865576  [38336/50000]\n",
      "loss: 1.053198  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.016179 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.795137  [ 6336/50000]\n",
      "loss: 0.841791  [12736/50000]\n",
      "loss: 1.073232  [19136/50000]\n",
      "loss: 0.921705  [25536/50000]\n",
      "loss: 0.910631  [31936/50000]\n",
      "loss: 0.649209  [38336/50000]\n",
      "loss: 0.873390  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.015824 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.776046  [ 6336/50000]\n",
      "loss: 0.886673  [12736/50000]\n",
      "loss: 0.987724  [19136/50000]\n",
      "loss: 0.869322  [25536/50000]\n",
      "loss: 0.922488  [31936/50000]\n",
      "loss: 0.982417  [38336/50000]\n",
      "loss: 0.881778  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 0.015797 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 1.047356  [ 6336/50000]\n",
      "loss: 0.917584  [12736/50000]\n",
      "loss: 0.818451  [19136/50000]\n",
      "loss: 0.983316  [25536/50000]\n",
      "loss: 0.965516  [31936/50000]\n",
      "loss: 0.888334  [38336/50000]\n",
      "loss: 0.741537  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 0.015612 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.802148  [ 6336/50000]\n",
      "loss: 0.968747  [12736/50000]\n",
      "loss: 0.905365  [19136/50000]\n",
      "loss: 0.775537  [25536/50000]\n",
      "loss: 1.024321  [31936/50000]\n",
      "loss: 0.940089  [38336/50000]\n",
      "loss: 1.079075  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 0.015592 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.661848  [ 6336/50000]\n",
      "loss: 1.098609  [12736/50000]\n",
      "loss: 0.631377  [19136/50000]\n",
      "loss: 0.844808  [25536/50000]\n",
      "loss: 1.053064  [31936/50000]\n",
      "loss: 1.010888  [38336/50000]\n",
      "loss: 0.880798  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.015825 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.949932  [ 6336/50000]\n",
      "loss: 0.771684  [12736/50000]\n",
      "loss: 1.143715  [19136/50000]\n",
      "loss: 0.754219  [25536/50000]\n",
      "loss: 0.909347  [31936/50000]\n",
      "loss: 0.686671  [38336/50000]\n",
      "loss: 0.800384  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 0.015604 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.922728  [ 6336/50000]\n",
      "loss: 0.689342  [12736/50000]\n",
      "loss: 0.932932  [19136/50000]\n",
      "loss: 0.773065  [25536/50000]\n",
      "loss: 0.817615  [31936/50000]\n",
      "loss: 0.978165  [38336/50000]\n",
      "loss: 1.121230  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.015681 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 1.172660  [ 6336/50000]\n",
      "loss: 0.768314  [12736/50000]\n",
      "loss: 0.876543  [19136/50000]\n",
      "loss: 0.793783  [25536/50000]\n",
      "loss: 0.946357  [31936/50000]\n",
      "loss: 0.923433  [38336/50000]\n",
      "loss: 0.915967  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.015552 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.752114  [ 6336/50000]\n",
      "loss: 0.957764  [12736/50000]\n",
      "loss: 0.915750  [19136/50000]\n",
      "loss: 0.749435  [25536/50000]\n",
      "loss: 0.935925  [31936/50000]\n",
      "loss: 0.888327  [38336/50000]\n",
      "loss: 0.913947  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.015556 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 1.114266  [ 6336/50000]\n",
      "loss: 0.832771  [12736/50000]\n",
      "loss: 0.941259  [19136/50000]\n",
      "loss: 0.807157  [25536/50000]\n",
      "loss: 1.047085  [31936/50000]\n",
      "loss: 1.004363  [38336/50000]\n",
      "loss: 0.688376  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.015790 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.685099  [ 6336/50000]\n",
      "loss: 0.833679  [12736/50000]\n",
      "loss: 0.735046  [19136/50000]\n",
      "loss: 0.621929  [25536/50000]\n",
      "loss: 0.782608  [31936/50000]\n",
      "loss: 0.954169  [38336/50000]\n",
      "loss: 1.065181  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 0.015521 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.788232  [ 6336/50000]\n",
      "loss: 0.993972  [12736/50000]\n",
      "loss: 0.840781  [19136/50000]\n",
      "loss: 0.949530  [25536/50000]\n",
      "loss: 0.928694  [31936/50000]\n",
      "loss: 0.695560  [38336/50000]\n",
      "loss: 1.030196  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.015505 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.962608  [ 6336/50000]\n",
      "loss: 0.827368  [12736/50000]\n",
      "loss: 0.872775  [19136/50000]\n",
      "loss: 1.269986  [25536/50000]\n",
      "loss: 0.819920  [31936/50000]\n",
      "loss: 0.892923  [38336/50000]\n",
      "loss: 0.891125  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.015351 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 1.089373  [ 6336/50000]\n",
      "loss: 0.827814  [12736/50000]\n",
      "loss: 1.062999  [19136/50000]\n",
      "loss: 1.054686  [25536/50000]\n",
      "loss: 0.920378  [31936/50000]\n",
      "loss: 0.713038  [38336/50000]\n",
      "loss: 1.105898  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.015675 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.785028  [ 6336/50000]\n",
      "loss: 0.858381  [12736/50000]\n",
      "loss: 1.106943  [19136/50000]\n",
      "loss: 0.693377  [25536/50000]\n",
      "loss: 0.980669  [31936/50000]\n",
      "loss: 0.758187  [38336/50000]\n",
      "loss: 0.913841  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.015378 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.746178  [ 6336/50000]\n",
      "loss: 0.801227  [12736/50000]\n",
      "loss: 0.938250  [19136/50000]\n",
      "loss: 0.942198  [25536/50000]\n",
      "loss: 0.812067  [31936/50000]\n",
      "loss: 0.900888  [38336/50000]\n",
      "loss: 1.167639  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.015654 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.812487  [ 6336/50000]\n",
      "loss: 0.817738  [12736/50000]\n",
      "loss: 0.848968  [19136/50000]\n",
      "loss: 0.958776  [25536/50000]\n",
      "loss: 1.139284  [31936/50000]\n",
      "loss: 0.918996  [38336/50000]\n",
      "loss: 0.597311  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.015531 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.898432  [ 6336/50000]\n",
      "loss: 0.956668  [12736/50000]\n",
      "loss: 0.918406  [19136/50000]\n",
      "loss: 0.924450  [25536/50000]\n",
      "loss: 0.778005  [31936/50000]\n",
      "loss: 0.922577  [38336/50000]\n",
      "loss: 0.940586  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.015365 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.599108  [ 6336/50000]\n",
      "loss: 0.792595  [12736/50000]\n",
      "loss: 0.900221  [19136/50000]\n",
      "loss: 0.779661  [25536/50000]\n",
      "loss: 0.804644  [31936/50000]\n",
      "loss: 0.804978  [38336/50000]\n",
      "loss: 0.753390  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.015479 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.894436  [ 6336/50000]\n",
      "loss: 0.930773  [12736/50000]\n",
      "loss: 0.785798  [19136/50000]\n",
      "loss: 0.906710  [25536/50000]\n",
      "loss: 0.794591  [31936/50000]\n",
      "loss: 1.015663  [38336/50000]\n",
      "loss: 0.638334  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.015120 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.949371  [ 6336/50000]\n",
      "loss: 0.741561  [12736/50000]\n",
      "loss: 0.989333  [19136/50000]\n",
      "loss: 0.748411  [25536/50000]\n",
      "loss: 0.872432  [31936/50000]\n",
      "loss: 0.874362  [38336/50000]\n",
      "loss: 0.676823  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 0.015396 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.584158  [ 6336/50000]\n",
      "loss: 0.860041  [12736/50000]\n",
      "loss: 0.728690  [19136/50000]\n",
      "loss: 0.904864  [25536/50000]\n",
      "loss: 0.852053  [31936/50000]\n",
      "loss: 0.868533  [38336/50000]\n",
      "loss: 0.633155  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.015260 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.764586  [ 6336/50000]\n",
      "loss: 0.873336  [12736/50000]\n",
      "loss: 0.967480  [19136/50000]\n",
      "loss: 0.851635  [25536/50000]\n",
      "loss: 0.756373  [31936/50000]\n",
      "loss: 0.654604  [38336/50000]\n",
      "loss: 0.819164  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.015794 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.753577  [ 6336/50000]\n",
      "loss: 0.735283  [12736/50000]\n",
      "loss: 0.955122  [19136/50000]\n",
      "loss: 0.810978  [25536/50000]\n",
      "loss: 0.848723  [31936/50000]\n",
      "loss: 0.774333  [38336/50000]\n",
      "loss: 0.729941  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.015296 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.942181  [ 6336/50000]\n",
      "loss: 0.693018  [12736/50000]\n",
      "loss: 0.980780  [19136/50000]\n",
      "loss: 0.962735  [25536/50000]\n",
      "loss: 0.920748  [31936/50000]\n",
      "loss: 0.873201  [38336/50000]\n",
      "loss: 0.683968  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.015378 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.814815  [ 6336/50000]\n",
      "loss: 0.922771  [12736/50000]\n",
      "loss: 0.870977  [19136/50000]\n",
      "loss: 0.759407  [25536/50000]\n",
      "loss: 1.126237  [31936/50000]\n",
      "loss: 0.847714  [38336/50000]\n",
      "loss: 0.798698  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.015179 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.883892  [ 6336/50000]\n",
      "loss: 0.603399  [12736/50000]\n",
      "loss: 1.130716  [19136/50000]\n",
      "loss: 0.720962  [25536/50000]\n",
      "loss: 0.784852  [31936/50000]\n",
      "loss: 0.862350  [38336/50000]\n",
      "loss: 0.769488  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.015087 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.755477  [ 6336/50000]\n",
      "loss: 0.733020  [12736/50000]\n",
      "loss: 0.820989  [19136/50000]\n",
      "loss: 0.925908  [25536/50000]\n",
      "loss: 0.677590  [31936/50000]\n",
      "loss: 0.630071  [38336/50000]\n",
      "loss: 0.725080  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.015344 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.682004  [ 6336/50000]\n",
      "loss: 0.875254  [12736/50000]\n",
      "loss: 0.717752  [19136/50000]\n",
      "loss: 0.548306  [25536/50000]\n",
      "loss: 0.857283  [31936/50000]\n",
      "loss: 0.861689  [38336/50000]\n",
      "loss: 0.812576  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.015383 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.675930  [ 6336/50000]\n",
      "loss: 0.730160  [12736/50000]\n",
      "loss: 0.711568  [19136/50000]\n",
      "loss: 0.697821  [25536/50000]\n",
      "loss: 0.785420  [31936/50000]\n",
      "loss: 0.615437  [38336/50000]\n",
      "loss: 0.770230  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.015106 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.887759  [ 6336/50000]\n",
      "loss: 1.045575  [12736/50000]\n",
      "loss: 0.958424  [19136/50000]\n",
      "loss: 0.870003  [25536/50000]\n",
      "loss: 0.994450  [31936/50000]\n",
      "loss: 0.783172  [38336/50000]\n",
      "loss: 0.701801  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.015130 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.885936  [ 6336/50000]\n",
      "loss: 0.966849  [12736/50000]\n",
      "loss: 0.899554  [19136/50000]\n",
      "loss: 0.740702  [25536/50000]\n",
      "loss: 0.962311  [31936/50000]\n",
      "loss: 0.819112  [38336/50000]\n",
      "loss: 0.595606  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.015182 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.717614  [ 6336/50000]\n",
      "loss: 0.882351  [12736/50000]\n",
      "loss: 0.966208  [19136/50000]\n",
      "loss: 0.882675  [25536/50000]\n",
      "loss: 0.632596  [31936/50000]\n",
      "loss: 0.696605  [38336/50000]\n",
      "loss: 0.902032  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.015195 \n",
      "\n",
      "Finished Training Net + <class 'z2_conv.ConvNetC'>\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306453  [ 6336/50000]\n",
      "loss: 2.301393  [12736/50000]\n",
      "loss: 2.303033  [19136/50000]\n",
      "loss: 2.305912  [25536/50000]\n",
      "loss: 2.307602  [31936/50000]\n",
      "loss: 2.304926  [38336/50000]\n",
      "loss: 2.300270  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 0.036152 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.300127  [ 6336/50000]\n",
      "loss: 2.303201  [12736/50000]\n",
      "loss: 2.302192  [19136/50000]\n",
      "loss: 2.303039  [25536/50000]\n",
      "loss: 2.299011  [31936/50000]\n",
      "loss: 2.302727  [38336/50000]\n",
      "loss: 2.302692  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 0.036145 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.298299  [ 6336/50000]\n",
      "loss: 2.299841  [12736/50000]\n",
      "loss: 2.302066  [19136/50000]\n",
      "loss: 2.301006  [25536/50000]\n",
      "loss: 2.302985  [31936/50000]\n",
      "loss: 2.301614  [38336/50000]\n",
      "loss: 2.302848  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 13.7%, Avg loss: 0.036140 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.302783  [ 6336/50000]\n",
      "loss: 2.301046  [12736/50000]\n",
      "loss: 2.300823  [19136/50000]\n",
      "loss: 2.302685  [25536/50000]\n",
      "loss: 2.301367  [31936/50000]\n",
      "loss: 2.301677  [38336/50000]\n",
      "loss: 2.301190  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 15.8%, Avg loss: 0.036130 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.300848  [ 6336/50000]\n",
      "loss: 2.301317  [12736/50000]\n",
      "loss: 2.299334  [19136/50000]\n",
      "loss: 2.300915  [25536/50000]\n",
      "loss: 2.299727  [31936/50000]\n",
      "loss: 2.300991  [38336/50000]\n",
      "loss: 2.300609  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 17.0%, Avg loss: 0.036098 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.297582  [ 6336/50000]\n",
      "loss: 2.297536  [12736/50000]\n",
      "loss: 2.296443  [19136/50000]\n",
      "loss: 2.296157  [25536/50000]\n",
      "loss: 2.293529  [31936/50000]\n",
      "loss: 2.295206  [38336/50000]\n",
      "loss: 2.292833  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 16.5%, Avg loss: 0.035917 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.259327  [ 6336/50000]\n",
      "loss: 2.263470  [12736/50000]\n",
      "loss: 2.222037  [19136/50000]\n",
      "loss: 2.174644  [25536/50000]\n",
      "loss: 2.191754  [31936/50000]\n",
      "loss: 2.043386  [38336/50000]\n",
      "loss: 1.880267  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 19.9%, Avg loss: 0.033280 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.981334  [ 6336/50000]\n",
      "loss: 1.960824  [12736/50000]\n",
      "loss: 2.070421  [19136/50000]\n",
      "loss: 1.863141  [25536/50000]\n",
      "loss: 1.959937  [31936/50000]\n",
      "loss: 1.945302  [38336/50000]\n",
      "loss: 1.773280  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 24.0%, Avg loss: 0.033333 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.864467  [ 6336/50000]\n",
      "loss: 1.751371  [12736/50000]\n",
      "loss: 1.789716  [19136/50000]\n",
      "loss: 1.603594  [25536/50000]\n",
      "loss: 1.708338  [31936/50000]\n",
      "loss: 1.819489  [38336/50000]\n",
      "loss: 1.714512  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 24.8%, Avg loss: 0.033281 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.960412  [ 6336/50000]\n",
      "loss: 1.784203  [12736/50000]\n",
      "loss: 1.789044  [19136/50000]\n",
      "loss: 1.724260  [25536/50000]\n",
      "loss: 1.569446  [31936/50000]\n",
      "loss: 1.746763  [38336/50000]\n",
      "loss: 1.652606  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 25.4%, Avg loss: 0.034993 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.735080  [ 6336/50000]\n",
      "loss: 1.575516  [12736/50000]\n",
      "loss: 1.615335  [19136/50000]\n",
      "loss: 1.453024  [25536/50000]\n",
      "loss: 1.627886  [31936/50000]\n",
      "loss: 1.495122  [38336/50000]\n",
      "loss: 1.635244  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 0.033757 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.701705  [ 6336/50000]\n",
      "loss: 1.697600  [12736/50000]\n",
      "loss: 1.459486  [19136/50000]\n",
      "loss: 1.660229  [25536/50000]\n",
      "loss: 1.432011  [31936/50000]\n",
      "loss: 1.412407  [38336/50000]\n",
      "loss: 1.628085  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 27.5%, Avg loss: 0.033714 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.623837  [ 6336/50000]\n",
      "loss: 1.563114  [12736/50000]\n",
      "loss: 1.499396  [19136/50000]\n",
      "loss: 1.296270  [25536/50000]\n",
      "loss: 1.428782  [31936/50000]\n",
      "loss: 1.311614  [38336/50000]\n",
      "loss: 1.494528  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 28.0%, Avg loss: 0.034209 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.533481  [ 6336/50000]\n",
      "loss: 1.676401  [12736/50000]\n",
      "loss: 1.475982  [19136/50000]\n",
      "loss: 1.517679  [25536/50000]\n",
      "loss: 1.511393  [31936/50000]\n",
      "loss: 1.482372  [38336/50000]\n",
      "loss: 1.417270  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 0.034383 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.664908  [ 6336/50000]\n",
      "loss: 1.679937  [12736/50000]\n",
      "loss: 1.608546  [19136/50000]\n",
      "loss: 1.371184  [25536/50000]\n",
      "loss: 1.330651  [31936/50000]\n",
      "loss: 1.220867  [38336/50000]\n",
      "loss: 1.418894  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 29.2%, Avg loss: 0.036769 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.491157  [ 6336/50000]\n",
      "loss: 1.342061  [12736/50000]\n",
      "loss: 1.361275  [19136/50000]\n",
      "loss: 1.346555  [25536/50000]\n",
      "loss: 1.075838  [31936/50000]\n",
      "loss: 1.492620  [38336/50000]\n",
      "loss: 1.345535  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 29.6%, Avg loss: 0.034422 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.390235  [ 6336/50000]\n",
      "loss: 1.354615  [12736/50000]\n",
      "loss: 1.608694  [19136/50000]\n",
      "loss: 1.359588  [25536/50000]\n",
      "loss: 1.402588  [31936/50000]\n",
      "loss: 1.307408  [38336/50000]\n",
      "loss: 1.253268  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 30.0%, Avg loss: 0.035802 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.302458  [ 6336/50000]\n",
      "loss: 1.316220  [12736/50000]\n",
      "loss: 1.397443  [19136/50000]\n",
      "loss: 1.111870  [25536/50000]\n",
      "loss: 1.187217  [31936/50000]\n",
      "loss: 1.297606  [38336/50000]\n",
      "loss: 1.413674  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 32.0%, Avg loss: 0.033603 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.265791  [ 6336/50000]\n",
      "loss: 1.354044  [12736/50000]\n",
      "loss: 1.401669  [19136/50000]\n",
      "loss: 1.167044  [25536/50000]\n",
      "loss: 1.194775  [31936/50000]\n",
      "loss: 1.261436  [38336/50000]\n",
      "loss: 1.431966  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 0.035050 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.443109  [ 6336/50000]\n",
      "loss: 1.342800  [12736/50000]\n",
      "loss: 1.204446  [19136/50000]\n",
      "loss: 1.324748  [25536/50000]\n",
      "loss: 1.240204  [31936/50000]\n",
      "loss: 1.273272  [38336/50000]\n",
      "loss: 1.039575  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 31.2%, Avg loss: 0.034192 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.380930  [ 6336/50000]\n",
      "loss: 1.104764  [12736/50000]\n",
      "loss: 1.267759  [19136/50000]\n",
      "loss: 1.119407  [25536/50000]\n",
      "loss: 1.259738  [31936/50000]\n",
      "loss: 1.261032  [38336/50000]\n",
      "loss: 1.258817  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 32.2%, Avg loss: 0.034614 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.933761  [ 6336/50000]\n",
      "loss: 1.132520  [12736/50000]\n",
      "loss: 1.370468  [19136/50000]\n",
      "loss: 1.383808  [25536/50000]\n",
      "loss: 1.223308  [31936/50000]\n",
      "loss: 1.178465  [38336/50000]\n",
      "loss: 1.112300  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 0.034595 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.009051  [ 6336/50000]\n",
      "loss: 1.339828  [12736/50000]\n",
      "loss: 0.953676  [19136/50000]\n",
      "loss: 1.194368  [25536/50000]\n",
      "loss: 1.302253  [31936/50000]\n",
      "loss: 1.238934  [38336/50000]\n",
      "loss: 1.165315  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.1%, Avg loss: 0.033580 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.021289  [ 6336/50000]\n",
      "loss: 0.966448  [12736/50000]\n",
      "loss: 1.119394  [19136/50000]\n",
      "loss: 1.049643  [25536/50000]\n",
      "loss: 1.308451  [31936/50000]\n",
      "loss: 1.262801  [38336/50000]\n",
      "loss: 1.172332  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 0.033542 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.222416  [ 6336/50000]\n",
      "loss: 1.024428  [12736/50000]\n",
      "loss: 1.177318  [19136/50000]\n",
      "loss: 0.978129  [25536/50000]\n",
      "loss: 1.078767  [31936/50000]\n",
      "loss: 0.987805  [38336/50000]\n",
      "loss: 1.042013  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 0.033154 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.959132  [ 6336/50000]\n",
      "loss: 1.047351  [12736/50000]\n",
      "loss: 1.107068  [19136/50000]\n",
      "loss: 1.215763  [25536/50000]\n",
      "loss: 1.090565  [31936/50000]\n",
      "loss: 1.012720  [38336/50000]\n",
      "loss: 0.839127  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 32.5%, Avg loss: 0.035746 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.953508  [ 6336/50000]\n",
      "loss: 1.213593  [12736/50000]\n",
      "loss: 1.142185  [19136/50000]\n",
      "loss: 1.105559  [25536/50000]\n",
      "loss: 1.123622  [31936/50000]\n",
      "loss: 1.236412  [38336/50000]\n",
      "loss: 1.093000  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 0.035133 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.208754  [ 6336/50000]\n",
      "loss: 0.833118  [12736/50000]\n",
      "loss: 1.226279  [19136/50000]\n",
      "loss: 1.153017  [25536/50000]\n",
      "loss: 1.004561  [31936/50000]\n",
      "loss: 1.241234  [38336/50000]\n",
      "loss: 1.175834  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.032639 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.072707  [ 6336/50000]\n",
      "loss: 0.878989  [12736/50000]\n",
      "loss: 0.914938  [19136/50000]\n",
      "loss: 1.127104  [25536/50000]\n",
      "loss: 0.803527  [31936/50000]\n",
      "loss: 0.863847  [38336/50000]\n",
      "loss: 1.003840  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.033074 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.881940  [ 6336/50000]\n",
      "loss: 0.910354  [12736/50000]\n",
      "loss: 0.819445  [19136/50000]\n",
      "loss: 0.836918  [25536/50000]\n",
      "loss: 1.301297  [31936/50000]\n",
      "loss: 1.110193  [38336/50000]\n",
      "loss: 0.940634  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 0.036468 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.970736  [ 6336/50000]\n",
      "loss: 1.051929  [12736/50000]\n",
      "loss: 1.163337  [19136/50000]\n",
      "loss: 1.142092  [25536/50000]\n",
      "loss: 1.024146  [31936/50000]\n",
      "loss: 1.044866  [38336/50000]\n",
      "loss: 0.850987  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.036171 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.946985  [ 6336/50000]\n",
      "loss: 0.734395  [12736/50000]\n",
      "loss: 0.990795  [19136/50000]\n",
      "loss: 0.833200  [25536/50000]\n",
      "loss: 1.011278  [31936/50000]\n",
      "loss: 0.864503  [38336/50000]\n",
      "loss: 0.939798  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.035484 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.714453  [ 6336/50000]\n",
      "loss: 1.200922  [12736/50000]\n",
      "loss: 1.090766  [19136/50000]\n",
      "loss: 0.997552  [25536/50000]\n",
      "loss: 0.784859  [31936/50000]\n",
      "loss: 0.917491  [38336/50000]\n",
      "loss: 1.015174  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.035304 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.877812  [ 6336/50000]\n",
      "loss: 0.822252  [12736/50000]\n",
      "loss: 0.758680  [19136/50000]\n",
      "loss: 0.822080  [25536/50000]\n",
      "loss: 0.707655  [31936/50000]\n",
      "loss: 0.991993  [38336/50000]\n",
      "loss: 0.856090  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.034973 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.968102  [ 6336/50000]\n",
      "loss: 1.034668  [12736/50000]\n",
      "loss: 0.766273  [19136/50000]\n",
      "loss: 0.868145  [25536/50000]\n",
      "loss: 1.076166  [31936/50000]\n",
      "loss: 0.842008  [38336/50000]\n",
      "loss: 0.917192  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.037287 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.766124  [ 6336/50000]\n",
      "loss: 0.668151  [12736/50000]\n",
      "loss: 1.114585  [19136/50000]\n",
      "loss: 0.957699  [25536/50000]\n",
      "loss: 0.781219  [31936/50000]\n",
      "loss: 0.871145  [38336/50000]\n",
      "loss: 1.082908  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.035489 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.844851  [ 6336/50000]\n",
      "loss: 0.895817  [12736/50000]\n",
      "loss: 0.645769  [19136/50000]\n",
      "loss: 0.678973  [25536/50000]\n",
      "loss: 0.850064  [31936/50000]\n",
      "loss: 0.935612  [38336/50000]\n",
      "loss: 0.843283  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 0.034844 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.917200  [ 6336/50000]\n",
      "loss: 0.593674  [12736/50000]\n",
      "loss: 1.159530  [19136/50000]\n",
      "loss: 0.673116  [25536/50000]\n",
      "loss: 0.886744  [31936/50000]\n",
      "loss: 0.893245  [38336/50000]\n",
      "loss: 0.811158  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 0.035922 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.801389  [ 6336/50000]\n",
      "loss: 1.006735  [12736/50000]\n",
      "loss: 0.730677  [19136/50000]\n",
      "loss: 0.800036  [25536/50000]\n",
      "loss: 0.722058  [31936/50000]\n",
      "loss: 0.703469  [38336/50000]\n",
      "loss: 0.728854  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 0.036699 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.675503  [ 6336/50000]\n",
      "loss: 0.891431  [12736/50000]\n",
      "loss: 0.743645  [19136/50000]\n",
      "loss: 0.723296  [25536/50000]\n",
      "loss: 0.694387  [31936/50000]\n",
      "loss: 0.595049  [38336/50000]\n",
      "loss: 0.867375  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 0.037607 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.919055  [ 6336/50000]\n",
      "loss: 0.757546  [12736/50000]\n",
      "loss: 0.807467  [19136/50000]\n",
      "loss: 0.822896  [25536/50000]\n",
      "loss: 0.902560  [31936/50000]\n",
      "loss: 0.761548  [38336/50000]\n",
      "loss: 0.740726  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 0.038784 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.677708  [ 6336/50000]\n",
      "loss: 0.854947  [12736/50000]\n",
      "loss: 0.502347  [19136/50000]\n",
      "loss: 0.780098  [25536/50000]\n",
      "loss: 0.612506  [31936/50000]\n",
      "loss: 0.825827  [38336/50000]\n",
      "loss: 0.675828  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 0.036619 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.767350  [ 6336/50000]\n",
      "loss: 0.729175  [12736/50000]\n",
      "loss: 0.666430  [19136/50000]\n",
      "loss: 0.619892  [25536/50000]\n",
      "loss: 0.610538  [31936/50000]\n",
      "loss: 0.791976  [38336/50000]\n",
      "loss: 0.684778  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 0.038252 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.672366  [ 6336/50000]\n",
      "loss: 0.659134  [12736/50000]\n",
      "loss: 0.617723  [19136/50000]\n",
      "loss: 0.924936  [25536/50000]\n",
      "loss: 0.601464  [31936/50000]\n",
      "loss: 0.827147  [38336/50000]\n",
      "loss: 0.675155  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 0.036373 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.895564  [ 6336/50000]\n",
      "loss: 0.711282  [12736/50000]\n",
      "loss: 0.651354  [19136/50000]\n",
      "loss: 0.863531  [25536/50000]\n",
      "loss: 0.567172  [31936/50000]\n",
      "loss: 0.632781  [38336/50000]\n",
      "loss: 0.683688  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.7%, Avg loss: 0.038104 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.646100  [ 6336/50000]\n",
      "loss: 0.805516  [12736/50000]\n",
      "loss: 0.711424  [19136/50000]\n",
      "loss: 0.786019  [25536/50000]\n",
      "loss: 0.748886  [31936/50000]\n",
      "loss: 0.729173  [38336/50000]\n",
      "loss: 0.552842  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 0.038505 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.533671  [ 6336/50000]\n",
      "loss: 0.643155  [12736/50000]\n",
      "loss: 1.051652  [19136/50000]\n",
      "loss: 0.560367  [25536/50000]\n",
      "loss: 0.656419  [31936/50000]\n",
      "loss: 0.785000  [38336/50000]\n",
      "loss: 0.490328  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 0.040547 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.498712  [ 6336/50000]\n",
      "loss: 0.650442  [12736/50000]\n",
      "loss: 0.573671  [19136/50000]\n",
      "loss: 0.591704  [25536/50000]\n",
      "loss: 0.743264  [31936/50000]\n",
      "loss: 0.699240  [38336/50000]\n",
      "loss: 0.537229  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.041842 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.619079  [ 6336/50000]\n",
      "loss: 0.627745  [12736/50000]\n",
      "loss: 0.633387  [19136/50000]\n",
      "loss: 0.775527  [25536/50000]\n",
      "loss: 0.619038  [31936/50000]\n",
      "loss: 0.475495  [38336/50000]\n",
      "loss: 0.399756  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.1%, Avg loss: 0.042730 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.609483  [ 6336/50000]\n",
      "loss: 0.495877  [12736/50000]\n",
      "loss: 0.511833  [19136/50000]\n",
      "loss: 0.618255  [25536/50000]\n",
      "loss: 0.793155  [31936/50000]\n",
      "loss: 0.592355  [38336/50000]\n",
      "loss: 0.801296  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 0.043548 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.380560  [ 6336/50000]\n",
      "loss: 0.712776  [12736/50000]\n",
      "loss: 0.561642  [19136/50000]\n",
      "loss: 0.509142  [25536/50000]\n",
      "loss: 0.449972  [31936/50000]\n",
      "loss: 0.602535  [38336/50000]\n",
      "loss: 0.617684  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.043151 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.445029  [ 6336/50000]\n",
      "loss: 0.429854  [12736/50000]\n",
      "loss: 0.399572  [19136/50000]\n",
      "loss: 0.667902  [25536/50000]\n",
      "loss: 0.472200  [31936/50000]\n",
      "loss: 0.611945  [38336/50000]\n",
      "loss: 0.545778  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.9%, Avg loss: 0.043250 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.598936  [ 6336/50000]\n",
      "loss: 0.417000  [12736/50000]\n",
      "loss: 0.380494  [19136/50000]\n",
      "loss: 0.533735  [25536/50000]\n",
      "loss: 0.545837  [31936/50000]\n",
      "loss: 0.692401  [38336/50000]\n",
      "loss: 0.613684  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.042982 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.397664  [ 6336/50000]\n",
      "loss: 0.335500  [12736/50000]\n",
      "loss: 0.556279  [19136/50000]\n",
      "loss: 0.530929  [25536/50000]\n",
      "loss: 0.597242  [31936/50000]\n",
      "loss: 0.354216  [38336/50000]\n",
      "loss: 0.479796  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.7%, Avg loss: 0.043426 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.661964  [ 6336/50000]\n",
      "loss: 0.626221  [12736/50000]\n",
      "loss: 0.515806  [19136/50000]\n",
      "loss: 0.738435  [25536/50000]\n",
      "loss: 0.660092  [31936/50000]\n",
      "loss: 0.473086  [38336/50000]\n",
      "loss: 0.493252  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 0.045439 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.395260  [ 6336/50000]\n",
      "loss: 0.460512  [12736/50000]\n",
      "loss: 0.371759  [19136/50000]\n",
      "loss: 0.695924  [25536/50000]\n",
      "loss: 0.402756  [31936/50000]\n",
      "loss: 0.445813  [38336/50000]\n",
      "loss: 0.518173  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 0.051261 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.322560  [ 6336/50000]\n",
      "loss: 0.375399  [12736/50000]\n",
      "loss: 0.434088  [19136/50000]\n",
      "loss: 0.423686  [25536/50000]\n",
      "loss: 0.493448  [31936/50000]\n",
      "loss: 0.433978  [38336/50000]\n",
      "loss: 0.680815  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 0.047032 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.362944  [ 6336/50000]\n",
      "loss: 0.486686  [12736/50000]\n",
      "loss: 0.409745  [19136/50000]\n",
      "loss: 0.387628  [25536/50000]\n",
      "loss: 0.398541  [31936/50000]\n",
      "loss: 0.512634  [38336/50000]\n",
      "loss: 0.358872  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 0.049363 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.484701  [ 6336/50000]\n",
      "loss: 0.559377  [12736/50000]\n",
      "loss: 0.401096  [19136/50000]\n",
      "loss: 0.428657  [25536/50000]\n",
      "loss: 0.429864  [31936/50000]\n",
      "loss: 0.413145  [38336/50000]\n",
      "loss: 0.487089  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 0.053161 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.323895  [ 6336/50000]\n",
      "loss: 0.315806  [12736/50000]\n",
      "loss: 0.325092  [19136/50000]\n",
      "loss: 0.544835  [25536/50000]\n",
      "loss: 0.572774  [31936/50000]\n",
      "loss: 0.424936  [38336/50000]\n",
      "loss: 0.481466  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 0.053236 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.188752  [ 6336/50000]\n",
      "loss: 0.510358  [12736/50000]\n",
      "loss: 0.392216  [19136/50000]\n",
      "loss: 0.494770  [25536/50000]\n",
      "loss: 0.402295  [31936/50000]\n",
      "loss: 0.404804  [38336/50000]\n",
      "loss: 0.531691  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.058737 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.297741  [ 6336/50000]\n",
      "loss: 0.338791  [12736/50000]\n",
      "loss: 0.343966  [19136/50000]\n",
      "loss: 0.513979  [25536/50000]\n",
      "loss: 0.280693  [31936/50000]\n",
      "loss: 0.369214  [38336/50000]\n",
      "loss: 0.349499  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.056736 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.243064  [ 6336/50000]\n",
      "loss: 0.473529  [12736/50000]\n",
      "loss: 0.311294  [19136/50000]\n",
      "loss: 0.311635  [25536/50000]\n",
      "loss: 0.442470  [31936/50000]\n",
      "loss: 0.271490  [38336/50000]\n",
      "loss: 0.389553  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 0.056083 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.304398  [ 6336/50000]\n",
      "loss: 0.150310  [12736/50000]\n",
      "loss: 0.461995  [19136/50000]\n",
      "loss: 0.274379  [25536/50000]\n",
      "loss: 0.252185  [31936/50000]\n",
      "loss: 0.501756  [38336/50000]\n",
      "loss: 0.294558  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.7%, Avg loss: 0.059663 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.207629  [ 6336/50000]\n",
      "loss: 0.385308  [12736/50000]\n",
      "loss: 0.403654  [19136/50000]\n",
      "loss: 0.348103  [25536/50000]\n",
      "loss: 0.257366  [31936/50000]\n",
      "loss: 0.408590  [38336/50000]\n",
      "loss: 0.459431  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.060457 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.355142  [ 6336/50000]\n",
      "loss: 0.132560  [12736/50000]\n",
      "loss: 0.387865  [19136/50000]\n",
      "loss: 0.354092  [25536/50000]\n",
      "loss: 0.311796  [31936/50000]\n",
      "loss: 0.450737  [38336/50000]\n",
      "loss: 0.396551  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.062684 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.245343  [ 6336/50000]\n",
      "loss: 0.193476  [12736/50000]\n",
      "loss: 0.154316  [19136/50000]\n",
      "loss: 0.379827  [25536/50000]\n",
      "loss: 0.222986  [31936/50000]\n",
      "loss: 0.302404  [38336/50000]\n",
      "loss: 0.204436  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.7%, Avg loss: 0.059574 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.251008  [ 6336/50000]\n",
      "loss: 0.191323  [12736/50000]\n",
      "loss: 0.204853  [19136/50000]\n",
      "loss: 0.223992  [25536/50000]\n",
      "loss: 0.263269  [31936/50000]\n",
      "loss: 0.338346  [38336/50000]\n",
      "loss: 0.309510  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.069375 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.212475  [ 6336/50000]\n",
      "loss: 0.163191  [12736/50000]\n",
      "loss: 0.237844  [19136/50000]\n",
      "loss: 0.357064  [25536/50000]\n",
      "loss: 0.173373  [31936/50000]\n",
      "loss: 0.109099  [38336/50000]\n",
      "loss: 0.301756  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.070595 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.165781  [ 6336/50000]\n",
      "loss: 0.218668  [12736/50000]\n",
      "loss: 0.238521  [19136/50000]\n",
      "loss: 0.241498  [25536/50000]\n",
      "loss: 0.187115  [31936/50000]\n",
      "loss: 0.271901  [38336/50000]\n",
      "loss: 0.389382  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.074943 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.072322  [ 6336/50000]\n",
      "loss: 0.092975  [12736/50000]\n",
      "loss: 0.338802  [19136/50000]\n",
      "loss: 0.143798  [25536/50000]\n",
      "loss: 0.226364  [31936/50000]\n",
      "loss: 0.181390  [38336/50000]\n",
      "loss: 0.232262  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 0.071261 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.211702  [ 6336/50000]\n",
      "loss: 0.315317  [12736/50000]\n",
      "loss: 0.202336  [19136/50000]\n",
      "loss: 0.282797  [25536/50000]\n",
      "loss: 0.183640  [31936/50000]\n",
      "loss: 0.176062  [38336/50000]\n",
      "loss: 0.234871  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.1%, Avg loss: 0.075481 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.174708  [ 6336/50000]\n",
      "loss: 0.107691  [12736/50000]\n",
      "loss: 0.285516  [19136/50000]\n",
      "loss: 0.212178  [25536/50000]\n",
      "loss: 0.219569  [31936/50000]\n",
      "loss: 0.281166  [38336/50000]\n",
      "loss: 0.175537  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 0.075378 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.117584  [ 6336/50000]\n",
      "loss: 0.316471  [12736/50000]\n",
      "loss: 0.127105  [19136/50000]\n",
      "loss: 0.065317  [25536/50000]\n",
      "loss: 0.250387  [31936/50000]\n",
      "loss: 0.301996  [38336/50000]\n",
      "loss: 0.182595  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.084470 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.168122  [ 6336/50000]\n",
      "loss: 0.172986  [12736/50000]\n",
      "loss: 0.138751  [19136/50000]\n",
      "loss: 0.201565  [25536/50000]\n",
      "loss: 0.294151  [31936/50000]\n",
      "loss: 0.078474  [38336/50000]\n",
      "loss: 0.157122  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.083515 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.078853  [ 6336/50000]\n",
      "loss: 0.149157  [12736/50000]\n",
      "loss: 0.104792  [19136/50000]\n",
      "loss: 0.105372  [25536/50000]\n",
      "loss: 0.102488  [31936/50000]\n",
      "loss: 0.249910  [38336/50000]\n",
      "loss: 0.320285  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.083723 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.181806  [ 6336/50000]\n",
      "loss: 0.066466  [12736/50000]\n",
      "loss: 0.151145  [19136/50000]\n",
      "loss: 0.114672  [25536/50000]\n",
      "loss: 0.245737  [31936/50000]\n",
      "loss: 0.194157  [38336/50000]\n",
      "loss: 0.117128  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 0.089699 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.094290  [ 6336/50000]\n",
      "loss: 0.199452  [12736/50000]\n",
      "loss: 0.050225  [19136/50000]\n",
      "loss: 0.136991  [25536/50000]\n",
      "loss: 0.177002  [31936/50000]\n",
      "loss: 0.203474  [38336/50000]\n",
      "loss: 0.250033  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 0.090014 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.110024  [ 6336/50000]\n",
      "loss: 0.079511  [12736/50000]\n",
      "loss: 0.124467  [19136/50000]\n",
      "loss: 0.095099  [25536/50000]\n",
      "loss: 0.097323  [31936/50000]\n",
      "loss: 0.115404  [38336/50000]\n",
      "loss: 0.314463  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 0.103589 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.125156  [ 6336/50000]\n",
      "loss: 0.068822  [12736/50000]\n",
      "loss: 0.203779  [19136/50000]\n",
      "loss: 0.216065  [25536/50000]\n",
      "loss: 0.132241  [31936/50000]\n",
      "loss: 0.133904  [38336/50000]\n",
      "loss: 0.316775  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 0.093210 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.082650  [ 6336/50000]\n",
      "loss: 0.040518  [12736/50000]\n",
      "loss: 0.060491  [19136/50000]\n",
      "loss: 0.069919  [25536/50000]\n",
      "loss: 0.090049  [31936/50000]\n",
      "loss: 0.116461  [38336/50000]\n",
      "loss: 0.074794  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.094019 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.076997  [ 6336/50000]\n",
      "loss: 0.060376  [12736/50000]\n",
      "loss: 0.140439  [19136/50000]\n",
      "loss: 0.061740  [25536/50000]\n",
      "loss: 0.099264  [31936/50000]\n",
      "loss: 0.102802  [38336/50000]\n",
      "loss: 0.238818  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.099371 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.153035  [ 6336/50000]\n",
      "loss: 0.162460  [12736/50000]\n",
      "loss: 0.159284  [19136/50000]\n",
      "loss: 0.207750  [25536/50000]\n",
      "loss: 0.050367  [31936/50000]\n",
      "loss: 0.056677  [38336/50000]\n",
      "loss: 0.072617  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.100224 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.079004  [ 6336/50000]\n",
      "loss: 0.089100  [12736/50000]\n",
      "loss: 0.116969  [19136/50000]\n",
      "loss: 0.175675  [25536/50000]\n",
      "loss: 0.144155  [31936/50000]\n",
      "loss: 0.122777  [38336/50000]\n",
      "loss: 0.100360  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.100680 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.172254  [ 6336/50000]\n",
      "loss: 0.058516  [12736/50000]\n",
      "loss: 0.021065  [19136/50000]\n",
      "loss: 0.087628  [25536/50000]\n",
      "loss: 0.122240  [31936/50000]\n",
      "loss: 0.068690  [38336/50000]\n",
      "loss: 0.096436  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.102404 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.030748  [ 6336/50000]\n",
      "loss: 0.067181  [12736/50000]\n",
      "loss: 0.067088  [19136/50000]\n",
      "loss: 0.236812  [25536/50000]\n",
      "loss: 0.080044  [31936/50000]\n",
      "loss: 0.103505  [38336/50000]\n",
      "loss: 0.075467  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 0.118416 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.034377  [ 6336/50000]\n",
      "loss: 0.131647  [12736/50000]\n",
      "loss: 0.049361  [19136/50000]\n",
      "loss: 0.059710  [25536/50000]\n",
      "loss: 0.097024  [31936/50000]\n",
      "loss: 0.071292  [38336/50000]\n",
      "loss: 0.157463  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.9%, Avg loss: 0.124620 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.182567  [ 6336/50000]\n",
      "loss: 0.122809  [12736/50000]\n",
      "loss: 0.033400  [19136/50000]\n",
      "loss: 0.074352  [25536/50000]\n",
      "loss: 0.132015  [31936/50000]\n",
      "loss: 0.033599  [38336/50000]\n",
      "loss: 0.046767  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 0.109314 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.075417  [ 6336/50000]\n",
      "loss: 0.054827  [12736/50000]\n",
      "loss: 0.048175  [19136/50000]\n",
      "loss: 0.032533  [25536/50000]\n",
      "loss: 0.128019  [31936/50000]\n",
      "loss: 0.131593  [38336/50000]\n",
      "loss: 0.079570  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.7%, Avg loss: 0.113933 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.036921  [ 6336/50000]\n",
      "loss: 0.016758  [12736/50000]\n",
      "loss: 0.041709  [19136/50000]\n",
      "loss: 0.075296  [25536/50000]\n",
      "loss: 0.190855  [31936/50000]\n",
      "loss: 0.280706  [38336/50000]\n",
      "loss: 0.201528  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.109292 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.085856  [ 6336/50000]\n",
      "loss: 0.051668  [12736/50000]\n",
      "loss: 0.055400  [19136/50000]\n",
      "loss: 0.093786  [25536/50000]\n",
      "loss: 0.147935  [31936/50000]\n",
      "loss: 0.153024  [38336/50000]\n",
      "loss: 0.129664  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.112572 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.061273  [ 6336/50000]\n",
      "loss: 0.064957  [12736/50000]\n",
      "loss: 0.074387  [19136/50000]\n",
      "loss: 0.108430  [25536/50000]\n",
      "loss: 0.051286  [31936/50000]\n",
      "loss: 0.051417  [38336/50000]\n",
      "loss: 0.119327  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.117717 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.051833  [ 6336/50000]\n",
      "loss: 0.027927  [12736/50000]\n",
      "loss: 0.165359  [19136/50000]\n",
      "loss: 0.019723  [25536/50000]\n",
      "loss: 0.110743  [31936/50000]\n",
      "loss: 0.032804  [38336/50000]\n",
      "loss: 0.094229  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.121115 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.050586  [ 6336/50000]\n",
      "loss: 0.079987  [12736/50000]\n",
      "loss: 0.065548  [19136/50000]\n",
      "loss: 0.017620  [25536/50000]\n",
      "loss: 0.022920  [31936/50000]\n",
      "loss: 0.042256  [38336/50000]\n",
      "loss: 0.152638  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.118581 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.046407  [ 6336/50000]\n",
      "loss: 0.036335  [12736/50000]\n",
      "loss: 0.018880  [19136/50000]\n",
      "loss: 0.052401  [25536/50000]\n",
      "loss: 0.039613  [31936/50000]\n",
      "loss: 0.092334  [38336/50000]\n",
      "loss: 0.050169  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.118198 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.031419  [ 6336/50000]\n",
      "loss: 0.045372  [12736/50000]\n",
      "loss: 0.064575  [19136/50000]\n",
      "loss: 0.015332  [25536/50000]\n",
      "loss: 0.021880  [31936/50000]\n",
      "loss: 0.037147  [38336/50000]\n",
      "loss: 0.036724  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.2%, Avg loss: 0.125190 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.097297  [ 6336/50000]\n",
      "loss: 0.043310  [12736/50000]\n",
      "loss: 0.203413  [19136/50000]\n",
      "loss: 0.133150  [25536/50000]\n",
      "loss: 0.078276  [31936/50000]\n",
      "loss: 0.056496  [38336/50000]\n",
      "loss: 0.071252  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 0.116445 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.014423  [ 6336/50000]\n",
      "loss: 0.022823  [12736/50000]\n",
      "loss: 0.015481  [19136/50000]\n",
      "loss: 0.198366  [25536/50000]\n",
      "loss: 0.025934  [31936/50000]\n",
      "loss: 0.026054  [38336/50000]\n",
      "loss: 0.007897  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.7%, Avg loss: 0.124216 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.017943  [ 6336/50000]\n",
      "loss: 0.044800  [12736/50000]\n",
      "loss: 0.039197  [19136/50000]\n",
      "loss: 0.019589  [25536/50000]\n",
      "loss: 0.014902  [31936/50000]\n",
      "loss: 0.094361  [38336/50000]\n",
      "loss: 0.090234  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.122708 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.010780  [ 6336/50000]\n",
      "loss: 0.051856  [12736/50000]\n",
      "loss: 0.010092  [19136/50000]\n",
      "loss: 0.022981  [25536/50000]\n",
      "loss: 0.045318  [31936/50000]\n",
      "loss: 0.020758  [38336/50000]\n",
      "loss: 0.132415  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 0.129206 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.035926  [ 6336/50000]\n",
      "loss: 0.033233  [12736/50000]\n",
      "loss: 0.135442  [19136/50000]\n",
      "loss: 0.015670  [25536/50000]\n",
      "loss: 0.096819  [31936/50000]\n",
      "loss: 0.083192  [38336/50000]\n",
      "loss: 0.278589  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.128537 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.027938  [ 6336/50000]\n",
      "loss: 0.085823  [12736/50000]\n",
      "loss: 0.064226  [19136/50000]\n",
      "loss: 0.045529  [25536/50000]\n",
      "loss: 0.051628  [31936/50000]\n",
      "loss: 0.031977  [38336/50000]\n",
      "loss: 0.132364  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 0.132356 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.098753  [ 6336/50000]\n",
      "loss: 0.015593  [12736/50000]\n",
      "loss: 0.151708  [19136/50000]\n",
      "loss: 0.082100  [25536/50000]\n",
      "loss: 0.028192  [31936/50000]\n",
      "loss: 0.078023  [38336/50000]\n",
      "loss: 0.059116  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.2%, Avg loss: 0.131172 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.061962  [ 6336/50000]\n",
      "loss: 0.070953  [12736/50000]\n",
      "loss: 0.007810  [19136/50000]\n",
      "loss: 0.043035  [25536/50000]\n",
      "loss: 0.026851  [31936/50000]\n",
      "loss: 0.026485  [38336/50000]\n",
      "loss: 0.080835  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 0.134177 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.013287  [ 6336/50000]\n",
      "loss: 0.009712  [12736/50000]\n",
      "loss: 0.065622  [19136/50000]\n",
      "loss: 0.048687  [25536/50000]\n",
      "loss: 0.074390  [31936/50000]\n",
      "loss: 0.063892  [38336/50000]\n",
      "loss: 0.031278  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 0.138283 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.004789  [ 6336/50000]\n",
      "loss: 0.033399  [12736/50000]\n",
      "loss: 0.020954  [19136/50000]\n",
      "loss: 0.048688  [25536/50000]\n",
      "loss: 0.011280  [31936/50000]\n",
      "loss: 0.018570  [38336/50000]\n",
      "loss: 0.043754  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.137919 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.005126  [ 6336/50000]\n",
      "loss: 0.005017  [12736/50000]\n",
      "loss: 0.004240  [19136/50000]\n",
      "loss: 0.002434  [25536/50000]\n",
      "loss: 0.003793  [31936/50000]\n",
      "loss: 0.001893  [38336/50000]\n",
      "loss: 0.000785  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 0.151217 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.002799  [ 6336/50000]\n",
      "loss: 0.001259  [12736/50000]\n",
      "loss: 0.002676  [19136/50000]\n",
      "loss: 0.000294  [25536/50000]\n",
      "loss: 0.000942  [31936/50000]\n",
      "loss: 0.000994  [38336/50000]\n",
      "loss: 0.001496  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 0.154657 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.000486  [ 6336/50000]\n",
      "loss: 0.000507  [12736/50000]\n",
      "loss: 0.000705  [19136/50000]\n",
      "loss: 0.001190  [25536/50000]\n",
      "loss: 0.001018  [31936/50000]\n",
      "loss: 0.001548  [38336/50000]\n",
      "loss: 0.001013  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 0.155039 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.001342  [ 6336/50000]\n",
      "loss: 0.000978  [12736/50000]\n",
      "loss: 0.000818  [19136/50000]\n",
      "loss: 0.000843  [25536/50000]\n",
      "loss: 0.000263  [31936/50000]\n",
      "loss: 0.001966  [38336/50000]\n",
      "loss: 0.000700  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.159393 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.000845  [ 6336/50000]\n",
      "loss: 0.000312  [12736/50000]\n",
      "loss: 0.000699  [19136/50000]\n",
      "loss: 0.000364  [25536/50000]\n",
      "loss: 0.001098  [31936/50000]\n",
      "loss: 0.000306  [38336/50000]\n",
      "loss: 0.000796  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 0.160954 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.000543  [ 6336/50000]\n",
      "loss: 0.000355  [12736/50000]\n",
      "loss: 0.000678  [19136/50000]\n",
      "loss: 0.000693  [25536/50000]\n",
      "loss: 0.000677  [31936/50000]\n",
      "loss: 0.000494  [38336/50000]\n",
      "loss: 0.000364  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.163583 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.000794  [ 6336/50000]\n",
      "loss: 0.000511  [12736/50000]\n",
      "loss: 0.000908  [19136/50000]\n",
      "loss: 0.000700  [25536/50000]\n",
      "loss: 0.000791  [31936/50000]\n",
      "loss: 0.000758  [38336/50000]\n",
      "loss: 0.000460  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.166607 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.000242  [ 6336/50000]\n",
      "loss: 0.000599  [12736/50000]\n",
      "loss: 0.000693  [19136/50000]\n",
      "loss: 0.000526  [25536/50000]\n",
      "loss: 0.000248  [31936/50000]\n",
      "loss: 0.000328  [38336/50000]\n",
      "loss: 0.000396  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 0.163767 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.000321  [ 6336/50000]\n",
      "loss: 0.000593  [12736/50000]\n",
      "loss: 0.000738  [19136/50000]\n",
      "loss: 0.000439  [25536/50000]\n",
      "loss: 0.000517  [31936/50000]\n",
      "loss: 0.000620  [38336/50000]\n",
      "loss: 0.000411  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 0.166187 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.000194  [ 6336/50000]\n",
      "loss: 0.000390  [12736/50000]\n",
      "loss: 0.000971  [19136/50000]\n",
      "loss: 0.000656  [25536/50000]\n",
      "loss: 0.000239  [31936/50000]\n",
      "loss: 0.000340  [38336/50000]\n",
      "loss: 0.000229  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 0.166351 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.000909  [ 6336/50000]\n",
      "loss: 0.000287  [12736/50000]\n",
      "loss: 0.000407  [19136/50000]\n",
      "loss: 0.000259  [25536/50000]\n",
      "loss: 0.000294  [31936/50000]\n",
      "loss: 0.000576  [38336/50000]\n",
      "loss: 0.000338  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.169527 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.000595  [ 6336/50000]\n",
      "loss: 0.000171  [12736/50000]\n",
      "loss: 0.000177  [19136/50000]\n",
      "loss: 0.000367  [25536/50000]\n",
      "loss: 0.000564  [31936/50000]\n",
      "loss: 0.000360  [38336/50000]\n",
      "loss: 0.000604  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 0.170955 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.000162  [ 6336/50000]\n",
      "loss: 0.000425  [12736/50000]\n",
      "loss: 0.000177  [19136/50000]\n",
      "loss: 0.000251  [25536/50000]\n",
      "loss: 0.000475  [31936/50000]\n",
      "loss: 0.000606  [38336/50000]\n",
      "loss: 0.000565  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 0.170303 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.000676  [ 6336/50000]\n",
      "loss: 0.000517  [12736/50000]\n",
      "loss: 0.000390  [19136/50000]\n",
      "loss: 0.000584  [25536/50000]\n",
      "loss: 0.000417  [31936/50000]\n",
      "loss: 0.000382  [38336/50000]\n",
      "loss: 0.000301  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.171839 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.000178  [ 6336/50000]\n",
      "loss: 0.000303  [12736/50000]\n",
      "loss: 0.000306  [19136/50000]\n",
      "loss: 0.001004  [25536/50000]\n",
      "loss: 0.000237  [31936/50000]\n",
      "loss: 0.000291  [38336/50000]\n",
      "loss: 0.000394  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 0.170717 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.000400  [ 6336/50000]\n",
      "loss: 0.000307  [12736/50000]\n",
      "loss: 0.000208  [19136/50000]\n",
      "loss: 0.000519  [25536/50000]\n",
      "loss: 0.000212  [31936/50000]\n",
      "loss: 0.000289  [38336/50000]\n",
      "loss: 0.000260  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 0.172967 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.000286  [ 6336/50000]\n",
      "loss: 0.000118  [12736/50000]\n",
      "loss: 0.000117  [19136/50000]\n",
      "loss: 0.000450  [25536/50000]\n",
      "loss: 0.000388  [31936/50000]\n",
      "loss: 0.000286  [38336/50000]\n",
      "loss: 0.000486  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.174543 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.000203  [ 6336/50000]\n",
      "loss: 0.000355  [12736/50000]\n",
      "loss: 0.000302  [19136/50000]\n",
      "loss: 0.000237  [25536/50000]\n",
      "loss: 0.000141  [31936/50000]\n",
      "loss: 0.000187  [38336/50000]\n",
      "loss: 0.000325  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.170292 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.000184  [ 6336/50000]\n",
      "loss: 0.000267  [12736/50000]\n",
      "loss: 0.000321  [19136/50000]\n",
      "loss: 0.000223  [25536/50000]\n",
      "loss: 0.000270  [31936/50000]\n",
      "loss: 0.000337  [38336/50000]\n",
      "loss: 0.000289  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.174441 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.000442  [ 6336/50000]\n",
      "loss: 0.000120  [12736/50000]\n",
      "loss: 0.000348  [19136/50000]\n",
      "loss: 0.000346  [25536/50000]\n",
      "loss: 0.000339  [31936/50000]\n",
      "loss: 0.000109  [38336/50000]\n",
      "loss: 0.000144  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 0.175055 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.000236  [ 6336/50000]\n",
      "loss: 0.000265  [12736/50000]\n",
      "loss: 0.000349  [19136/50000]\n",
      "loss: 0.000530  [25536/50000]\n",
      "loss: 0.000493  [31936/50000]\n",
      "loss: 0.000040  [38336/50000]\n",
      "loss: 0.000302  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 0.176538 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.000176  [ 6336/50000]\n",
      "loss: 0.000264  [12736/50000]\n",
      "loss: 0.000462  [19136/50000]\n",
      "loss: 0.000203  [25536/50000]\n",
      "loss: 0.000156  [31936/50000]\n",
      "loss: 0.000213  [38336/50000]\n",
      "loss: 0.000247  [44736/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.177961 \n",
      "\n",
      "Finished Training Net + <class 'z2_conv.ConvNetC'>\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Comparisons\r\n",
    "\r\n",
    "There are a few comparisons between the models to be made here. Here is a list of the following that I log\r\n",
    "- Model accuracy on 10000 test images\r\n",
    "- Model accuracy per class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def test_accuracy(net):\r\n",
    "    net.to(device)\r\n",
    "    \r\n",
    "    correct = 0\r\n",
    "    total = 0\r\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in test_dataloader_rot:\r\n",
    "            images, labels = data[0].to(device), data[1].to(device)\r\n",
    "            # calculate outputs by running images through the network\r\n",
    "            outputs = net(images)\r\n",
    "            # the class with the highest energy is what we choose as prediction\r\n",
    "            _, predicted = torch.max(outputs.data, 1)\r\n",
    "            total += labels.size(0)\r\n",
    "            correct += (predicted == labels.to(device)).sum().item()\r\n",
    "\r\n",
    "    print('Accuracy of the ' + str(type(net)) + ' on the 10000 test images: %f %%' % (\r\n",
    "        100.0 * correct / total))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def class_labels(net):\r\n",
    "    net.to(device)\r\n",
    "    \r\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\r\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\r\n",
    "    # prepare to count predictions for each class\r\n",
    "    correct_pred = {num : 0 for num in range(0, 10)}\r\n",
    "    total_pred = {num : 0 for num in range(0, 10)}\r\n",
    "\r\n",
    "    # again no gradients needed\r\n",
    "    with torch.no_grad():\r\n",
    "        for data in test_dataloader_rot:\r\n",
    "            images, labels = data[0].to(device), data[1].to(device)\r\n",
    "            outputs = net(images.to(device))\r\n",
    "            _, predictions = torch.max(outputs, 1)\r\n",
    "            # collect the correct predictions for each class\r\n",
    "            for label, prediction in zip(labels, predictions):\r\n",
    "                if label == prediction:\r\n",
    "                    correct_pred[classes[label]] += 1\r\n",
    "                total_pred[classes[label]] += 1\r\n",
    "\r\n",
    "    print('Classes for ' + str(type(net)))\r\n",
    "\r\n",
    "    # print accuracy for each class\r\n",
    "    for classname, correct_count in correct_pred.items():\r\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\r\n",
    "        print(\"Accuracy for num {} is: {:.1f} %\".format(classname,\r\n",
    "                                                   accuracy))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "test_accuracy(p4m_net)\r\n",
    "class_labels(p4m_net)\r\n",
    "\r\n",
    "test_accuracy(p4_net)\r\n",
    "class_labels(p4_net)\r\n",
    "\r\n",
    "test_accuracy(conv_net)\r\n",
    "class_labels(conv_net)\r\n",
    "\r\n",
    "test_accuracy(convu_net)\r\n",
    "class_labels(convu_net)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5dd6fd0c021b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp4m_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp4m_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp4_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp4_net\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-5872bd6680f7>\u001b[0m in \u001b[0;36mtest_accuracy\u001b[1;34m(net)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;31m# calculate outputs by running images through the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;31m# the class with the highest energy is what we choose as prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Repos\\jack-champagne\\reu-code\\p4m-gconv\\p4m_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplane_group_spatial_max_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\reu-code\\lib\\site-packages\\groupy\\gconv\\pytorch_gconv\\splitgconv2d.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_channels\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_stabilizer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         y = F.conv2d(input, weight=tw, bias=None, stride=self.stride,\n\u001b[0m\u001b[0;32m     77\u001b[0m                         padding=self.padding)\n\u001b[0;32m     78\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnx_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## TODO: Uncomment\r\n",
    "torch.save(p4m_net, 'upright-trained-p4m-cifar-1.pth')\r\n",
    "torch.save(p4_net, 'upright-trained-p4-cifar-1.pth')\r\n",
    "torch.save(conv_net, 'rot-trained-conv-cifar-1.pth')\r\n",
    "torch.save(convu_net, 'upright-trained-conv-cifar-1.pth')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f665fd8ed1386b9605bd6d1d95408943e5396eca0f77e44c2585e6a9876cbe3c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('reu-code': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}